{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d162e062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Activation, Dense,Flatten, BatchNormalization, Add, Conv2D, MaxPooling2D\n",
    "from keras.layers import AveragePooling2D,Permute,Reshape,LSTM,Lambda,GRU,Bidirectional,BatchNormalization,Concatenate\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "import json\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac2d5790",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(MyEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f847e51a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yv67\\Documents\\12FundsHK_ToShare\\deeplearningdata\\stocks - Copy (2).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yv67\\AppData\\Local\\Temp/ipykernel_13184/52871672.py:86: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  X,y,tickers = self.load_data( csvpath_data,  timesteps_input,  timesteps_output)\n",
      "C:\\Python36\\Anaconda\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "14/14 [==============================] - 7s 103ms/step - loss: 0.4785 - sharpe_ratio: 0.2438 - val_loss: 0.0839 - val_sharpe_ratio: 0.1553\n",
      "Epoch 2/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.0925 - sharpe_ratio: 0.2922 - val_loss: -0.0590 - val_sharpe_ratio: 0.1534\n",
      "Epoch 3/300\n",
      "14/14 [==============================] - 0s 30ms/step - loss: -0.1924 - sharpe_ratio: 0.3066 - val_loss: -0.0738 - val_sharpe_ratio: 0.1473\n",
      "Epoch 4/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2237 - sharpe_ratio: 0.3132 - val_loss: -0.0906 - val_sharpe_ratio: 0.1649\n",
      "Epoch 5/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2443 - sharpe_ratio: 0.3252 - val_loss: -0.0552 - val_sharpe_ratio: 0.1578\n",
      "Epoch 6/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.2344 - sharpe_ratio: 0.3300 - val_loss: -0.0771 - val_sharpe_ratio: 0.1649\n",
      "Epoch 7/300\n",
      "14/14 [==============================] - 0s 36ms/step - loss: -0.2236 - sharpe_ratio: 0.3160 - val_loss: -0.0458 - val_sharpe_ratio: 0.1677\n",
      "Epoch 8/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.2463 - sharpe_ratio: 0.3642 - val_loss: -0.0085 - val_sharpe_ratio: 0.0737\n",
      "Epoch 9/300\n",
      "14/14 [==============================] - 1s 37ms/step - loss: -0.2535 - sharpe_ratio: 0.3509 - val_loss: -0.0813 - val_sharpe_ratio: 0.1777\n",
      "Epoch 10/300\n",
      "14/14 [==============================] - 1s 37ms/step - loss: -0.2546 - sharpe_ratio: 0.3600 - val_loss: -0.0373 - val_sharpe_ratio: 0.1601\n",
      "Epoch 11/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2279 - sharpe_ratio: 0.3228 - val_loss: -0.0088 - val_sharpe_ratio: 0.1182\n",
      "Epoch 12/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2303 - sharpe_ratio: 0.3487 - val_loss: -0.0053 - val_sharpe_ratio: 0.0777\n",
      "Epoch 13/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2440 - sharpe_ratio: 0.3583 - val_loss: 0.0134 - val_sharpe_ratio: 0.1113\n",
      "Epoch 14/300\n",
      "14/14 [==============================] - 1s 40ms/step - loss: -0.2561 - sharpe_ratio: 0.3431 - val_loss: 0.0879 - val_sharpe_ratio: -0.0066\n",
      "Epoch 15/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2107 - sharpe_ratio: 0.3394 - val_loss: -0.0076 - val_sharpe_ratio: 0.1503\n",
      "Epoch 16/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2336 - sharpe_ratio: 0.3352 - val_loss: -0.0320 - val_sharpe_ratio: 0.1149\n",
      "Epoch 17/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.2246 - sharpe_ratio: 0.3211 - val_loss: 0.0126 - val_sharpe_ratio: 0.1268\n",
      "Epoch 18/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2333 - sharpe_ratio: 0.3314 - val_loss: -0.0317 - val_sharpe_ratio: 0.1424\n",
      "Epoch 19/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2139 - sharpe_ratio: 0.3469 - val_loss: 0.0413 - val_sharpe_ratio: 0.1549\n",
      "Epoch 20/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2560 - sharpe_ratio: 0.3493 - val_loss: -0.0292 - val_sharpe_ratio: 0.1404\n",
      "Epoch 21/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.2140 - sharpe_ratio: 0.3338 - val_loss: 0.0306 - val_sharpe_ratio: 0.0872\n",
      "Epoch 22/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2506 - sharpe_ratio: 0.3230 - val_loss: -0.0760 - val_sharpe_ratio: 0.1316\n",
      "Epoch 23/300\n",
      "14/14 [==============================] - 0s 30ms/step - loss: -0.2705 - sharpe_ratio: 0.3138 - val_loss: -0.0308 - val_sharpe_ratio: 0.1457\n",
      "Epoch 24/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.2544 - sharpe_ratio: 0.3514 - val_loss: 0.0532 - val_sharpe_ratio: 0.0592\n",
      "Epoch 25/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2653 - sharpe_ratio: 0.3418 - val_loss: 0.0271 - val_sharpe_ratio: 0.0539\n",
      "Epoch 26/300\n",
      "14/14 [==============================] - 1s 38ms/step - loss: -0.2801 - sharpe_ratio: 0.3633 - val_loss: -0.0189 - val_sharpe_ratio: 0.1168\n",
      "Epoch 27/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.1880 - sharpe_ratio: 0.3378 - val_loss: 0.1041 - val_sharpe_ratio: 0.0347\n",
      "Epoch 28/300\n",
      "14/14 [==============================] - 1s 37ms/step - loss: -0.2206 - sharpe_ratio: 0.3419 - val_loss: 0.1244 - val_sharpe_ratio: -0.0245\n",
      "Epoch 29/300\n",
      "14/14 [==============================] - 1s 44ms/step - loss: -0.2464 - sharpe_ratio: 0.3618 - val_loss: 0.0425 - val_sharpe_ratio: 0.0637\n",
      "Epoch 30/300\n",
      "14/14 [==============================] - 1s 40ms/step - loss: -0.2517 - sharpe_ratio: 0.3646 - val_loss: 0.0378 - val_sharpe_ratio: 0.0715\n",
      "Epoch 31/300\n",
      "14/14 [==============================] - 1s 38ms/step - loss: -0.2742 - sharpe_ratio: 0.3465 - val_loss: 0.0613 - val_sharpe_ratio: 0.0543\n",
      "Epoch 32/300\n",
      "14/14 [==============================] - 0s 36ms/step - loss: -0.2850 - sharpe_ratio: 0.3545 - val_loss: 0.0021 - val_sharpe_ratio: 0.1205\n",
      "Epoch 33/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.2700 - sharpe_ratio: 0.3563 - val_loss: 0.0234 - val_sharpe_ratio: 0.1185\n",
      "Epoch 34/300\n",
      "14/14 [==============================] - 0s 36ms/step - loss: -0.2469 - sharpe_ratio: 0.3547 - val_loss: -1.3876e-04 - val_sharpe_ratio: 0.0563\n",
      "Epoch 35/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.2811 - sharpe_ratio: 0.3417 - val_loss: 0.0387 - val_sharpe_ratio: 0.0758\n",
      "Epoch 36/300\n",
      "14/14 [==============================] - 0s 36ms/step - loss: -0.2442 - sharpe_ratio: 0.3136 - val_loss: 0.0819 - val_sharpe_ratio: 0.0589\n",
      "Epoch 37/300\n",
      "14/14 [==============================] - 1s 40ms/step - loss: -0.2574 - sharpe_ratio: 0.3384 - val_loss: 0.0093 - val_sharpe_ratio: 0.1240\n",
      "Epoch 38/300\n",
      "14/14 [==============================] - 1s 40ms/step - loss: -0.2838 - sharpe_ratio: 0.3610 - val_loss: -7.9860e-04 - val_sharpe_ratio: 0.0979\n",
      "Epoch 39/300\n",
      "14/14 [==============================] - 1s 43ms/step - loss: -0.2990 - sharpe_ratio: 0.3182 - val_loss: -0.0160 - val_sharpe_ratio: 0.1700\n",
      "Epoch 40/300\n",
      "14/14 [==============================] - 1s 41ms/step - loss: -0.2395 - sharpe_ratio: 0.3100 - val_loss: 0.0219 - val_sharpe_ratio: 0.0231\n",
      "Epoch 41/300\n",
      "14/14 [==============================] - 1s 42ms/step - loss: -0.2593 - sharpe_ratio: 0.3025 - val_loss: 0.0151 - val_sharpe_ratio: 0.1277\n",
      "Epoch 42/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.2347 - sharpe_ratio: 0.2962 - val_loss: 0.0469 - val_sharpe_ratio: 0.1158\n",
      "Epoch 43/300\n",
      "14/14 [==============================] - 1s 46ms/step - loss: -0.2015 - sharpe_ratio: 0.2789 - val_loss: 0.0190 - val_sharpe_ratio: 0.0968\n",
      "Epoch 44/300\n",
      "14/14 [==============================] - 1s 38ms/step - loss: -0.2705 - sharpe_ratio: 0.3087 - val_loss: -0.0129 - val_sharpe_ratio: 0.0973\n",
      "Epoch 45/300\n",
      "14/14 [==============================] - 1s 38ms/step - loss: -0.2661 - sharpe_ratio: 0.3124 - val_loss: 0.0750 - val_sharpe_ratio: 0.0326\n",
      "Epoch 46/300\n",
      "14/14 [==============================] - 0s 36ms/step - loss: -0.2729 - sharpe_ratio: 0.3077 - val_loss: -0.0209 - val_sharpe_ratio: 0.1145\n",
      "Epoch 47/300\n",
      "14/14 [==============================] - 1s 39ms/step - loss: -0.2545 - sharpe_ratio: 0.2966 - val_loss: -0.0112 - val_sharpe_ratio: 0.1149\n",
      "Epoch 48/300\n",
      "14/14 [==============================] - 1s 37ms/step - loss: -0.2372 - sharpe_ratio: 0.3280 - val_loss: 0.0244 - val_sharpe_ratio: 0.1092\n",
      "Epoch 49/300\n",
      "14/14 [==============================] - 1s 37ms/step - loss: -0.2137 - sharpe_ratio: 0.2998 - val_loss: 0.0903 - val_sharpe_ratio: 0.0499\n",
      "Epoch 50/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.2095 - sharpe_ratio: 0.3224 - val_loss: 0.0422 - val_sharpe_ratio: 0.1264\n",
      "Epoch 51/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.2619 - sharpe_ratio: 0.3111 - val_loss: 0.0211 - val_sharpe_ratio: 0.0656\n",
      "Epoch 52/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2403 - sharpe_ratio: 0.2801 - val_loss: 0.0763 - val_sharpe_ratio: 0.0339\n",
      "Epoch 53/300\n",
      "14/14 [==============================] - 0s 36ms/step - loss: -0.2625 - sharpe_ratio: 0.3002 - val_loss: -0.0254 - val_sharpe_ratio: 0.0997\n",
      "Epoch 54/300\n",
      "14/14 [==============================] - 1s 37ms/step - loss: -0.2341 - sharpe_ratio: 0.2720 - val_loss: -0.0272 - val_sharpe_ratio: 0.1267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/300\n",
      "14/14 [==============================] - 1s 45ms/step - loss: -0.2843 - sharpe_ratio: 0.3109 - val_loss: 0.0824 - val_sharpe_ratio: 0.0049\n",
      "Epoch 56/300\n",
      "14/14 [==============================] - 1s 42ms/step - loss: -0.2363 - sharpe_ratio: 0.3195 - val_loss: 0.0250 - val_sharpe_ratio: 0.0801\n",
      "Epoch 57/300\n",
      "14/14 [==============================] - 1s 39ms/step - loss: -0.2429 - sharpe_ratio: 0.3062 - val_loss: -0.0389 - val_sharpe_ratio: 0.1411\n",
      "Epoch 58/300\n",
      "14/14 [==============================] - 0s 36ms/step - loss: -0.2670 - sharpe_ratio: 0.3221 - val_loss: -0.0434 - val_sharpe_ratio: 0.1434\n",
      "Epoch 59/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2630 - sharpe_ratio: 0.3097 - val_loss: -0.0420 - val_sharpe_ratio: 0.1436\n",
      "Epoch 60/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2913 - sharpe_ratio: 0.3272 - val_loss: -0.1444 - val_sharpe_ratio: 0.2446\n",
      "Epoch 61/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2956 - sharpe_ratio: 0.3191 - val_loss: -0.0277 - val_sharpe_ratio: 0.1271\n",
      "Epoch 62/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.2900 - sharpe_ratio: 0.3074 - val_loss: -0.0971 - val_sharpe_ratio: 0.1905\n",
      "Epoch 63/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.2827 - sharpe_ratio: 0.3179 - val_loss: -0.0453 - val_sharpe_ratio: 0.1618\n",
      "Epoch 64/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2731 - sharpe_ratio: 0.3410 - val_loss: 0.0685 - val_sharpe_ratio: 0.0186\n",
      "Epoch 65/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.2515 - sharpe_ratio: 0.3396 - val_loss: 0.0958 - val_sharpe_ratio: 0.0466\n",
      "Epoch 66/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.2453 - sharpe_ratio: 0.3499 - val_loss: 0.0318 - val_sharpe_ratio: 0.0982\n",
      "Epoch 67/300\n",
      "14/14 [==============================] - 0s 36ms/step - loss: -0.2831 - sharpe_ratio: 0.3548 - val_loss: -0.0252 - val_sharpe_ratio: 0.1200\n",
      "Epoch 68/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3055 - sharpe_ratio: 0.3425 - val_loss: 0.0180 - val_sharpe_ratio: 0.0443\n",
      "Epoch 69/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3187 - sharpe_ratio: 0.3442 - val_loss: -0.0103 - val_sharpe_ratio: 0.1105\n",
      "Epoch 70/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2955 - sharpe_ratio: 0.3408 - val_loss: 0.0144 - val_sharpe_ratio: 0.0940\n",
      "Epoch 71/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3250 - sharpe_ratio: 0.3246 - val_loss: 0.0155 - val_sharpe_ratio: 0.0661\n",
      "Epoch 72/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3017 - sharpe_ratio: 0.3461 - val_loss: -0.0565 - val_sharpe_ratio: 0.0749\n",
      "Epoch 73/300\n",
      "14/14 [==============================] - 1s 35ms/step - loss: -0.3224 - sharpe_ratio: 0.3309 - val_loss: 0.0441 - val_sharpe_ratio: 0.0436\n",
      "Epoch 74/300\n",
      "14/14 [==============================] - 1s 37ms/step - loss: -0.3117 - sharpe_ratio: 0.3330 - val_loss: -0.0493 - val_sharpe_ratio: 0.0898\n",
      "Epoch 75/300\n",
      "14/14 [==============================] - 1s 41ms/step - loss: -0.3173 - sharpe_ratio: 0.3324 - val_loss: 0.1196 - val_sharpe_ratio: -0.0545\n",
      "Epoch 76/300\n",
      "14/14 [==============================] - 1s 38ms/step - loss: -0.2956 - sharpe_ratio: 0.3360 - val_loss: -0.0188 - val_sharpe_ratio: 0.1042\n",
      "Epoch 77/300\n",
      "14/14 [==============================] - 1s 37ms/step - loss: -0.3066 - sharpe_ratio: 0.3368 - val_loss: -0.0206 - val_sharpe_ratio: 0.0918\n",
      "Epoch 78/300\n",
      "14/14 [==============================] - 1s 41ms/step - loss: -0.3012 - sharpe_ratio: 0.3479 - val_loss: -0.0046 - val_sharpe_ratio: 0.1029\n",
      "Epoch 79/300\n",
      "14/14 [==============================] - 1s 42ms/step - loss: -0.2992 - sharpe_ratio: 0.3518 - val_loss: 0.0310 - val_sharpe_ratio: 0.0522\n",
      "Epoch 80/300\n",
      "14/14 [==============================] - 1s 40ms/step - loss: -0.3123 - sharpe_ratio: 0.3436 - val_loss: 0.0469 - val_sharpe_ratio: 0.0400\n",
      "Epoch 81/300\n",
      "14/14 [==============================] - 0s 36ms/step - loss: -0.3292 - sharpe_ratio: 0.3584 - val_loss: 0.0341 - val_sharpe_ratio: 0.0676\n",
      "Epoch 82/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3107 - sharpe_ratio: 0.3177 - val_loss: -0.0097 - val_sharpe_ratio: 0.1214\n",
      "Epoch 83/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2402 - sharpe_ratio: 0.3005 - val_loss: -0.0175 - val_sharpe_ratio: 0.1386\n",
      "Epoch 84/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2471 - sharpe_ratio: 0.3049 - val_loss: 0.0287 - val_sharpe_ratio: 0.0984\n",
      "Epoch 85/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2856 - sharpe_ratio: 0.3158 - val_loss: -0.0394 - val_sharpe_ratio: 0.1214\n",
      "Epoch 86/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.2813 - sharpe_ratio: 0.3293 - val_loss: 0.0339 - val_sharpe_ratio: 0.0873\n",
      "Epoch 87/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2121 - sharpe_ratio: 0.3004 - val_loss: -0.0041 - val_sharpe_ratio: 0.1000\n",
      "Epoch 88/300\n",
      "14/14 [==============================] - 1s 38ms/step - loss: -0.2414 - sharpe_ratio: 0.3035 - val_loss: 0.0202 - val_sharpe_ratio: 0.1151\n",
      "Epoch 89/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.2652 - sharpe_ratio: 0.3317 - val_loss: -0.0198 - val_sharpe_ratio: 0.1419\n",
      "Epoch 90/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.2717 - sharpe_ratio: 0.3142 - val_loss: 0.0164 - val_sharpe_ratio: 0.0705\n",
      "Epoch 91/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.2683 - sharpe_ratio: 0.3281 - val_loss: -0.0417 - val_sharpe_ratio: 0.1438\n",
      "Epoch 92/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2827 - sharpe_ratio: 0.3245 - val_loss: 0.0338 - val_sharpe_ratio: 0.0502\n",
      "Epoch 93/300\n",
      "14/14 [==============================] - 1s 46ms/step - loss: -0.2910 - sharpe_ratio: 0.3126 - val_loss: -0.0212 - val_sharpe_ratio: 0.0971\n",
      "Epoch 94/300\n",
      "14/14 [==============================] - 1s 40ms/step - loss: -0.3281 - sharpe_ratio: 0.3092 - val_loss: -0.0942 - val_sharpe_ratio: 0.1451\n",
      "Epoch 95/300\n",
      "14/14 [==============================] - 1s 41ms/step - loss: -0.3124 - sharpe_ratio: 0.3066 - val_loss: -0.0507 - val_sharpe_ratio: 0.0714\n",
      "Epoch 96/300\n",
      "14/14 [==============================] - 1s 41ms/step - loss: -0.3097 - sharpe_ratio: 0.2918 - val_loss: -0.0698 - val_sharpe_ratio: 0.1366\n",
      "Epoch 97/300\n",
      "14/14 [==============================] - 1s 46ms/step - loss: -0.2747 - sharpe_ratio: 0.3368 - val_loss: 0.0140 - val_sharpe_ratio: 0.0707\n",
      "Epoch 98/300\n",
      "14/14 [==============================] - 1s 36ms/step - loss: -0.2780 - sharpe_ratio: 0.3066 - val_loss: -0.0642 - val_sharpe_ratio: 0.1547\n",
      "Epoch 99/300\n",
      "14/14 [==============================] - 1s 42ms/step - loss: -0.2996 - sharpe_ratio: 0.3276 - val_loss: -0.0277 - val_sharpe_ratio: 0.0341\n",
      "Epoch 100/300\n",
      "14/14 [==============================] - 1s 40ms/step - loss: -0.3241 - sharpe_ratio: 0.3168 - val_loss: -0.0011 - val_sharpe_ratio: 0.0705\n",
      "Epoch 101/300\n",
      "14/14 [==============================] - 1s 49ms/step - loss: -0.3144 - sharpe_ratio: 0.3121 - val_loss: 0.0169 - val_sharpe_ratio: 0.0549\n",
      "Epoch 102/300\n",
      "14/14 [==============================] - 1s 41ms/step - loss: -0.2770 - sharpe_ratio: 0.2972 - val_loss: -0.0045 - val_sharpe_ratio: 0.0915\n",
      "Epoch 103/300\n",
      "14/14 [==============================] - 1s 38ms/step - loss: -0.2141 - sharpe_ratio: 0.3224 - val_loss: 0.0600 - val_sharpe_ratio: 0.1395\n",
      "Epoch 104/300\n",
      "14/14 [==============================] - 1s 39ms/step - loss: -0.2226 - sharpe_ratio: 0.3550 - val_loss: 0.0299 - val_sharpe_ratio: 0.0714\n",
      "Epoch 105/300\n",
      "14/14 [==============================] - 1s 40ms/step - loss: -0.2872 - sharpe_ratio: 0.2613 - val_loss: -0.0936 - val_sharpe_ratio: 0.1624\n",
      "Epoch 106/300\n",
      "14/14 [==============================] - 1s 40ms/step - loss: -0.3203 - sharpe_ratio: 0.2880 - val_loss: -0.0562 - val_sharpe_ratio: 0.1255\n",
      "Epoch 107/300\n",
      "14/14 [==============================] - 1s 38ms/step - loss: -0.3098 - sharpe_ratio: 0.3332 - val_loss: -0.0391 - val_sharpe_ratio: 0.1045\n",
      "Epoch 108/300\n",
      "14/14 [==============================] - 1s 37ms/step - loss: -0.3187 - sharpe_ratio: 0.3309 - val_loss: -0.0253 - val_sharpe_ratio: 0.0697\n",
      "Epoch 109/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.3205 - sharpe_ratio: 0.3280 - val_loss: 0.0376 - val_sharpe_ratio: 0.0705\n",
      "Epoch 110/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.2735 - sharpe_ratio: 0.3462 - val_loss: -0.0047 - val_sharpe_ratio: 0.0891\n",
      "Epoch 111/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.2884 - sharpe_ratio: 0.3048 - val_loss: 0.0022 - val_sharpe_ratio: 0.0764\n",
      "Epoch 112/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3163 - sharpe_ratio: 0.3262 - val_loss: -0.0487 - val_sharpe_ratio: 0.1682\n",
      "Epoch 113/300\n",
      "14/14 [==============================] - 0s 36ms/step - loss: -0.2940 - sharpe_ratio: 0.3339 - val_loss: -0.0615 - val_sharpe_ratio: 0.1313\n",
      "Epoch 114/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3129 - sharpe_ratio: 0.3548 - val_loss: -0.0545 - val_sharpe_ratio: 0.1155\n",
      "Epoch 115/300\n",
      "14/14 [==============================] - 1s 38ms/step - loss: -0.3130 - sharpe_ratio: 0.3143 - val_loss: 0.0105 - val_sharpe_ratio: 0.0705\n",
      "Epoch 116/300\n",
      "14/14 [==============================] - 1s 37ms/step - loss: -0.3268 - sharpe_ratio: 0.3217 - val_loss: -0.0911 - val_sharpe_ratio: 0.1493\n",
      "Epoch 117/300\n",
      "14/14 [==============================] - 1s 37ms/step - loss: -0.3359 - sharpe_ratio: 0.3459 - val_loss: -0.0736 - val_sharpe_ratio: 0.1357\n",
      "Epoch 118/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3382 - sharpe_ratio: 0.3396 - val_loss: -0.0100 - val_sharpe_ratio: 0.0684\n",
      "Epoch 119/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3508 - sharpe_ratio: 0.3092 - val_loss: -0.0084 - val_sharpe_ratio: 0.1167\n",
      "Epoch 120/300\n",
      "14/14 [==============================] - 1s 39ms/step - loss: -0.2822 - sharpe_ratio: 0.3479 - val_loss: 0.0165 - val_sharpe_ratio: 0.0625\n",
      "Epoch 121/300\n",
      "14/14 [==============================] - 1s 39ms/step - loss: -0.3242 - sharpe_ratio: 0.3330 - val_loss: -0.0414 - val_sharpe_ratio: 0.0714\n",
      "Epoch 122/300\n",
      "14/14 [==============================] - 1s 39ms/step - loss: -0.3004 - sharpe_ratio: 0.3360 - val_loss: -0.0057 - val_sharpe_ratio: 0.1123\n",
      "Epoch 123/300\n",
      "14/14 [==============================] - 1s 40ms/step - loss: -0.2770 - sharpe_ratio: 0.3086 - val_loss: 0.0341 - val_sharpe_ratio: 0.1386\n",
      "Epoch 124/300\n",
      "14/14 [==============================] - 1s 37ms/step - loss: -0.1407 - sharpe_ratio: 0.3183 - val_loss: 0.1147 - val_sharpe_ratio: 0.1199\n",
      "Epoch 125/300\n",
      "14/14 [==============================] - 1s 37ms/step - loss: -0.1521 - sharpe_ratio: 0.3033 - val_loss: 0.0464 - val_sharpe_ratio: 0.1058\n",
      "Epoch 126/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2021 - sharpe_ratio: 0.3265 - val_loss: -0.0159 - val_sharpe_ratio: 0.1688\n",
      "Epoch 127/300\n",
      "14/14 [==============================] - 1s 38ms/step - loss: -0.2216 - sharpe_ratio: 0.3291 - val_loss: 0.0213 - val_sharpe_ratio: 0.1058\n",
      "Epoch 128/300\n",
      "14/14 [==============================] - 0s 30ms/step - loss: -0.2248 - sharpe_ratio: 0.3160 - val_loss: 0.0579 - val_sharpe_ratio: 0.0346\n",
      "Epoch 129/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.2450 - sharpe_ratio: 0.3325 - val_loss: 0.0144 - val_sharpe_ratio: 0.1242\n",
      "Epoch 130/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2592 - sharpe_ratio: 0.3602 - val_loss: 0.0328 - val_sharpe_ratio: 0.0663\n",
      "Epoch 131/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2864 - sharpe_ratio: 0.3376 - val_loss: -0.0101 - val_sharpe_ratio: 0.0832\n",
      "Epoch 132/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.2480 - sharpe_ratio: 0.3214 - val_loss: 0.0808 - val_sharpe_ratio: 0.0469\n",
      "Epoch 133/300\n",
      "14/14 [==============================] - 0s 30ms/step - loss: -0.2303 - sharpe_ratio: 0.3355 - val_loss: 0.0184 - val_sharpe_ratio: 0.0916\n",
      "Epoch 134/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.2758 - sharpe_ratio: 0.3774 - val_loss: 0.0751 - val_sharpe_ratio: -0.0013\n",
      "Epoch 135/300\n",
      "14/14 [==============================] - 0s 37ms/step - loss: -0.2435 - sharpe_ratio: 0.3430 - val_loss: 0.0458 - val_sharpe_ratio: 0.1350\n",
      "Epoch 136/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.2016 - sharpe_ratio: 0.3410 - val_loss: -0.0241 - val_sharpe_ratio: 0.1382\n",
      "Epoch 137/300\n",
      "14/14 [==============================] - 1s 36ms/step - loss: -0.3013 - sharpe_ratio: 0.3678 - val_loss: -0.0614 - val_sharpe_ratio: 0.1406\n",
      "Epoch 138/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.2089 - sharpe_ratio: 0.3490 - val_loss: 0.0261 - val_sharpe_ratio: 0.0730\n",
      "Epoch 139/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2713 - sharpe_ratio: 0.3548 - val_loss: -0.0265 - val_sharpe_ratio: 0.0616\n",
      "Epoch 140/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3148 - sharpe_ratio: 0.3592 - val_loss: -0.0434 - val_sharpe_ratio: 0.1162\n",
      "Epoch 141/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2848 - sharpe_ratio: 0.3686 - val_loss: 0.0140 - val_sharpe_ratio: 0.0940\n",
      "Epoch 142/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.2929 - sharpe_ratio: 0.3613 - val_loss: -0.0508 - val_sharpe_ratio: 0.1459\n",
      "Epoch 143/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2838 - sharpe_ratio: 0.3484 - val_loss: -0.0204 - val_sharpe_ratio: 0.1057\n",
      "Epoch 144/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2790 - sharpe_ratio: 0.3603 - val_loss: 0.0296 - val_sharpe_ratio: 0.0200\n",
      "Epoch 145/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2917 - sharpe_ratio: 0.3426 - val_loss: 0.0083 - val_sharpe_ratio: 0.0727\n",
      "Epoch 146/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2213 - sharpe_ratio: 0.3577 - val_loss: -0.0633 - val_sharpe_ratio: 0.1825\n",
      "Epoch 147/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.2389 - sharpe_ratio: 0.3354 - val_loss: -0.0129 - val_sharpe_ratio: 0.1670\n",
      "Epoch 148/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.2552 - sharpe_ratio: 0.3793 - val_loss: -0.0283 - val_sharpe_ratio: 0.1228\n",
      "Epoch 149/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.2779 - sharpe_ratio: 0.3628 - val_loss: -0.0318 - val_sharpe_ratio: 0.1158\n",
      "Epoch 150/300\n",
      "14/14 [==============================] - 0s 30ms/step - loss: -0.3244 - sharpe_ratio: 0.3725 - val_loss: -0.0503 - val_sharpe_ratio: 0.1191\n",
      "Epoch 151/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.2861 - sharpe_ratio: 0.3744 - val_loss: -0.0530 - val_sharpe_ratio: 0.1666\n",
      "Epoch 152/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2593 - sharpe_ratio: 0.3345 - val_loss: -0.0222 - val_sharpe_ratio: 0.0897\n",
      "Epoch 153/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.2933 - sharpe_ratio: 0.3725 - val_loss: 0.0076 - val_sharpe_ratio: 0.0409\n",
      "Epoch 154/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.2668 - sharpe_ratio: 0.3478 - val_loss: 0.0390 - val_sharpe_ratio: 0.1033\n",
      "Epoch 155/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2953 - sharpe_ratio: 0.3693 - val_loss: -0.0552 - val_sharpe_ratio: 0.1420\n",
      "Epoch 156/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.3017 - sharpe_ratio: 0.3941 - val_loss: -0.0673 - val_sharpe_ratio: 0.1529\n",
      "Epoch 157/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3254 - sharpe_ratio: 0.3571 - val_loss: -0.0617 - val_sharpe_ratio: 0.1099\n",
      "Epoch 158/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.3248 - sharpe_ratio: 0.3654 - val_loss: -0.0822 - val_sharpe_ratio: 0.1592\n",
      "Epoch 159/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.3010 - sharpe_ratio: 0.3350 - val_loss: 0.0277 - val_sharpe_ratio: 0.1028\n",
      "Epoch 160/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.2377 - sharpe_ratio: 0.3522 - val_loss: 0.0293 - val_sharpe_ratio: 0.0755\n",
      "Epoch 161/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2944 - sharpe_ratio: 0.3680 - val_loss: -0.0718 - val_sharpe_ratio: 0.1419\n",
      "Epoch 162/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.2812 - sharpe_ratio: 0.3440 - val_loss: 0.0418 - val_sharpe_ratio: 0.0382\n",
      "Epoch 163/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3075 - sharpe_ratio: 0.3645 - val_loss: -0.0736 - val_sharpe_ratio: 0.0213\n",
      "Epoch 164/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3291 - sharpe_ratio: 0.3335 - val_loss: -0.0754 - val_sharpe_ratio: 0.0933\n",
      "Epoch 165/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3313 - sharpe_ratio: 0.3730 - val_loss: -0.1012 - val_sharpe_ratio: 0.1924\n",
      "Epoch 166/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2883 - sharpe_ratio: 0.3093 - val_loss: -0.0170 - val_sharpe_ratio: 0.0890\n",
      "Epoch 167/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3046 - sharpe_ratio: 0.3610 - val_loss: -0.0837 - val_sharpe_ratio: 0.1126\n",
      "Epoch 168/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.3236 - sharpe_ratio: 0.3463 - val_loss: -0.1174 - val_sharpe_ratio: 0.1837\n",
      "Epoch 169/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.3240 - sharpe_ratio: 0.3586 - val_loss: -0.0783 - val_sharpe_ratio: 0.1221\n",
      "Epoch 170/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3439 - sharpe_ratio: 0.3827 - val_loss: -0.0928 - val_sharpe_ratio: 0.1438\n",
      "Epoch 171/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3632 - sharpe_ratio: 0.3792 - val_loss: -0.1148 - val_sharpe_ratio: 0.1488\n",
      "Epoch 172/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3553 - sharpe_ratio: 0.3594 - val_loss: -0.1181 - val_sharpe_ratio: 0.1623\n",
      "Epoch 173/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3536 - sharpe_ratio: 0.3672 - val_loss: -0.0545 - val_sharpe_ratio: 0.1116\n",
      "Epoch 174/300\n",
      "14/14 [==============================] - 1s 39ms/step - loss: -0.3279 - sharpe_ratio: 0.3622 - val_loss: -0.0150 - val_sharpe_ratio: 0.0570\n",
      "Epoch 175/300\n",
      "14/14 [==============================] - 1s 37ms/step - loss: -0.3433 - sharpe_ratio: 0.3253 - val_loss: -0.0718 - val_sharpe_ratio: 0.0738\n",
      "Epoch 176/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3297 - sharpe_ratio: 0.3527 - val_loss: -0.0358 - val_sharpe_ratio: 0.0819\n",
      "Epoch 177/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3307 - sharpe_ratio: 0.3404 - val_loss: -0.0776 - val_sharpe_ratio: 0.1475\n",
      "Epoch 178/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3401 - sharpe_ratio: 0.3777 - val_loss: -0.0439 - val_sharpe_ratio: 0.1103\n",
      "Epoch 179/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3073 - sharpe_ratio: 0.3293 - val_loss: -0.1119 - val_sharpe_ratio: 0.2023\n",
      "Epoch 180/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3190 - sharpe_ratio: 0.3788 - val_loss: -0.0481 - val_sharpe_ratio: 0.1250\n",
      "Epoch 181/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3290 - sharpe_ratio: 0.3475 - val_loss: 0.0118 - val_sharpe_ratio: 0.0834\n",
      "Epoch 182/300\n",
      "14/14 [==============================] - 0s 36ms/step - loss: -0.2898 - sharpe_ratio: 0.3437 - val_loss: -0.1261 - val_sharpe_ratio: 0.1847\n",
      "Epoch 183/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.3250 - sharpe_ratio: 0.3396 - val_loss: 0.0096 - val_sharpe_ratio: 0.0317\n",
      "Epoch 184/300\n",
      "14/14 [==============================] - 0s 36ms/step - loss: -0.3341 - sharpe_ratio: 0.3355 - val_loss: -0.0942 - val_sharpe_ratio: 0.1566\n",
      "Epoch 185/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3455 - sharpe_ratio: 0.3577 - val_loss: -0.0371 - val_sharpe_ratio: 0.0774\n",
      "Epoch 186/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3458 - sharpe_ratio: 0.3441 - val_loss: -0.0492 - val_sharpe_ratio: 0.1088\n",
      "Epoch 187/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3128 - sharpe_ratio: 0.3368 - val_loss: -0.1168 - val_sharpe_ratio: 0.1728\n",
      "Epoch 188/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3442 - sharpe_ratio: 0.3570 - val_loss: -0.0012 - val_sharpe_ratio: 0.0387\n",
      "Epoch 189/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3346 - sharpe_ratio: 0.3343 - val_loss: -0.0753 - val_sharpe_ratio: 0.1834\n",
      "Epoch 190/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2999 - sharpe_ratio: 0.3746 - val_loss: -0.0617 - val_sharpe_ratio: 0.1064\n",
      "Epoch 191/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3308 - sharpe_ratio: 0.3446 - val_loss: -0.1039 - val_sharpe_ratio: 0.1733\n",
      "Epoch 192/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3045 - sharpe_ratio: 0.3280 - val_loss: -0.0989 - val_sharpe_ratio: 0.1836\n",
      "Epoch 193/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3035 - sharpe_ratio: 0.3437 - val_loss: -0.0314 - val_sharpe_ratio: 0.1214\n",
      "Epoch 194/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2847 - sharpe_ratio: 0.3302 - val_loss: -0.1132 - val_sharpe_ratio: 0.1636\n",
      "Epoch 195/300\n",
      "14/14 [==============================] - 1s 40ms/step - loss: -0.3298 - sharpe_ratio: 0.3317 - val_loss: -0.0579 - val_sharpe_ratio: 0.1523\n",
      "Epoch 196/300\n",
      "14/14 [==============================] - 1s 37ms/step - loss: -0.3034 - sharpe_ratio: 0.3717 - val_loss: -0.0286 - val_sharpe_ratio: 0.0807\n",
      "Epoch 197/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3076 - sharpe_ratio: 0.3557 - val_loss: 0.0019 - val_sharpe_ratio: 0.1337\n",
      "Epoch 198/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.2710 - sharpe_ratio: 0.3495 - val_loss: -0.0283 - val_sharpe_ratio: 0.1126\n",
      "Epoch 199/300\n",
      "14/14 [==============================] - 1s 38ms/step - loss: -0.2921 - sharpe_ratio: 0.3439 - val_loss: -0.0166 - val_sharpe_ratio: 0.0935\n",
      "Epoch 200/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3207 - sharpe_ratio: 0.3707 - val_loss: -0.0373 - val_sharpe_ratio: 0.0920\n",
      "Epoch 201/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.2500 - sharpe_ratio: 0.3253 - val_loss: 0.0512 - val_sharpe_ratio: 0.1167\n",
      "Epoch 202/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2605 - sharpe_ratio: 0.3756 - val_loss: -0.0816 - val_sharpe_ratio: 0.1523\n",
      "Epoch 203/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2887 - sharpe_ratio: 0.2998 - val_loss: -0.0270 - val_sharpe_ratio: 0.1306\n",
      "Epoch 204/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.2905 - sharpe_ratio: 0.3736 - val_loss: -0.0696 - val_sharpe_ratio: 0.1210\n",
      "Epoch 205/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3006 - sharpe_ratio: 0.3068 - val_loss: 0.0118 - val_sharpe_ratio: 0.0936\n",
      "Epoch 206/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2935 - sharpe_ratio: 0.3590 - val_loss: -0.0638 - val_sharpe_ratio: 0.1396\n",
      "Epoch 207/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3238 - sharpe_ratio: 0.3347 - val_loss: -0.1342 - val_sharpe_ratio: 0.1961\n",
      "Epoch 208/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3309 - sharpe_ratio: 0.3612 - val_loss: -0.0133 - val_sharpe_ratio: 0.0921\n",
      "Epoch 209/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3047 - sharpe_ratio: 0.3429 - val_loss: -0.0460 - val_sharpe_ratio: 0.1451\n",
      "Epoch 210/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2895 - sharpe_ratio: 0.3355 - val_loss: -0.0071 - val_sharpe_ratio: 0.0956\n",
      "Epoch 211/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3176 - sharpe_ratio: 0.3623 - val_loss: -0.0379 - val_sharpe_ratio: 0.1122\n",
      "Epoch 212/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.3064 - sharpe_ratio: 0.3471 - val_loss: -0.0662 - val_sharpe_ratio: 0.1242\n",
      "Epoch 213/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3205 - sharpe_ratio: 0.3718 - val_loss: -0.0757 - val_sharpe_ratio: 0.1538\n",
      "Epoch 214/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3289 - sharpe_ratio: 0.3734 - val_loss: 0.0010 - val_sharpe_ratio: 0.0705\n",
      "Epoch 215/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3354 - sharpe_ratio: 0.3518 - val_loss: -0.1020 - val_sharpe_ratio: 0.1699\n",
      "Epoch 216/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.3335 - sharpe_ratio: 0.3532 - val_loss: -0.0538 - val_sharpe_ratio: 0.1393\n",
      "Epoch 217/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3134 - sharpe_ratio: 0.3463 - val_loss: -0.0476 - val_sharpe_ratio: 0.1395\n",
      "Epoch 218/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2777 - sharpe_ratio: 0.3219 - val_loss: -0.0661 - val_sharpe_ratio: 0.1473\n",
      "Epoch 219/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.2700 - sharpe_ratio: 0.3224 - val_loss: 0.0637 - val_sharpe_ratio: 0.0969\n",
      "Epoch 220/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2670 - sharpe_ratio: 0.3536 - val_loss: -0.0247 - val_sharpe_ratio: 0.1527\n",
      "Epoch 221/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2637 - sharpe_ratio: 0.3297 - val_loss: -0.0932 - val_sharpe_ratio: 0.1563\n",
      "Epoch 222/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.3157 - sharpe_ratio: 0.3544 - val_loss: -0.0653 - val_sharpe_ratio: 0.1089\n",
      "Epoch 223/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3166 - sharpe_ratio: 0.3413 - val_loss: -0.0290 - val_sharpe_ratio: 0.1064\n",
      "Epoch 224/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3040 - sharpe_ratio: 0.3325 - val_loss: -0.0056 - val_sharpe_ratio: 0.0696\n",
      "Epoch 225/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3202 - sharpe_ratio: 0.3609 - val_loss: -0.0473 - val_sharpe_ratio: 0.0451\n",
      "Epoch 226/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3442 - sharpe_ratio: 0.3614 - val_loss: -0.0650 - val_sharpe_ratio: 0.1393\n",
      "Epoch 227/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3492 - sharpe_ratio: 0.3634 - val_loss: -0.0783 - val_sharpe_ratio: 0.1194\n",
      "Epoch 228/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3448 - sharpe_ratio: 0.3544 - val_loss: -0.1049 - val_sharpe_ratio: 0.1526\n",
      "Epoch 229/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3357 - sharpe_ratio: 0.3667 - val_loss: -0.0133 - val_sharpe_ratio: 0.1218\n",
      "Epoch 230/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3046 - sharpe_ratio: 0.3714 - val_loss: -0.0779 - val_sharpe_ratio: 0.1538\n",
      "Epoch 231/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3269 - sharpe_ratio: 0.3258 - val_loss: -0.0395 - val_sharpe_ratio: 0.1197\n",
      "Epoch 232/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3381 - sharpe_ratio: 0.3584 - val_loss: -0.0730 - val_sharpe_ratio: 0.1223\n",
      "Epoch 233/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3398 - sharpe_ratio: 0.3538 - val_loss: -0.0576 - val_sharpe_ratio: 0.1183\n",
      "Epoch 234/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3375 - sharpe_ratio: 0.3473 - val_loss: -0.0928 - val_sharpe_ratio: 0.1542\n",
      "Epoch 235/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3016 - sharpe_ratio: 0.3587 - val_loss: -0.0029 - val_sharpe_ratio: 0.0862\n",
      "Epoch 236/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3252 - sharpe_ratio: 0.3502 - val_loss: -0.0726 - val_sharpe_ratio: 0.1265\n",
      "Epoch 237/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2925 - sharpe_ratio: 0.3323 - val_loss: -0.0187 - val_sharpe_ratio: 0.1129\n",
      "Epoch 238/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2943 - sharpe_ratio: 0.3528 - val_loss: -0.0188 - val_sharpe_ratio: 0.1004\n",
      "Epoch 239/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3024 - sharpe_ratio: 0.3652 - val_loss: -0.1024 - val_sharpe_ratio: 0.1984\n",
      "Epoch 240/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3156 - sharpe_ratio: 0.3742 - val_loss: -0.0696 - val_sharpe_ratio: 0.1196\n",
      "Epoch 241/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3500 - sharpe_ratio: 0.3685 - val_loss: -0.1239 - val_sharpe_ratio: 0.1561\n",
      "Epoch 242/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3596 - sharpe_ratio: 0.3624 - val_loss: -0.1141 - val_sharpe_ratio: 0.1831\n",
      "Epoch 243/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3452 - sharpe_ratio: 0.3726 - val_loss: -0.1068 - val_sharpe_ratio: 0.1052\n",
      "Epoch 244/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3551 - sharpe_ratio: 0.3828 - val_loss: -0.1123 - val_sharpe_ratio: 0.1903\n",
      "Epoch 245/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3549 - sharpe_ratio: 0.3622 - val_loss: -0.1055 - val_sharpe_ratio: 0.1655\n",
      "Epoch 246/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3480 - sharpe_ratio: 0.3560 - val_loss: -0.0397 - val_sharpe_ratio: 0.0766\n",
      "Epoch 247/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3585 - sharpe_ratio: 0.3757 - val_loss: -0.1176 - val_sharpe_ratio: 0.1666\n",
      "Epoch 248/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3507 - sharpe_ratio: 0.3559 - val_loss: -0.0684 - val_sharpe_ratio: 0.1024\n",
      "Epoch 249/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3225 - sharpe_ratio: 0.3779 - val_loss: -0.0388 - val_sharpe_ratio: 0.1176\n",
      "Epoch 250/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.3427 - sharpe_ratio: 0.3576 - val_loss: -0.0508 - val_sharpe_ratio: 0.0705\n",
      "Epoch 251/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3278 - sharpe_ratio: 0.3401 - val_loss: -0.0933 - val_sharpe_ratio: 0.1670\n",
      "Epoch 252/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3445 - sharpe_ratio: 0.3814 - val_loss: -0.0903 - val_sharpe_ratio: 0.1357\n",
      "Epoch 253/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.3588 - sharpe_ratio: 0.3735 - val_loss: -0.0941 - val_sharpe_ratio: 0.1451\n",
      "Epoch 254/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.2973 - sharpe_ratio: 0.3447 - val_loss: 0.0297 - val_sharpe_ratio: 0.1190\n",
      "Epoch 255/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.1197 - sharpe_ratio: 0.3234 - val_loss: 0.0102 - val_sharpe_ratio: 0.1713\n",
      "Epoch 256/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2097 - sharpe_ratio: 0.2949 - val_loss: 0.0708 - val_sharpe_ratio: 0.0385\n",
      "Epoch 257/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.1285 - sharpe_ratio: 0.2821 - val_loss: 0.1105 - val_sharpe_ratio: 0.0815\n",
      "Epoch 258/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.1954 - sharpe_ratio: 0.3265 - val_loss: 0.0696 - val_sharpe_ratio: 0.0569\n",
      "Epoch 259/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2607 - sharpe_ratio: 0.3422 - val_loss: -0.0398 - val_sharpe_ratio: 0.1447\n",
      "Epoch 260/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.2939 - sharpe_ratio: 0.3556 - val_loss: 0.0020 - val_sharpe_ratio: 0.0503\n",
      "Epoch 261/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3076 - sharpe_ratio: 0.3671 - val_loss: -0.0145 - val_sharpe_ratio: 0.0645\n",
      "Epoch 262/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.2893 - sharpe_ratio: 0.3635 - val_loss: -0.0705 - val_sharpe_ratio: 0.0762\n",
      "Epoch 263/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.2987 - sharpe_ratio: 0.3582 - val_loss: 0.0248 - val_sharpe_ratio: 0.0592\n",
      "Epoch 264/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2837 - sharpe_ratio: 0.3276 - val_loss: -0.0477 - val_sharpe_ratio: 0.1316\n",
      "Epoch 265/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.0915 - sharpe_ratio: 0.3121 - val_loss: 0.7533 - val_sharpe_ratio: 0.1692\n",
      "Epoch 266/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4521 - sharpe_ratio: 0.3021 - val_loss: 0.3251 - val_sharpe_ratio: 0.1059\n",
      "Epoch 267/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 31ms/step - loss: -0.0497 - sharpe_ratio: 0.3254 - val_loss: 0.1279 - val_sharpe_ratio: 0.1239\n",
      "Epoch 268/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.1594 - sharpe_ratio: 0.3477 - val_loss: 0.0958 - val_sharpe_ratio: 0.1150\n",
      "Epoch 269/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.1922 - sharpe_ratio: 0.3571 - val_loss: -0.0170 - val_sharpe_ratio: 0.1443\n",
      "Epoch 270/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2038 - sharpe_ratio: 0.3430 - val_loss: 0.0226 - val_sharpe_ratio: 0.1151\n",
      "Epoch 271/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2851 - sharpe_ratio: 0.3640 - val_loss: 0.0187 - val_sharpe_ratio: 0.0679\n",
      "Epoch 272/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2632 - sharpe_ratio: 0.3493 - val_loss: -0.0378 - val_sharpe_ratio: 0.1354\n",
      "Epoch 273/300\n",
      "14/14 [==============================] - 0s 36ms/step - loss: -0.2628 - sharpe_ratio: 0.3337 - val_loss: 0.0423 - val_sharpe_ratio: 0.1007\n",
      "Epoch 274/300\n",
      "14/14 [==============================] - 1s 37ms/step - loss: -0.2319 - sharpe_ratio: 0.3353 - val_loss: 0.0250 - val_sharpe_ratio: 0.0844\n",
      "Epoch 275/300\n",
      "14/14 [==============================] - 1s 40ms/step - loss: -0.2051 - sharpe_ratio: 0.3445 - val_loss: 0.0925 - val_sharpe_ratio: 0.0335\n",
      "Epoch 276/300\n",
      "14/14 [==============================] - 1s 36ms/step - loss: -0.2781 - sharpe_ratio: 0.3603 - val_loss: 0.1290 - val_sharpe_ratio: 0.0469\n",
      "Epoch 277/300\n",
      "14/14 [==============================] - 0s 37ms/step - loss: -0.2014 - sharpe_ratio: 0.3595 - val_loss: 0.0015 - val_sharpe_ratio: 0.1338\n",
      "Epoch 278/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.2347 - sharpe_ratio: 0.3455 - val_loss: 0.0347 - val_sharpe_ratio: 0.0946\n",
      "Epoch 279/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2388 - sharpe_ratio: 0.3388 - val_loss: 0.0355 - val_sharpe_ratio: 0.0480\n",
      "Epoch 280/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.1945 - sharpe_ratio: 0.3087 - val_loss: 0.0323 - val_sharpe_ratio: 0.0820\n",
      "Epoch 281/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.1950 - sharpe_ratio: 0.2929 - val_loss: 0.0566 - val_sharpe_ratio: 0.0700\n",
      "Epoch 282/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.1803 - sharpe_ratio: 0.3096 - val_loss: -0.0214 - val_sharpe_ratio: 0.1523\n",
      "Epoch 283/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.2451 - sharpe_ratio: 0.3437 - val_loss: -6.2119e-04 - val_sharpe_ratio: 0.1069\n",
      "Epoch 284/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.2420 - sharpe_ratio: 0.3231 - val_loss: 0.1183 - val_sharpe_ratio: 0.1082\n",
      "Epoch 285/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.1254 - sharpe_ratio: 0.3232 - val_loss: -0.0229 - val_sharpe_ratio: 0.1449\n",
      "Epoch 286/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.2788 - sharpe_ratio: 0.3305 - val_loss: 0.0528 - val_sharpe_ratio: 0.0921\n",
      "Epoch 287/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.1296 - sharpe_ratio: 0.3243 - val_loss: 0.0459 - val_sharpe_ratio: 0.1579\n",
      "Epoch 288/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.2149 - sharpe_ratio: 0.3412 - val_loss: -0.0261 - val_sharpe_ratio: 0.1308\n",
      "Epoch 289/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.2758 - sharpe_ratio: 0.3680 - val_loss: -0.0320 - val_sharpe_ratio: 0.1179\n",
      "Epoch 290/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.2977 - sharpe_ratio: 0.3696 - val_loss: -0.0464 - val_sharpe_ratio: 0.1096\n",
      "Epoch 291/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.3433 - sharpe_ratio: 0.3940 - val_loss: -0.0669 - val_sharpe_ratio: 0.1330\n",
      "Epoch 292/300\n",
      "14/14 [==============================] - 0s 31ms/step - loss: -0.3371 - sharpe_ratio: 0.3718 - val_loss: -0.0529 - val_sharpe_ratio: 0.1116\n",
      "Epoch 293/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3151 - sharpe_ratio: 0.3662 - val_loss: -0.0553 - val_sharpe_ratio: 0.1373\n",
      "Epoch 294/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2638 - sharpe_ratio: 0.3244 - val_loss: -0.0438 - val_sharpe_ratio: 0.1290\n",
      "Epoch 295/300\n",
      "14/14 [==============================] - 0s 32ms/step - loss: -0.2918 - sharpe_ratio: 0.3644 - val_loss: -0.0889 - val_sharpe_ratio: 0.1494\n",
      "Epoch 296/300\n",
      "14/14 [==============================] - 0s 33ms/step - loss: -0.3350 - sharpe_ratio: 0.3501 - val_loss: -0.1189 - val_sharpe_ratio: 0.1737\n",
      "Epoch 297/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.3089 - sharpe_ratio: 0.3539 - val_loss: -0.0121 - val_sharpe_ratio: 0.0962\n",
      "Epoch 298/300\n",
      "14/14 [==============================] - 0s 34ms/step - loss: -0.3248 - sharpe_ratio: 0.3627 - val_loss: -0.0641 - val_sharpe_ratio: 0.1329\n",
      "Epoch 299/300\n",
      "14/14 [==============================] - 1s 37ms/step - loss: -0.3132 - sharpe_ratio: 0.3496 - val_loss: -0.0885 - val_sharpe_ratio: 0.1664\n",
      "Epoch 300/300\n",
      "14/14 [==============================] - 0s 35ms/step - loss: -0.2989 - sharpe_ratio: 0.3611 - val_loss: -0.0073 - val_sharpe_ratio: 0.0705\n",
      "1/1 [==============================] - 1s 771ms/step\n",
      "There are total 11 samples to predict\n",
      "Sample 0 : [ HCLTECH.NS ]\n",
      "Sample 1 : [ HCLTECH.NS ]\n",
      "Sample 2 : [ HCLTECH.NS ]\n",
      "Sample 3 : [ HCLTECH.NS ]\n",
      "Sample 4 : [ HCLTECH.NS ]\n",
      "Sample 5 : [ HCLTECH.NS ]\n",
      "Sample 6 : [ HCLTECH.NS ]\n",
      "Sample 7 : [ HCLTECH.NS ]\n",
      "Sample 8 : [ HCLTECH.NS ]\n",
      "Sample 9 : [ HCLTECH.NS ]\n",
      "Sample 10 : [ HCLTECH.NS ]\n",
      "Sharpe ratio of this portfolio: [1.2319717789301388, 1.113791001232399, -0.5525525327042612, 0.5744895853462179, -0.38288803762149803, 0.572054065243545, 1.638143748782805, 0.2704289219125297, -1.2947992098817909, 1.118015846420443, -0.9090395271575448]\n",
      "write file log at C:/Users/yv67/Documents/12FundsHK_ToShare/deeplearningdata/logs/GRU\\log_437.txt\n",
      "Epoch 1/300\n",
      "28/28 [==============================] - 1s 36ms/step - loss: -0.1322 - sharpe_ratio: 0.2116 - val_loss: 0.1503 - val_sharpe_ratio: -0.0614\n",
      "Epoch 2/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.1535 - sharpe_ratio: 0.2150 - val_loss: 0.0189 - val_sharpe_ratio: 0.0479\n",
      "Epoch 3/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: -0.1714 - sharpe_ratio: 0.2385 - val_loss: 0.1551 - val_sharpe_ratio: -0.0629\n",
      "Epoch 4/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.1734 - sharpe_ratio: 0.2393 - val_loss: 0.0501 - val_sharpe_ratio: 0.0191\n",
      "Epoch 5/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.1442 - sharpe_ratio: 0.2225 - val_loss: 0.1425 - val_sharpe_ratio: -0.0682\n",
      "Epoch 6/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.1701 - sharpe_ratio: 0.2246 - val_loss: 0.0593 - val_sharpe_ratio: -0.0136\n",
      "Epoch 7/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2033 - sharpe_ratio: 0.2338 - val_loss: 0.0759 - val_sharpe_ratio: -0.0295\n",
      "Epoch 8/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2102 - sharpe_ratio: 0.2615 - val_loss: 0.0870 - val_sharpe_ratio: -0.0140\n",
      "Epoch 9/300\n",
      "28/28 [==============================] - 1s 42ms/step - loss: -0.1603 - sharpe_ratio: 0.2369 - val_loss: 0.1225 - val_sharpe_ratio: -0.0370\n",
      "Epoch 10/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.1949 - sharpe_ratio: 0.2500 - val_loss: 0.0670 - val_sharpe_ratio: -0.0123\n",
      "Epoch 11/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.1684 - sharpe_ratio: 0.2269 - val_loss: 0.1507 - val_sharpe_ratio: -0.0257\n",
      "Epoch 12/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.1712 - sharpe_ratio: 0.2405 - val_loss: 0.1064 - val_sharpe_ratio: -0.0213\n",
      "Epoch 13/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.1606 - sharpe_ratio: 0.2394 - val_loss: 0.1102 - val_sharpe_ratio: -0.0152\n",
      "Epoch 14/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.1808 - sharpe_ratio: 0.2400 - val_loss: -0.0136 - val_sharpe_ratio: 0.0505\n",
      "Epoch 15/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.1906 - sharpe_ratio: 0.2450 - val_loss: 0.0162 - val_sharpe_ratio: 0.0601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.1950 - sharpe_ratio: 0.2336 - val_loss: 0.0898 - val_sharpe_ratio: -0.0464\n",
      "Epoch 17/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2092 - sharpe_ratio: 0.2499 - val_loss: 0.0561 - val_sharpe_ratio: -0.0035\n",
      "Epoch 18/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2202 - sharpe_ratio: 0.2458 - val_loss: -0.0024 - val_sharpe_ratio: 0.0450\n",
      "Epoch 19/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.1895 - sharpe_ratio: 0.2145 - val_loss: 0.0880 - val_sharpe_ratio: -0.0266\n",
      "Epoch 20/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2039 - sharpe_ratio: 0.2485 - val_loss: 0.0013 - val_sharpe_ratio: 0.0612\n",
      "Epoch 21/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2008 - sharpe_ratio: 0.2443 - val_loss: 0.0842 - val_sharpe_ratio: -0.0100\n",
      "Epoch 22/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2230 - sharpe_ratio: 0.2564 - val_loss: 0.0837 - val_sharpe_ratio: -0.0342\n",
      "Epoch 23/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2089 - sharpe_ratio: 0.2450 - val_loss: 0.0759 - val_sharpe_ratio: -0.0471\n",
      "Epoch 24/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.1792 - sharpe_ratio: 0.2425 - val_loss: 0.0773 - val_sharpe_ratio: 0.0339\n",
      "Epoch 25/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.1711 - sharpe_ratio: 0.2409 - val_loss: 0.0716 - val_sharpe_ratio: -0.0095\n",
      "Epoch 26/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2096 - sharpe_ratio: 0.2400 - val_loss: 0.1181 - val_sharpe_ratio: -0.0468\n",
      "Epoch 27/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.1722 - sharpe_ratio: 0.2361 - val_loss: 0.1207 - val_sharpe_ratio: -0.0161\n",
      "Epoch 28/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.1844 - sharpe_ratio: 0.2486 - val_loss: 0.0926 - val_sharpe_ratio: -0.0151\n",
      "Epoch 29/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.1901 - sharpe_ratio: 0.2521 - val_loss: 0.0730 - val_sharpe_ratio: -0.0036\n",
      "Epoch 30/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2196 - sharpe_ratio: 0.2560 - val_loss: 0.0575 - val_sharpe_ratio: -0.0052\n",
      "Epoch 31/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2024 - sharpe_ratio: 0.2409 - val_loss: 0.0838 - val_sharpe_ratio: -0.0240\n",
      "Epoch 32/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2053 - sharpe_ratio: 0.2404 - val_loss: 0.0914 - val_sharpe_ratio: -0.0269\n",
      "Epoch 33/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2072 - sharpe_ratio: 0.2346 - val_loss: 0.0650 - val_sharpe_ratio: -0.0186\n",
      "Epoch 34/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2252 - sharpe_ratio: 0.2563 - val_loss: 0.0434 - val_sharpe_ratio: 0.0234\n",
      "Epoch 35/300\n",
      "28/28 [==============================] - 1s 28ms/step - loss: -0.2086 - sharpe_ratio: 0.2388 - val_loss: 0.0743 - val_sharpe_ratio: -0.0054\n",
      "Epoch 36/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2202 - sharpe_ratio: 0.2621 - val_loss: 0.0541 - val_sharpe_ratio: -0.0158\n",
      "Epoch 37/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2305 - sharpe_ratio: 0.2595 - val_loss: 0.0539 - val_sharpe_ratio: -0.0038\n",
      "Epoch 38/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2168 - sharpe_ratio: 0.2479 - val_loss: 0.0671 - val_sharpe_ratio: -0.0302\n",
      "Epoch 39/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2296 - sharpe_ratio: 0.2553 - val_loss: 0.0779 - val_sharpe_ratio: -0.0346\n",
      "Epoch 40/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2242 - sharpe_ratio: 0.2436 - val_loss: 0.0658 - val_sharpe_ratio: -0.0261\n",
      "Epoch 41/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2314 - sharpe_ratio: 0.2723 - val_loss: 0.0654 - val_sharpe_ratio: -0.0653\n",
      "Epoch 42/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2329 - sharpe_ratio: 0.2676 - val_loss: 0.1191 - val_sharpe_ratio: -0.0948\n",
      "Epoch 43/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2255 - sharpe_ratio: 0.2684 - val_loss: 0.1248 - val_sharpe_ratio: -0.0593\n",
      "Epoch 44/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.1897 - sharpe_ratio: 0.2433 - val_loss: 0.0742 - val_sharpe_ratio: -0.0017\n",
      "Epoch 45/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2061 - sharpe_ratio: 0.2450 - val_loss: 0.0683 - val_sharpe_ratio: 0.0214\n",
      "Epoch 46/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.1922 - sharpe_ratio: 0.2421 - val_loss: 0.0194 - val_sharpe_ratio: 0.0146\n",
      "Epoch 47/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2356 - sharpe_ratio: 0.2553 - val_loss: 0.0648 - val_sharpe_ratio: -0.0023\n",
      "Epoch 48/300\n",
      "28/28 [==============================] - 1s 28ms/step - loss: -0.2416 - sharpe_ratio: 0.2772 - val_loss: -0.0092 - val_sharpe_ratio: 0.0762\n",
      "Epoch 49/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2418 - sharpe_ratio: 0.2751 - val_loss: 0.0505 - val_sharpe_ratio: -0.0260\n",
      "Epoch 50/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2334 - sharpe_ratio: 0.2680 - val_loss: 0.0605 - val_sharpe_ratio: -0.0151\n",
      "Epoch 51/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2391 - sharpe_ratio: 0.2701 - val_loss: 0.0524 - val_sharpe_ratio: -0.0069\n",
      "Epoch 52/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2367 - sharpe_ratio: 0.2759 - val_loss: 0.0557 - val_sharpe_ratio: -0.0169\n",
      "Epoch 53/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2320 - sharpe_ratio: 0.2574 - val_loss: 0.0694 - val_sharpe_ratio: -0.0262\n",
      "Epoch 54/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2406 - sharpe_ratio: 0.2553 - val_loss: 0.0676 - val_sharpe_ratio: -0.0186\n",
      "Epoch 55/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2326 - sharpe_ratio: 0.2763 - val_loss: 0.0693 - val_sharpe_ratio: -0.0256\n",
      "Epoch 56/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2299 - sharpe_ratio: 0.2599 - val_loss: 0.0501 - val_sharpe_ratio: 0.0042\n",
      "Epoch 57/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2343 - sharpe_ratio: 0.2655 - val_loss: 0.0792 - val_sharpe_ratio: -0.0307\n",
      "Epoch 58/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2345 - sharpe_ratio: 0.2735 - val_loss: 0.0891 - val_sharpe_ratio: -0.0179\n",
      "Epoch 59/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2184 - sharpe_ratio: 0.2543 - val_loss: 0.0665 - val_sharpe_ratio: -0.0053\n",
      "Epoch 60/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2307 - sharpe_ratio: 0.2717 - val_loss: 0.0585 - val_sharpe_ratio: -0.0093\n",
      "Epoch 61/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2403 - sharpe_ratio: 0.2718 - val_loss: 0.0547 - val_sharpe_ratio: -0.0094\n",
      "Epoch 62/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2047 - sharpe_ratio: 0.2384 - val_loss: 0.0742 - val_sharpe_ratio: -0.0031\n",
      "Epoch 63/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2126 - sharpe_ratio: 0.2514 - val_loss: 0.0930 - val_sharpe_ratio: -0.0383\n",
      "Epoch 64/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2148 - sharpe_ratio: 0.2283 - val_loss: 0.1393 - val_sharpe_ratio: -0.1137\n",
      "Epoch 65/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2207 - sharpe_ratio: 0.2499 - val_loss: 0.1634 - val_sharpe_ratio: -0.1135\n",
      "Epoch 66/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2002 - sharpe_ratio: 0.2352 - val_loss: 0.0659 - val_sharpe_ratio: -0.0353\n",
      "Epoch 67/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2152 - sharpe_ratio: 0.2467 - val_loss: 0.0863 - val_sharpe_ratio: -0.0297\n",
      "Epoch 68/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2277 - sharpe_ratio: 0.2491 - val_loss: 0.0945 - val_sharpe_ratio: -0.0658\n",
      "Epoch 69/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.1953 - sharpe_ratio: 0.2430 - val_loss: 0.0974 - val_sharpe_ratio: -0.0427\n",
      "Epoch 70/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.1976 - sharpe_ratio: 0.2439 - val_loss: 0.0771 - val_sharpe_ratio: -0.0166\n",
      "Epoch 71/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2022 - sharpe_ratio: 0.2504 - val_loss: 0.0775 - val_sharpe_ratio: -0.0225\n",
      "Epoch 72/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2107 - sharpe_ratio: 0.2492 - val_loss: 0.0772 - val_sharpe_ratio: -0.0314\n",
      "Epoch 73/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2256 - sharpe_ratio: 0.2645 - val_loss: -0.0121 - val_sharpe_ratio: 0.0547\n",
      "Epoch 74/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2231 - sharpe_ratio: 0.2562 - val_loss: 0.0439 - val_sharpe_ratio: -0.0075\n",
      "Epoch 75/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2357 - sharpe_ratio: 0.2588 - val_loss: 0.0615 - val_sharpe_ratio: -0.0208\n",
      "Epoch 76/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2167 - sharpe_ratio: 0.2379 - val_loss: 0.0610 - val_sharpe_ratio: -0.0116\n",
      "Epoch 77/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2297 - sharpe_ratio: 0.2519 - val_loss: 0.0520 - val_sharpe_ratio: -0.0202\n",
      "Epoch 78/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2223 - sharpe_ratio: 0.2360 - val_loss: 0.0468 - val_sharpe_ratio: -0.0158\n",
      "Epoch 79/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2487 - sharpe_ratio: 0.2477 - val_loss: 0.0398 - val_sharpe_ratio: -0.0190\n",
      "Epoch 80/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2396 - sharpe_ratio: 0.2498 - val_loss: 0.0560 - val_sharpe_ratio: -0.0136\n",
      "Epoch 81/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2417 - sharpe_ratio: 0.2534 - val_loss: 0.0471 - val_sharpe_ratio: -0.0114\n",
      "Epoch 82/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2484 - sharpe_ratio: 0.2604 - val_loss: 0.0630 - val_sharpe_ratio: -0.0559\n",
      "Epoch 83/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: -0.2124 - sharpe_ratio: 0.2439 - val_loss: 0.0748 - val_sharpe_ratio: -0.0332\n",
      "Epoch 84/300\n",
      "28/28 [==============================] - 1s 39ms/step - loss: -0.2357 - sharpe_ratio: 0.2458 - val_loss: 0.0373 - val_sharpe_ratio: -0.0143\n",
      "Epoch 85/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.1989 - sharpe_ratio: 0.2294 - val_loss: 0.0811 - val_sharpe_ratio: -0.0151\n",
      "Epoch 86/300\n",
      "28/28 [==============================] - 1s 40ms/step - loss: -0.2177 - sharpe_ratio: 0.2535 - val_loss: 0.0433 - val_sharpe_ratio: -0.0078\n",
      "Epoch 87/300\n",
      "28/28 [==============================] - 1s 36ms/step - loss: -0.2393 - sharpe_ratio: 0.2593 - val_loss: 0.0602 - val_sharpe_ratio: -0.0190\n",
      "Epoch 88/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2296 - sharpe_ratio: 0.2492 - val_loss: 0.0716 - val_sharpe_ratio: -0.0314\n",
      "Epoch 89/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2190 - sharpe_ratio: 0.2473 - val_loss: 0.0923 - val_sharpe_ratio: -0.0340\n",
      "Epoch 90/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2062 - sharpe_ratio: 0.2619 - val_loss: 0.0616 - val_sharpe_ratio: -0.0037\n",
      "Epoch 91/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2145 - sharpe_ratio: 0.2517 - val_loss: 0.1091 - val_sharpe_ratio: -0.0446\n",
      "Epoch 92/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2037 - sharpe_ratio: 0.2531 - val_loss: 0.0879 - val_sharpe_ratio: -0.0676\n",
      "Epoch 93/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2275 - sharpe_ratio: 0.2719 - val_loss: 0.0738 - val_sharpe_ratio: -0.0067\n",
      "Epoch 94/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2004 - sharpe_ratio: 0.2621 - val_loss: 0.0612 - val_sharpe_ratio: 0.0033\n",
      "Epoch 95/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2237 - sharpe_ratio: 0.2591 - val_loss: 0.0955 - val_sharpe_ratio: -0.0409\n",
      "Epoch 96/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2273 - sharpe_ratio: 0.2712 - val_loss: 0.0779 - val_sharpe_ratio: -0.0106\n",
      "Epoch 97/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2312 - sharpe_ratio: 0.2507 - val_loss: 0.0782 - val_sharpe_ratio: -0.0361\n",
      "Epoch 98/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2324 - sharpe_ratio: 0.2630 - val_loss: 0.0670 - val_sharpe_ratio: -0.0274\n",
      "Epoch 99/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: -0.2024 - sharpe_ratio: 0.2426 - val_loss: 0.0888 - val_sharpe_ratio: -0.0148\n",
      "Epoch 100/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2203 - sharpe_ratio: 0.2578 - val_loss: 0.0619 - val_sharpe_ratio: -0.0234\n",
      "Epoch 101/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2267 - sharpe_ratio: 0.2505 - val_loss: 0.0611 - val_sharpe_ratio: -0.0464\n",
      "Epoch 102/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2440 - sharpe_ratio: 0.2700 - val_loss: 0.0589 - val_sharpe_ratio: -0.0213\n",
      "Epoch 103/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2231 - sharpe_ratio: 0.2465 - val_loss: 0.0593 - val_sharpe_ratio: -0.0201\n",
      "Epoch 104/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2401 - sharpe_ratio: 0.2698 - val_loss: 0.0822 - val_sharpe_ratio: -0.0106\n",
      "Epoch 105/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.1913 - sharpe_ratio: 0.2373 - val_loss: 0.0693 - val_sharpe_ratio: -0.0301\n",
      "Epoch 106/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2181 - sharpe_ratio: 0.2449 - val_loss: 0.0635 - val_sharpe_ratio: -0.0325\n",
      "Epoch 107/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2403 - sharpe_ratio: 0.2578 - val_loss: 0.0774 - val_sharpe_ratio: -0.0319\n",
      "Epoch 108/300\n",
      "28/28 [==============================] - 1s 35ms/step - loss: -0.2278 - sharpe_ratio: 0.2514 - val_loss: 0.0577 - val_sharpe_ratio: -0.0167\n",
      "Epoch 109/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.1967 - sharpe_ratio: 0.2298 - val_loss: 0.0789 - val_sharpe_ratio: -0.0190\n",
      "Epoch 110/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.1807 - sharpe_ratio: 0.2337 - val_loss: 0.0329 - val_sharpe_ratio: 0.0545\n",
      "Epoch 111/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.1873 - sharpe_ratio: 0.2705 - val_loss: 0.1014 - val_sharpe_ratio: -0.0076\n",
      "Epoch 112/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2110 - sharpe_ratio: 0.2705 - val_loss: 0.0759 - val_sharpe_ratio: -0.0342\n",
      "Epoch 113/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2141 - sharpe_ratio: 0.2546 - val_loss: 0.0732 - val_sharpe_ratio: -0.0151\n",
      "Epoch 114/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2070 - sharpe_ratio: 0.2516 - val_loss: 0.0830 - val_sharpe_ratio: -0.0151\n",
      "Epoch 115/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: -0.2216 - sharpe_ratio: 0.2639 - val_loss: 0.0534 - val_sharpe_ratio: -1.3628e-06\n",
      "Epoch 116/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2166 - sharpe_ratio: 0.2615 - val_loss: 0.0981 - val_sharpe_ratio: -0.0483\n",
      "Epoch 117/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: -0.2345 - sharpe_ratio: 0.2641 - val_loss: 0.0684 - val_sharpe_ratio: -0.0246\n",
      "Epoch 118/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: -0.1922 - sharpe_ratio: 0.2335 - val_loss: 0.0511 - val_sharpe_ratio: 9.0919e-05\n",
      "Epoch 119/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2358 - sharpe_ratio: 0.2586 - val_loss: 0.0417 - val_sharpe_ratio: -0.0089\n",
      "Epoch 120/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2265 - sharpe_ratio: 0.2463 - val_loss: 0.0397 - val_sharpe_ratio: -0.0020\n",
      "Epoch 121/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2260 - sharpe_ratio: 0.2486 - val_loss: 0.0597 - val_sharpe_ratio: -0.0188\n",
      "Epoch 122/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2288 - sharpe_ratio: 0.2570 - val_loss: 0.0737 - val_sharpe_ratio: -0.0304\n",
      "Epoch 123/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2365 - sharpe_ratio: 0.2597 - val_loss: 0.0266 - val_sharpe_ratio: 1.6121e-04\n",
      "Epoch 124/300\n",
      "28/28 [==============================] - 1s 35ms/step - loss: -0.2416 - sharpe_ratio: 0.2523 - val_loss: 0.0415 - val_sharpe_ratio: -0.0069\n",
      "Epoch 125/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2388 - sharpe_ratio: 0.2559 - val_loss: 0.0461 - val_sharpe_ratio: -0.0246\n",
      "Epoch 126/300\n",
      "28/28 [==============================] - 1s 36ms/step - loss: -0.2419 - sharpe_ratio: 0.2571 - val_loss: 0.0446 - val_sharpe_ratio: -0.0023\n",
      "Epoch 127/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2394 - sharpe_ratio: 0.2642 - val_loss: 0.0466 - val_sharpe_ratio: -0.0072\n",
      "Epoch 128/300\n",
      "28/28 [==============================] - 1s 44ms/step - loss: -0.2411 - sharpe_ratio: 0.2652 - val_loss: 0.1257 - val_sharpe_ratio: -0.0719\n",
      "Epoch 129/300\n",
      "28/28 [==============================] - 1s 43ms/step - loss: -0.2147 - sharpe_ratio: 0.2650 - val_loss: 0.0090 - val_sharpe_ratio: 0.0207\n",
      "Epoch 130/300\n",
      "28/28 [==============================] - 1s 35ms/step - loss: -0.2257 - sharpe_ratio: 0.2575 - val_loss: 0.0429 - val_sharpe_ratio: -0.0086\n",
      "Epoch 131/300\n",
      "28/28 [==============================] - 1s 40ms/step - loss: -0.2380 - sharpe_ratio: 0.2593 - val_loss: 0.0395 - val_sharpe_ratio: 9.9259e-04\n",
      "Epoch 132/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2304 - sharpe_ratio: 0.2638 - val_loss: 0.0741 - val_sharpe_ratio: -0.0125\n",
      "Epoch 133/300\n",
      "28/28 [==============================] - 1s 39ms/step - loss: -0.2349 - sharpe_ratio: 0.2631 - val_loss: 0.0463 - val_sharpe_ratio: -0.0069\n",
      "Epoch 134/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2234 - sharpe_ratio: 0.2506 - val_loss: 0.0705 - val_sharpe_ratio: -0.0126\n",
      "Epoch 135/300\n",
      "28/28 [==============================] - 1s 36ms/step - loss: -0.2265 - sharpe_ratio: 0.2539 - val_loss: 0.0561 - val_sharpe_ratio: -0.0068\n",
      "Epoch 136/300\n",
      "28/28 [==============================] - 1s 41ms/step - loss: -0.2418 - sharpe_ratio: 0.2586 - val_loss: 0.0524 - val_sharpe_ratio: -0.0050\n",
      "Epoch 137/300\n",
      "28/28 [==============================] - 1s 43ms/step - loss: -0.2259 - sharpe_ratio: 0.2702 - val_loss: 0.0884 - val_sharpe_ratio: -0.0541\n",
      "Epoch 138/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: -0.2118 - sharpe_ratio: 0.2332 - val_loss: 0.0606 - val_sharpe_ratio: -0.0059\n",
      "Epoch 139/300\n",
      "28/28 [==============================] - 1s 39ms/step - loss: -0.2262 - sharpe_ratio: 0.2633 - val_loss: 0.0670 - val_sharpe_ratio: -0.0171\n",
      "Epoch 140/300\n",
      "28/28 [==============================] - 1s 40ms/step - loss: -0.2372 - sharpe_ratio: 0.2629 - val_loss: 0.0696 - val_sharpe_ratio: -0.0395\n",
      "Epoch 141/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2339 - sharpe_ratio: 0.2641 - val_loss: 0.0594 - val_sharpe_ratio: -0.0146\n",
      "Epoch 142/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2364 - sharpe_ratio: 0.2703 - val_loss: 0.0429 - val_sharpe_ratio: 0.0525\n",
      "Epoch 143/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.1679 - sharpe_ratio: 0.2286 - val_loss: 0.0772 - val_sharpe_ratio: -0.0154\n",
      "Epoch 144/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2196 - sharpe_ratio: 0.2619 - val_loss: 0.0811 - val_sharpe_ratio: -0.0172\n",
      "Epoch 145/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2188 - sharpe_ratio: 0.2590 - val_loss: 0.0666 - val_sharpe_ratio: -0.0390\n",
      "Epoch 146/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2240 - sharpe_ratio: 0.2573 - val_loss: 0.0532 - val_sharpe_ratio: 0.0106\n",
      "Epoch 147/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2205 - sharpe_ratio: 0.2466 - val_loss: 0.0630 - val_sharpe_ratio: -0.0190\n",
      "Epoch 148/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2436 - sharpe_ratio: 0.2663 - val_loss: 0.0500 - val_sharpe_ratio: -0.0099\n",
      "Epoch 149/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2509 - sharpe_ratio: 0.2716 - val_loss: 0.0887 - val_sharpe_ratio: -0.0514\n",
      "Epoch 150/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2373 - sharpe_ratio: 0.2695 - val_loss: 0.0544 - val_sharpe_ratio: -0.0190\n",
      "Epoch 151/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2196 - sharpe_ratio: 0.2525 - val_loss: 0.0615 - val_sharpe_ratio: -0.0100\n",
      "Epoch 152/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2333 - sharpe_ratio: 0.2646 - val_loss: 0.0503 - val_sharpe_ratio: -0.0297\n",
      "Epoch 153/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2446 - sharpe_ratio: 0.2669 - val_loss: 0.0501 - val_sharpe_ratio: -0.0190\n",
      "Epoch 154/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2408 - sharpe_ratio: 0.2585 - val_loss: 0.0401 - val_sharpe_ratio: -0.0015\n",
      "Epoch 155/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2322 - sharpe_ratio: 0.2506 - val_loss: 0.0332 - val_sharpe_ratio: -0.0046\n",
      "Epoch 156/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2209 - sharpe_ratio: 0.2443 - val_loss: 0.0735 - val_sharpe_ratio: -0.0251\n",
      "Epoch 157/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2226 - sharpe_ratio: 0.2624 - val_loss: 0.0786 - val_sharpe_ratio: -0.0420\n",
      "Epoch 158/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2250 - sharpe_ratio: 0.2432 - val_loss: 0.0552 - val_sharpe_ratio: -0.0219\n",
      "Epoch 159/300\n",
      "28/28 [==============================] - 1s 35ms/step - loss: -0.2256 - sharpe_ratio: 0.2421 - val_loss: 0.0573 - val_sharpe_ratio: -0.0158\n",
      "Epoch 160/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2303 - sharpe_ratio: 0.2410 - val_loss: 0.0624 - val_sharpe_ratio: -0.0315\n",
      "Epoch 161/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2160 - sharpe_ratio: 0.2456 - val_loss: 0.0878 - val_sharpe_ratio: -0.0571\n",
      "Epoch 162/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2225 - sharpe_ratio: 0.2545 - val_loss: 0.0709 - val_sharpe_ratio: -0.0198\n",
      "Epoch 163/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2424 - sharpe_ratio: 0.2657 - val_loss: 0.0781 - val_sharpe_ratio: -0.0403\n",
      "Epoch 164/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2229 - sharpe_ratio: 0.2538 - val_loss: 0.0037 - val_sharpe_ratio: 0.0417\n",
      "Epoch 165/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2322 - sharpe_ratio: 0.2489 - val_loss: 0.0525 - val_sharpe_ratio: -0.0139\n",
      "Epoch 166/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2476 - sharpe_ratio: 0.2777 - val_loss: 0.0510 - val_sharpe_ratio: -0.0138\n",
      "Epoch 167/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2254 - sharpe_ratio: 0.2613 - val_loss: 0.0566 - val_sharpe_ratio: -0.0054\n",
      "Epoch 168/300\n",
      "28/28 [==============================] - 1s 36ms/step - loss: -0.2244 - sharpe_ratio: 0.2538 - val_loss: 0.0718 - val_sharpe_ratio: -0.0114\n",
      "Epoch 169/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2438 - sharpe_ratio: 0.2762 - val_loss: 0.0594 - val_sharpe_ratio: -0.0147\n",
      "Epoch 170/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2373 - sharpe_ratio: 0.2622 - val_loss: 0.0712 - val_sharpe_ratio: -0.0134\n",
      "Epoch 171/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2335 - sharpe_ratio: 0.2550 - val_loss: -0.0190 - val_sharpe_ratio: 0.0585\n",
      "Epoch 172/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2362 - sharpe_ratio: 0.2378 - val_loss: 0.0438 - val_sharpe_ratio: -0.0087\n",
      "Epoch 173/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2415 - sharpe_ratio: 0.2501 - val_loss: 0.0388 - val_sharpe_ratio: -8.2627e-04\n",
      "Epoch 174/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2377 - sharpe_ratio: 0.2647 - val_loss: 0.0568 - val_sharpe_ratio: -0.0127\n",
      "Epoch 175/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2304 - sharpe_ratio: 0.2561 - val_loss: 0.0607 - val_sharpe_ratio: -0.0324\n",
      "Epoch 176/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: -0.2399 - sharpe_ratio: 0.2520 - val_loss: 0.0649 - val_sharpe_ratio: -0.0438\n",
      "Epoch 177/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2292 - sharpe_ratio: 0.2406 - val_loss: 0.0606 - val_sharpe_ratio: -0.0047\n",
      "Epoch 178/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2315 - sharpe_ratio: 0.2480 - val_loss: 0.1221 - val_sharpe_ratio: -0.0951\n",
      "Epoch 179/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2442 - sharpe_ratio: 0.2643 - val_loss: 0.0555 - val_sharpe_ratio: -0.0295\n",
      "Epoch 180/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2321 - sharpe_ratio: 0.2537 - val_loss: 0.0654 - val_sharpe_ratio: -0.0267\n",
      "Epoch 181/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2228 - sharpe_ratio: 0.2539 - val_loss: 0.0814 - val_sharpe_ratio: -0.0116\n",
      "Epoch 182/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2039 - sharpe_ratio: 0.2381 - val_loss: 0.0609 - val_sharpe_ratio: -0.0045\n",
      "Epoch 183/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.1263 - sharpe_ratio: 0.1932 - val_loss: 0.1304 - val_sharpe_ratio: -0.0565\n",
      "Epoch 184/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2001 - sharpe_ratio: 0.2544 - val_loss: -0.0056 - val_sharpe_ratio: 0.1013\n",
      "Epoch 185/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2049 - sharpe_ratio: 0.2493 - val_loss: 0.0368 - val_sharpe_ratio: 0.0528\n",
      "Epoch 186/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2289 - sharpe_ratio: 0.2517 - val_loss: 0.0499 - val_sharpe_ratio: -0.0158\n",
      "Epoch 187/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.1859 - sharpe_ratio: 0.2125 - val_loss: 0.0311 - val_sharpe_ratio: 0.0131\n",
      "Epoch 188/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2183 - sharpe_ratio: 0.2387 - val_loss: 0.0581 - val_sharpe_ratio: -0.0246\n",
      "Epoch 189/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: -0.2363 - sharpe_ratio: 0.2593 - val_loss: 0.0691 - val_sharpe_ratio: -0.0270\n",
      "Epoch 190/300\n",
      "28/28 [==============================] - 1s 28ms/step - loss: -0.2314 - sharpe_ratio: 0.2619 - val_loss: 0.0747 - val_sharpe_ratio: -0.0229\n",
      "Epoch 191/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2236 - sharpe_ratio: 0.2634 - val_loss: 0.0505 - val_sharpe_ratio: -0.0297\n",
      "Epoch 192/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2203 - sharpe_ratio: 0.2442 - val_loss: -0.0299 - val_sharpe_ratio: 0.0450\n",
      "Epoch 193/300\n",
      "28/28 [==============================] - 1s 35ms/step - loss: -0.2407 - sharpe_ratio: 0.2680 - val_loss: 0.0173 - val_sharpe_ratio: 0.0193\n",
      "Epoch 194/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2343 - sharpe_ratio: 0.2590 - val_loss: 0.0554 - val_sharpe_ratio: -0.0349\n",
      "Epoch 195/300\n",
      "28/28 [==============================] - 1s 40ms/step - loss: -0.2247 - sharpe_ratio: 0.2545 - val_loss: 0.0575 - val_sharpe_ratio: -0.0078\n",
      "Epoch 196/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2147 - sharpe_ratio: 0.2299 - val_loss: 0.0571 - val_sharpe_ratio: 0.0026\n",
      "Epoch 197/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2208 - sharpe_ratio: 0.2557 - val_loss: 0.0687 - val_sharpe_ratio: -0.0339\n",
      "Epoch 198/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.1932 - sharpe_ratio: 0.2400 - val_loss: 0.0781 - val_sharpe_ratio: -0.0257\n",
      "Epoch 199/300\n",
      "28/28 [==============================] - 1s 28ms/step - loss: -0.2317 - sharpe_ratio: 0.2627 - val_loss: 0.0031 - val_sharpe_ratio: 0.0581\n",
      "Epoch 200/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2217 - sharpe_ratio: 0.2573 - val_loss: 0.0616 - val_sharpe_ratio: -0.0246\n",
      "Epoch 201/300\n",
      "28/28 [==============================] - 1s 28ms/step - loss: -0.2086 - sharpe_ratio: 0.2477 - val_loss: -0.0247 - val_sharpe_ratio: 0.0684\n",
      "Epoch 202/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2144 - sharpe_ratio: 0.2408 - val_loss: 0.0751 - val_sharpe_ratio: -0.0439\n",
      "Epoch 203/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2291 - sharpe_ratio: 0.2658 - val_loss: 0.0760 - val_sharpe_ratio: -0.0474\n",
      "Epoch 204/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2445 - sharpe_ratio: 0.2661 - val_loss: 0.0580 - val_sharpe_ratio: -0.0139\n",
      "Epoch 205/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2274 - sharpe_ratio: 0.2533 - val_loss: 0.0752 - val_sharpe_ratio: 0.0056\n",
      "Epoch 206/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2318 - sharpe_ratio: 0.2612 - val_loss: 0.0493 - val_sharpe_ratio: -0.0040\n",
      "Epoch 207/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2118 - sharpe_ratio: 0.2487 - val_loss: 0.0847 - val_sharpe_ratio: -0.0393\n",
      "Epoch 208/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2213 - sharpe_ratio: 0.2509 - val_loss: 0.0600 - val_sharpe_ratio: -0.0301\n",
      "Epoch 209/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2241 - sharpe_ratio: 0.2429 - val_loss: 0.0950 - val_sharpe_ratio: -0.0328\n",
      "Epoch 210/300\n",
      "28/28 [==============================] - 1s 28ms/step - loss: -0.1927 - sharpe_ratio: 0.2273 - val_loss: 0.0192 - val_sharpe_ratio: 0.0236\n",
      "Epoch 211/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2201 - sharpe_ratio: 0.2552 - val_loss: 0.0530 - val_sharpe_ratio: 0.0045\n",
      "Epoch 212/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2297 - sharpe_ratio: 0.2559 - val_loss: 0.0462 - val_sharpe_ratio: -0.0030\n",
      "Epoch 213/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2107 - sharpe_ratio: 0.2445 - val_loss: 0.0603 - val_sharpe_ratio: -0.0242\n",
      "Epoch 214/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2391 - sharpe_ratio: 0.2669 - val_loss: 0.0891 - val_sharpe_ratio: -0.0345\n",
      "Epoch 215/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2235 - sharpe_ratio: 0.2572 - val_loss: -0.0181 - val_sharpe_ratio: 0.0449\n",
      "Epoch 216/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2393 - sharpe_ratio: 0.2804 - val_loss: 0.0682 - val_sharpe_ratio: -0.0291\n",
      "Epoch 217/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2517 - sharpe_ratio: 0.2808 - val_loss: 0.0497 - val_sharpe_ratio: -0.0092\n",
      "Epoch 218/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2434 - sharpe_ratio: 0.2830 - val_loss: 0.0577 - val_sharpe_ratio: -0.0237\n",
      "Epoch 219/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2492 - sharpe_ratio: 0.2707 - val_loss: 0.0451 - val_sharpe_ratio: -0.0203\n",
      "Epoch 220/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2501 - sharpe_ratio: 0.2762 - val_loss: 0.0529 - val_sharpe_ratio: -0.0047\n",
      "Epoch 221/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2488 - sharpe_ratio: 0.2731 - val_loss: 0.0522 - val_sharpe_ratio: -0.0172\n",
      "Epoch 222/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2419 - sharpe_ratio: 0.2621 - val_loss: -0.0143 - val_sharpe_ratio: 0.0527\n",
      "Epoch 223/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2372 - sharpe_ratio: 0.2572 - val_loss: 0.0877 - val_sharpe_ratio: -0.0401\n",
      "Epoch 224/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: -0.2140 - sharpe_ratio: 0.2478 - val_loss: 0.0643 - val_sharpe_ratio: -0.0318\n",
      "Epoch 225/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2210 - sharpe_ratio: 0.2441 - val_loss: 0.0466 - val_sharpe_ratio: -0.0045\n",
      "Epoch 226/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2365 - sharpe_ratio: 0.2645 - val_loss: 0.0492 - val_sharpe_ratio: -0.0035\n",
      "Epoch 227/300\n",
      "28/28 [==============================] - 1s 28ms/step - loss: -0.2476 - sharpe_ratio: 0.2795 - val_loss: 0.0350 - val_sharpe_ratio: -0.0191\n",
      "Epoch 228/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 28ms/step - loss: -0.2419 - sharpe_ratio: 0.2677 - val_loss: 0.0586 - val_sharpe_ratio: -0.0148\n",
      "Epoch 229/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2354 - sharpe_ratio: 0.2471 - val_loss: 0.0604 - val_sharpe_ratio: -0.0322\n",
      "Epoch 230/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2430 - sharpe_ratio: 0.2718 - val_loss: 0.0629 - val_sharpe_ratio: -0.0307\n",
      "Epoch 231/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2161 - sharpe_ratio: 0.2536 - val_loss: 0.0415 - val_sharpe_ratio: -9.6096e-04\n",
      "Epoch 232/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2018 - sharpe_ratio: 0.2325 - val_loss: 0.0878 - val_sharpe_ratio: -0.0313\n",
      "Epoch 233/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2144 - sharpe_ratio: 0.2542 - val_loss: 0.0247 - val_sharpe_ratio: 0.0487\n",
      "Epoch 234/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.1729 - sharpe_ratio: 0.2256 - val_loss: 0.0793 - val_sharpe_ratio: -0.0640\n",
      "Epoch 235/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2121 - sharpe_ratio: 0.2493 - val_loss: -0.0323 - val_sharpe_ratio: 0.0884\n",
      "Epoch 236/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2120 - sharpe_ratio: 0.2543 - val_loss: 0.0614 - val_sharpe_ratio: -0.0014\n",
      "Epoch 237/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2150 - sharpe_ratio: 0.2433 - val_loss: 0.0802 - val_sharpe_ratio: -0.0366\n",
      "Epoch 238/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2213 - sharpe_ratio: 0.2691 - val_loss: 0.0892 - val_sharpe_ratio: 0.0027\n",
      "Epoch 239/300\n",
      "28/28 [==============================] - 1s 28ms/step - loss: -0.2424 - sharpe_ratio: 0.2708 - val_loss: 0.0669 - val_sharpe_ratio: -0.0105\n",
      "Epoch 240/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2403 - sharpe_ratio: 0.2615 - val_loss: 0.0609 - val_sharpe_ratio: -0.0259\n",
      "Epoch 241/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2357 - sharpe_ratio: 0.2566 - val_loss: 0.0745 - val_sharpe_ratio: -0.0398\n",
      "Epoch 242/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2205 - sharpe_ratio: 0.2489 - val_loss: 0.0580 - val_sharpe_ratio: -0.0125\n",
      "Epoch 243/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2403 - sharpe_ratio: 0.2590 - val_loss: 0.0550 - val_sharpe_ratio: -0.0162\n",
      "Epoch 244/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.1886 - sharpe_ratio: 0.2492 - val_loss: 0.1207 - val_sharpe_ratio: -0.0364\n",
      "Epoch 245/300\n",
      "28/28 [==============================] - 1s 36ms/step - loss: -0.2146 - sharpe_ratio: 0.2580 - val_loss: 0.0458 - val_sharpe_ratio: -0.0205\n",
      "Epoch 246/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2204 - sharpe_ratio: 0.2401 - val_loss: 0.0823 - val_sharpe_ratio: -0.0356\n",
      "Epoch 247/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2009 - sharpe_ratio: 0.2134 - val_loss: 0.0169 - val_sharpe_ratio: 0.0065\n",
      "Epoch 248/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2135 - sharpe_ratio: 0.2392 - val_loss: 0.0590 - val_sharpe_ratio: -0.0151\n",
      "Epoch 249/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.1972 - sharpe_ratio: 0.2129 - val_loss: 0.0528 - val_sharpe_ratio: -0.0089\n",
      "Epoch 250/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2054 - sharpe_ratio: 0.2347 - val_loss: 0.0972 - val_sharpe_ratio: -0.0163\n",
      "Epoch 251/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2188 - sharpe_ratio: 0.2466 - val_loss: 0.0760 - val_sharpe_ratio: -0.0154\n",
      "Epoch 252/300\n",
      "28/28 [==============================] - 1s 36ms/step - loss: -0.1771 - sharpe_ratio: 0.2359 - val_loss: 0.0787 - val_sharpe_ratio: -0.0183\n",
      "Epoch 253/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: -0.1925 - sharpe_ratio: 0.2273 - val_loss: 0.1113 - val_sharpe_ratio: -0.0460\n",
      "Epoch 254/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.1949 - sharpe_ratio: 0.2573 - val_loss: 0.0589 - val_sharpe_ratio: 0.0360\n",
      "Epoch 255/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2201 - sharpe_ratio: 0.2605 - val_loss: 0.0581 - val_sharpe_ratio: -0.0082\n",
      "Epoch 256/300\n",
      "28/28 [==============================] - 1s 35ms/step - loss: -0.1897 - sharpe_ratio: 0.2301 - val_loss: 0.0761 - val_sharpe_ratio: -0.0061\n",
      "Epoch 257/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2076 - sharpe_ratio: 0.2509 - val_loss: 0.0665 - val_sharpe_ratio: -0.0119\n",
      "Epoch 258/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2346 - sharpe_ratio: 0.2640 - val_loss: 0.0660 - val_sharpe_ratio: -0.0119\n",
      "Epoch 259/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2183 - sharpe_ratio: 0.2534 - val_loss: 0.0689 - val_sharpe_ratio: -0.0151\n",
      "Epoch 260/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2130 - sharpe_ratio: 0.2441 - val_loss: -0.0053 - val_sharpe_ratio: 0.0461\n",
      "Epoch 261/300\n",
      "28/28 [==============================] - 1s 35ms/step - loss: -0.2075 - sharpe_ratio: 0.2533 - val_loss: 0.0794 - val_sharpe_ratio: -0.0195\n",
      "Epoch 262/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.1968 - sharpe_ratio: 0.2435 - val_loss: 0.0875 - val_sharpe_ratio: -0.0301\n",
      "Epoch 263/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2199 - sharpe_ratio: 0.2549 - val_loss: 0.0711 - val_sharpe_ratio: 5.1527e-04\n",
      "Epoch 264/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2132 - sharpe_ratio: 0.2589 - val_loss: 0.0685 - val_sharpe_ratio: -0.0186\n",
      "Epoch 265/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2310 - sharpe_ratio: 0.2687 - val_loss: 0.0680 - val_sharpe_ratio: -0.0305\n",
      "Epoch 266/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2363 - sharpe_ratio: 0.2692 - val_loss: 0.0638 - val_sharpe_ratio: -0.0297\n",
      "Epoch 267/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2273 - sharpe_ratio: 0.2506 - val_loss: 0.0576 - val_sharpe_ratio: -0.0223\n",
      "Epoch 268/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2380 - sharpe_ratio: 0.2761 - val_loss: 0.0563 - val_sharpe_ratio: -0.0083\n",
      "Epoch 269/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2376 - sharpe_ratio: 0.2650 - val_loss: 0.0540 - val_sharpe_ratio: -0.0064\n",
      "Epoch 270/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2364 - sharpe_ratio: 0.2482 - val_loss: 0.0900 - val_sharpe_ratio: -0.0581\n",
      "Epoch 271/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2274 - sharpe_ratio: 0.2663 - val_loss: 0.0645 - val_sharpe_ratio: -0.0139\n",
      "Epoch 272/300\n",
      "28/28 [==============================] - 1s 35ms/step - loss: -0.2314 - sharpe_ratio: 0.2690 - val_loss: -0.0250 - val_sharpe_ratio: 0.0872\n",
      "Epoch 273/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: -0.2147 - sharpe_ratio: 0.2478 - val_loss: 0.0769 - val_sharpe_ratio: -0.0250\n",
      "Epoch 274/300\n",
      "28/28 [==============================] - 1s 36ms/step - loss: -0.2307 - sharpe_ratio: 0.2661 - val_loss: 0.0799 - val_sharpe_ratio: -0.0257\n",
      "Epoch 275/300\n",
      "28/28 [==============================] - 1s 39ms/step - loss: -0.2277 - sharpe_ratio: 0.2479 - val_loss: 0.0537 - val_sharpe_ratio: -0.0076\n",
      "Epoch 276/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: -0.2443 - sharpe_ratio: 0.2710 - val_loss: 0.0466 - val_sharpe_ratio: -0.0172\n",
      "Epoch 277/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2294 - sharpe_ratio: 0.2530 - val_loss: 0.0631 - val_sharpe_ratio: -0.0093\n",
      "Epoch 278/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2319 - sharpe_ratio: 0.2637 - val_loss: 0.0876 - val_sharpe_ratio: -0.0216\n",
      "Epoch 279/300\n",
      "28/28 [==============================] - 1s 28ms/step - loss: -0.2281 - sharpe_ratio: 0.2652 - val_loss: 0.0414 - val_sharpe_ratio: -0.0111\n",
      "Epoch 280/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2519 - sharpe_ratio: 0.2745 - val_loss: 0.0597 - val_sharpe_ratio: -0.0218\n",
      "Epoch 281/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2350 - sharpe_ratio: 0.2567 - val_loss: 0.0729 - val_sharpe_ratio: -0.0223\n",
      "Epoch 282/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2431 - sharpe_ratio: 0.2743 - val_loss: 0.0530 - val_sharpe_ratio: -0.0040\n",
      "Epoch 283/300\n",
      "28/28 [==============================] - 1s 29ms/step - loss: -0.2287 - sharpe_ratio: 0.2675 - val_loss: 0.0748 - val_sharpe_ratio: -0.0246\n",
      "Epoch 284/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2285 - sharpe_ratio: 0.2567 - val_loss: 0.0608 - val_sharpe_ratio: -0.0237\n",
      "Epoch 285/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2408 - sharpe_ratio: 0.2679 - val_loss: 0.0522 - val_sharpe_ratio: -0.0303\n",
      "Epoch 286/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2326 - sharpe_ratio: 0.2605 - val_loss: 0.0527 - val_sharpe_ratio: -0.0240\n",
      "Epoch 287/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2385 - sharpe_ratio: 0.2643 - val_loss: 0.0611 - val_sharpe_ratio: -0.0430\n",
      "Epoch 288/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2052 - sharpe_ratio: 0.2400 - val_loss: 0.0910 - val_sharpe_ratio: -0.0394\n",
      "Epoch 289/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.1903 - sharpe_ratio: 0.2474 - val_loss: 0.0829 - val_sharpe_ratio: -0.0253\n",
      "Epoch 290/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2235 - sharpe_ratio: 0.2658 - val_loss: 0.0711 - val_sharpe_ratio: -0.0246\n",
      "Epoch 291/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: -0.2375 - sharpe_ratio: 0.2720 - val_loss: 0.0576 - val_sharpe_ratio: -0.0021\n",
      "Epoch 292/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2177 - sharpe_ratio: 0.2530 - val_loss: 0.0541 - val_sharpe_ratio: -0.0129\n",
      "Epoch 293/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2454 - sharpe_ratio: 0.2752 - val_loss: 0.0315 - val_sharpe_ratio: -0.0060\n",
      "Epoch 294/300\n",
      "28/28 [==============================] - 1s 35ms/step - loss: -0.2377 - sharpe_ratio: 0.2582 - val_loss: 0.0562 - val_sharpe_ratio: -0.0138\n",
      "Epoch 295/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: -0.1940 - sharpe_ratio: 0.2283 - val_loss: 0.0772 - val_sharpe_ratio: -0.0394\n",
      "Epoch 296/300\n",
      "28/28 [==============================] - 1s 40ms/step - loss: -0.2304 - sharpe_ratio: 0.2504 - val_loss: 0.0582 - val_sharpe_ratio: -0.0094\n",
      "Epoch 297/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: -0.2232 - sharpe_ratio: 0.2532 - val_loss: 0.0757 - val_sharpe_ratio: -0.0070\n",
      "Epoch 298/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2185 - sharpe_ratio: 0.2449 - val_loss: 0.0706 - val_sharpe_ratio: -0.0415\n",
      "Epoch 299/300\n",
      "28/28 [==============================] - 1s 30ms/step - loss: -0.2339 - sharpe_ratio: 0.2553 - val_loss: 0.0514 - val_sharpe_ratio: -0.0125\n",
      "Epoch 300/300\n",
      "28/28 [==============================] - 1s 31ms/step - loss: -0.2375 - sharpe_ratio: 0.2683 - val_loss: 0.0781 - val_sharpe_ratio: -0.0182\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "There are total 11 samples to predict\n",
      "Sample 0 : [ MARUTI.NS ]\n",
      "Sample 1 : [ COALINDIA.NS MARUTI.NS ]\n",
      "Sample 2 : [ COALINDIA.NS MARUTI.NS ]\n",
      "Sample 3 : [ COALINDIA.NS MARUTI.NS ]\n",
      "Sample 4 : [ COALINDIA.NS MARUTI.NS ]\n",
      "Sample 5 : [ COALINDIA.NS MARUTI.NS SUNPHARMA.NS ]\n",
      "Sample 6 : [ MARUTI.NS SUNPHARMA.NS ]\n",
      "Sample 7 : [ MARUTI.NS SUNPHARMA.NS ]\n",
      "Sample 8 : [ MARUTI.NS SUNPHARMA.NS ]\n",
      "Sample 9 : [ MARUTI.NS SUNPHARMA.NS ]\n",
      "Sample 10 : [ DRREDDY.NS INFY.NS MARUTI.NS ]\n",
      "Sharpe ratio of this portfolio: [1.4757370623772903, -0.9122362179486752, -0.5507613518524669, 0.233563098259921, 0.3558325617329719, -0.17873803125604532, -0.5020220508633256, -0.4584026242023757, -0.22319460336484886, -0.1974930217595095, 0.08601037156973487]\n",
      "write file log at C:/Users/yv67/Documents/12FundsHK_ToShare/deeplearningdata/logs/GRU\\log_653.txt\n",
      "Epoch 1/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1407 - sharpe_ratio: 0.1775 - val_loss: -0.1340 - val_sharpe_ratio: 0.1784\n",
      "Epoch 2/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1544 - sharpe_ratio: 0.1896 - val_loss: -0.0737 - val_sharpe_ratio: 0.0931\n",
      "Epoch 3/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1324 - sharpe_ratio: 0.1777 - val_loss: 0.0314 - val_sharpe_ratio: 0.0355\n",
      "Epoch 4/300\n",
      "41/41 [==============================] - 1s 35ms/step - loss: -0.1367 - sharpe_ratio: 0.1878 - val_loss: -0.0870 - val_sharpe_ratio: 0.1390\n",
      "Epoch 5/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1631 - sharpe_ratio: 0.1990 - val_loss: -0.1034 - val_sharpe_ratio: 0.1619\n",
      "Epoch 6/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1670 - sharpe_ratio: 0.1897 - val_loss: -0.0082 - val_sharpe_ratio: 0.0355\n",
      "Epoch 7/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1457 - sharpe_ratio: 0.1833 - val_loss: -0.0569 - val_sharpe_ratio: 0.1005\n",
      "Epoch 8/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1464 - sharpe_ratio: 0.1801 - val_loss: -0.0320 - val_sharpe_ratio: 0.0455\n",
      "Epoch 9/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1250 - sharpe_ratio: 0.1651 - val_loss: -0.0571 - val_sharpe_ratio: 0.1120\n",
      "Epoch 10/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1481 - sharpe_ratio: 0.1832 - val_loss: -0.1402 - val_sharpe_ratio: 0.1784\n",
      "Epoch 11/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1334 - sharpe_ratio: 0.1730 - val_loss: -0.0649 - val_sharpe_ratio: 0.1441\n",
      "Epoch 12/300\n",
      "41/41 [==============================] - 1s 36ms/step - loss: -0.1393 - sharpe_ratio: 0.1856 - val_loss: -0.0184 - val_sharpe_ratio: 0.0889\n",
      "Epoch 13/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1626 - sharpe_ratio: 0.2004 - val_loss: -0.0589 - val_sharpe_ratio: 0.0950\n",
      "Epoch 14/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1609 - sharpe_ratio: 0.1923 - val_loss: -0.0018 - val_sharpe_ratio: 0.0071\n",
      "Epoch 15/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1577 - sharpe_ratio: 0.1913 - val_loss: -0.0227 - val_sharpe_ratio: 0.0490\n",
      "Epoch 16/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1499 - sharpe_ratio: 0.1771 - val_loss: -0.0339 - val_sharpe_ratio: 0.0897\n",
      "Epoch 17/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1734 - sharpe_ratio: 0.2034 - val_loss: -0.0795 - val_sharpe_ratio: 0.1245\n",
      "Epoch 18/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1669 - sharpe_ratio: 0.1957 - val_loss: -0.0536 - val_sharpe_ratio: 0.0857\n",
      "Epoch 19/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1630 - sharpe_ratio: 0.1940 - val_loss: -0.0301 - val_sharpe_ratio: 0.0692\n",
      "Epoch 20/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1546 - sharpe_ratio: 0.1905 - val_loss: -0.1169 - val_sharpe_ratio: 0.1619\n",
      "Epoch 21/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1588 - sharpe_ratio: 0.1935 - val_loss: 0.0121 - val_sharpe_ratio: 0.0303\n",
      "Epoch 22/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1662 - sharpe_ratio: 0.1993 - val_loss: -0.0595 - val_sharpe_ratio: 0.1217\n",
      "Epoch 23/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1428 - sharpe_ratio: 0.1793 - val_loss: -0.0486 - val_sharpe_ratio: 0.1334\n",
      "Epoch 24/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1113 - sharpe_ratio: 0.1667 - val_loss: -0.0064 - val_sharpe_ratio: 0.0453\n",
      "Epoch 25/300\n",
      "41/41 [==============================] - 1s 36ms/step - loss: -0.1111 - sharpe_ratio: 0.1695 - val_loss: -0.0541 - val_sharpe_ratio: 0.0960\n",
      "Epoch 26/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1282 - sharpe_ratio: 0.1759 - val_loss: -0.0141 - val_sharpe_ratio: 0.0647\n",
      "Epoch 27/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1445 - sharpe_ratio: 0.1900 - val_loss: -0.0371 - val_sharpe_ratio: 0.0971\n",
      "Epoch 28/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1313 - sharpe_ratio: 0.1769 - val_loss: -0.0367 - val_sharpe_ratio: 0.0821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/300\n",
      "41/41 [==============================] - 2s 39ms/step - loss: -0.1422 - sharpe_ratio: 0.1881 - val_loss: -0.0485 - val_sharpe_ratio: 0.0977\n",
      "Epoch 30/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1347 - sharpe_ratio: 0.1886 - val_loss: -0.0502 - val_sharpe_ratio: 0.0858\n",
      "Epoch 31/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1563 - sharpe_ratio: 0.1950 - val_loss: 8.8919e-04 - val_sharpe_ratio: 0.0303\n",
      "Epoch 32/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1425 - sharpe_ratio: 0.1887 - val_loss: -0.0948 - val_sharpe_ratio: 0.1591\n",
      "Epoch 33/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1244 - sharpe_ratio: 0.1825 - val_loss: -0.0056 - val_sharpe_ratio: 0.0501\n",
      "Epoch 34/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1416 - sharpe_ratio: 0.1827 - val_loss: -0.0462 - val_sharpe_ratio: 0.0809\n",
      "Epoch 35/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1073 - sharpe_ratio: 0.1609 - val_loss: -0.0751 - val_sharpe_ratio: 0.1723\n",
      "Epoch 36/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1018 - sharpe_ratio: 0.1784 - val_loss: 0.0514 - val_sharpe_ratio: 0.0848\n",
      "Epoch 37/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1081 - sharpe_ratio: 0.1783 - val_loss: -0.0639 - val_sharpe_ratio: 0.0969\n",
      "Epoch 38/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1365 - sharpe_ratio: 0.1858 - val_loss: -0.0908 - val_sharpe_ratio: 0.1224\n",
      "Epoch 39/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1649 - sharpe_ratio: 0.1967 - val_loss: -0.0029 - val_sharpe_ratio: 0.0303\n",
      "Epoch 40/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1598 - sharpe_ratio: 0.1921 - val_loss: -0.0661 - val_sharpe_ratio: 0.0917\n",
      "Epoch 41/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1632 - sharpe_ratio: 0.1935 - val_loss: -0.0771 - val_sharpe_ratio: 0.1129\n",
      "Epoch 42/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1696 - sharpe_ratio: 0.1893 - val_loss: -0.0353 - val_sharpe_ratio: 0.0624\n",
      "Epoch 43/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1664 - sharpe_ratio: 0.1930 - val_loss: 0.0096 - val_sharpe_ratio: 0.0231\n",
      "Epoch 44/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1231 - sharpe_ratio: 0.1864 - val_loss: 0.0096 - val_sharpe_ratio: 0.0608\n",
      "Epoch 45/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1440 - sharpe_ratio: 0.1912 - val_loss: -0.0165 - val_sharpe_ratio: 0.0433\n",
      "Epoch 46/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1539 - sharpe_ratio: 0.1897 - val_loss: -0.0742 - val_sharpe_ratio: 0.0948\n",
      "Epoch 47/300\n",
      "41/41 [==============================] - 1s 28ms/step - loss: -0.1373 - sharpe_ratio: 0.1811 - val_loss: -0.0225 - val_sharpe_ratio: 0.0964\n",
      "Epoch 48/300\n",
      "41/41 [==============================] - 1s 28ms/step - loss: -0.1261 - sharpe_ratio: 0.1793 - val_loss: -0.0157 - val_sharpe_ratio: 0.0362\n",
      "Epoch 49/300\n",
      "41/41 [==============================] - 1s 27ms/step - loss: -0.1526 - sharpe_ratio: 0.1879 - val_loss: -0.0541 - val_sharpe_ratio: 0.0959\n",
      "Epoch 50/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1732 - sharpe_ratio: 0.1963 - val_loss: -0.0672 - val_sharpe_ratio: 0.1202\n",
      "Epoch 51/300\n",
      "41/41 [==============================] - 1s 28ms/step - loss: -0.1468 - sharpe_ratio: 0.1925 - val_loss: -0.0343 - val_sharpe_ratio: 0.0884\n",
      "Epoch 52/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1334 - sharpe_ratio: 0.1892 - val_loss: -0.0610 - val_sharpe_ratio: 0.1334\n",
      "Epoch 53/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1577 - sharpe_ratio: 0.1931 - val_loss: -0.0324 - val_sharpe_ratio: 0.1063\n",
      "Epoch 54/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1422 - sharpe_ratio: 0.1916 - val_loss: -0.0554 - val_sharpe_ratio: 0.0686\n",
      "Epoch 55/300\n",
      "41/41 [==============================] - 1s 28ms/step - loss: -0.1535 - sharpe_ratio: 0.1887 - val_loss: -0.0485 - val_sharpe_ratio: 0.0615\n",
      "Epoch 56/300\n",
      "41/41 [==============================] - 2s 38ms/step - loss: -0.1304 - sharpe_ratio: 0.1832 - val_loss: -0.1189 - val_sharpe_ratio: 0.1609\n",
      "Epoch 57/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1378 - sharpe_ratio: 0.1844 - val_loss: -0.1079 - val_sharpe_ratio: 0.1356\n",
      "Epoch 58/300\n",
      "41/41 [==============================] - 1s 35ms/step - loss: -0.1525 - sharpe_ratio: 0.1922 - val_loss: -0.0519 - val_sharpe_ratio: 0.0850\n",
      "Epoch 59/300\n",
      "41/41 [==============================] - 1s 36ms/step - loss: -0.1286 - sharpe_ratio: 0.1641 - val_loss: -0.0502 - val_sharpe_ratio: 0.1271\n",
      "Epoch 60/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1300 - sharpe_ratio: 0.1776 - val_loss: -0.0117 - val_sharpe_ratio: 0.0310\n",
      "Epoch 61/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1395 - sharpe_ratio: 0.1819 - val_loss: -0.0047 - val_sharpe_ratio: 0.0576\n",
      "Epoch 62/300\n",
      "41/41 [==============================] - 1s 28ms/step - loss: -0.1258 - sharpe_ratio: 0.1837 - val_loss: 0.0527 - val_sharpe_ratio: 0.0278\n",
      "Epoch 63/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1323 - sharpe_ratio: 0.1850 - val_loss: -0.0070 - val_sharpe_ratio: 0.0441\n",
      "Epoch 64/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1571 - sharpe_ratio: 0.1953 - val_loss: -0.0393 - val_sharpe_ratio: 0.0912\n",
      "Epoch 65/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1513 - sharpe_ratio: 0.1881 - val_loss: -0.1008 - val_sharpe_ratio: 0.1126\n",
      "Epoch 66/300\n",
      "41/41 [==============================] - 1s 35ms/step - loss: -0.1344 - sharpe_ratio: 0.1824 - val_loss: 0.0027 - val_sharpe_ratio: 0.0800\n",
      "Epoch 67/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1401 - sharpe_ratio: 0.1906 - val_loss: -0.1048 - val_sharpe_ratio: 0.1329\n",
      "Epoch 68/300\n",
      "41/41 [==============================] - 2s 38ms/step - loss: -0.1498 - sharpe_ratio: 0.1833 - val_loss: -0.0482 - val_sharpe_ratio: 0.0934\n",
      "Epoch 69/300\n",
      "41/41 [==============================] - 2s 38ms/step - loss: -0.1451 - sharpe_ratio: 0.1794 - val_loss: -0.0911 - val_sharpe_ratio: 0.1413\n",
      "Epoch 70/300\n",
      "41/41 [==============================] - 1s 36ms/step - loss: -0.1504 - sharpe_ratio: 0.1943 - val_loss: 0.0286 - val_sharpe_ratio: 0.0358\n",
      "Epoch 71/300\n",
      "41/41 [==============================] - 2s 38ms/step - loss: -0.1480 - sharpe_ratio: 0.1927 - val_loss: 0.0388 - val_sharpe_ratio: 0.0303\n",
      "Epoch 72/300\n",
      "41/41 [==============================] - 2s 37ms/step - loss: -0.1394 - sharpe_ratio: 0.1832 - val_loss: -0.0190 - val_sharpe_ratio: 0.0546\n",
      "Epoch 73/300\n",
      "41/41 [==============================] - 2s 38ms/step - loss: -0.1427 - sharpe_ratio: 0.1915 - val_loss: -0.0708 - val_sharpe_ratio: 0.1182\n",
      "Epoch 74/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1552 - sharpe_ratio: 0.1945 - val_loss: -0.0436 - val_sharpe_ratio: 0.0815\n",
      "Epoch 75/300\n",
      "41/41 [==============================] - 1s 36ms/step - loss: -0.1585 - sharpe_ratio: 0.1967 - val_loss: -0.0348 - val_sharpe_ratio: 0.0996\n",
      "Epoch 76/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1451 - sharpe_ratio: 0.1891 - val_loss: 0.0156 - val_sharpe_ratio: 0.0297\n",
      "Epoch 77/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1382 - sharpe_ratio: 0.1877 - val_loss: -0.0102 - val_sharpe_ratio: 0.0580\n",
      "Epoch 78/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1625 - sharpe_ratio: 0.1929 - val_loss: -0.0706 - val_sharpe_ratio: 0.1215\n",
      "Epoch 79/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1492 - sharpe_ratio: 0.1930 - val_loss: -0.0487 - val_sharpe_ratio: 0.0819\n",
      "Epoch 80/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1454 - sharpe_ratio: 0.1823 - val_loss: -0.1307 - val_sharpe_ratio: 0.1717\n",
      "Epoch 81/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1189 - sharpe_ratio: 0.1706 - val_loss: -0.0401 - val_sharpe_ratio: 0.0924\n",
      "Epoch 82/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1093 - sharpe_ratio: 0.1570 - val_loss: -0.0569 - val_sharpe_ratio: 0.1228\n",
      "Epoch 83/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1211 - sharpe_ratio: 0.1756 - val_loss: -0.0275 - val_sharpe_ratio: 0.0642\n",
      "Epoch 84/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1480 - sharpe_ratio: 0.1883 - val_loss: -0.0988 - val_sharpe_ratio: 0.1282\n",
      "Epoch 85/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1419 - sharpe_ratio: 0.1861 - val_loss: 0.0205 - val_sharpe_ratio: 0.0423\n",
      "Epoch 86/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1588 - sharpe_ratio: 0.2049 - val_loss: -0.0853 - val_sharpe_ratio: 0.1286\n",
      "Epoch 87/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1411 - sharpe_ratio: 0.1882 - val_loss: -0.0940 - val_sharpe_ratio: 0.1390\n",
      "Epoch 88/300\n",
      "41/41 [==============================] - 2s 37ms/step - loss: -0.1651 - sharpe_ratio: 0.1975 - val_loss: -0.1450 - val_sharpe_ratio: 0.1791\n",
      "Epoch 89/300\n",
      "41/41 [==============================] - 2s 37ms/step - loss: -0.1378 - sharpe_ratio: 0.1830 - val_loss: -0.0464 - val_sharpe_ratio: 0.1001\n",
      "Epoch 90/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1509 - sharpe_ratio: 0.1794 - val_loss: -0.0307 - val_sharpe_ratio: 0.0761\n",
      "Epoch 91/300\n",
      "41/41 [==============================] - 1s 36ms/step - loss: -0.1366 - sharpe_ratio: 0.1774 - val_loss: -0.0355 - val_sharpe_ratio: 0.0730\n",
      "Epoch 92/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1502 - sharpe_ratio: 0.1889 - val_loss: -0.0331 - val_sharpe_ratio: 0.0604\n",
      "Epoch 93/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1558 - sharpe_ratio: 0.1914 - val_loss: -0.0522 - val_sharpe_ratio: 0.0974\n",
      "Epoch 94/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1393 - sharpe_ratio: 0.1885 - val_loss: -0.0401 - val_sharpe_ratio: 0.0925\n",
      "Epoch 95/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1626 - sharpe_ratio: 0.1939 - val_loss: -0.0568 - val_sharpe_ratio: 0.0754\n",
      "Epoch 96/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1665 - sharpe_ratio: 0.1904 - val_loss: -0.0733 - val_sharpe_ratio: 0.1279\n",
      "Epoch 97/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1551 - sharpe_ratio: 0.2022 - val_loss: -0.0228 - val_sharpe_ratio: 0.0814\n",
      "Epoch 98/300\n",
      "41/41 [==============================] - 1s 35ms/step - loss: -0.1675 - sharpe_ratio: 0.1971 - val_loss: -0.0924 - val_sharpe_ratio: 0.1240\n",
      "Epoch 99/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1431 - sharpe_ratio: 0.1883 - val_loss: -0.0094 - val_sharpe_ratio: 0.0303\n",
      "Epoch 100/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1439 - sharpe_ratio: 0.1820 - val_loss: -0.0550 - val_sharpe_ratio: 0.0945\n",
      "Epoch 101/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1466 - sharpe_ratio: 0.1923 - val_loss: -0.0660 - val_sharpe_ratio: 0.1144\n",
      "Epoch 102/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1742 - sharpe_ratio: 0.2069 - val_loss: -0.1299 - val_sharpe_ratio: 0.1810\n",
      "Epoch 103/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1328 - sharpe_ratio: 0.1918 - val_loss: -0.0146 - val_sharpe_ratio: 0.0489\n",
      "Epoch 104/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1538 - sharpe_ratio: 0.1955 - val_loss: -0.0485 - val_sharpe_ratio: 0.1114\n",
      "Epoch 105/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1516 - sharpe_ratio: 0.1907 - val_loss: -0.0318 - val_sharpe_ratio: 0.0485\n",
      "Epoch 106/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1353 - sharpe_ratio: 0.1749 - val_loss: 0.0227 - val_sharpe_ratio: 0.0357\n",
      "Epoch 107/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1451 - sharpe_ratio: 0.1915 - val_loss: -0.0553 - val_sharpe_ratio: 0.1139\n",
      "Epoch 108/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1555 - sharpe_ratio: 0.1971 - val_loss: 0.0090 - val_sharpe_ratio: 0.0325\n",
      "Epoch 109/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1533 - sharpe_ratio: 0.1955 - val_loss: -0.0586 - val_sharpe_ratio: 0.1108\n",
      "Epoch 110/300\n",
      "41/41 [==============================] - 1s 28ms/step - loss: -0.1489 - sharpe_ratio: 0.1964 - val_loss: 0.0162 - val_sharpe_ratio: 0.0303\n",
      "Epoch 111/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1383 - sharpe_ratio: 0.1887 - val_loss: -0.0351 - val_sharpe_ratio: 0.0962\n",
      "Epoch 112/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1376 - sharpe_ratio: 0.1876 - val_loss: -0.0196 - val_sharpe_ratio: 0.0523\n",
      "Epoch 113/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1364 - sharpe_ratio: 0.1918 - val_loss: -0.0338 - val_sharpe_ratio: 0.0712\n",
      "Epoch 114/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1384 - sharpe_ratio: 0.1902 - val_loss: -0.0380 - val_sharpe_ratio: 0.0755\n",
      "Epoch 115/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1373 - sharpe_ratio: 0.1891 - val_loss: -0.0439 - val_sharpe_ratio: 0.1037\n",
      "Epoch 116/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1221 - sharpe_ratio: 0.1765 - val_loss: -0.0740 - val_sharpe_ratio: 0.1432\n",
      "Epoch 117/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1307 - sharpe_ratio: 0.1891 - val_loss: -0.0487 - val_sharpe_ratio: 0.0982\n",
      "Epoch 118/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1483 - sharpe_ratio: 0.1943 - val_loss: -0.0510 - val_sharpe_ratio: 0.0768\n",
      "Epoch 119/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1263 - sharpe_ratio: 0.1938 - val_loss: 0.0059 - val_sharpe_ratio: 0.0457\n",
      "Epoch 120/300\n",
      "41/41 [==============================] - 1s 28ms/step - loss: -0.1396 - sharpe_ratio: 0.1852 - val_loss: 0.0086 - val_sharpe_ratio: 0.0452\n",
      "Epoch 121/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1414 - sharpe_ratio: 0.1888 - val_loss: -0.0412 - val_sharpe_ratio: 0.1098\n",
      "Epoch 122/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1468 - sharpe_ratio: 0.1893 - val_loss: -0.0722 - val_sharpe_ratio: 0.1057\n",
      "Epoch 123/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1620 - sharpe_ratio: 0.1961 - val_loss: -0.0316 - val_sharpe_ratio: 0.0888\n",
      "Epoch 124/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1426 - sharpe_ratio: 0.1816 - val_loss: -0.0024 - val_sharpe_ratio: 0.0368\n",
      "Epoch 125/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1572 - sharpe_ratio: 0.1905 - val_loss: -0.0715 - val_sharpe_ratio: 0.1075\n",
      "Epoch 126/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1271 - sharpe_ratio: 0.1708 - val_loss: -0.0240 - val_sharpe_ratio: 0.0675\n",
      "Epoch 127/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1607 - sharpe_ratio: 0.1956 - val_loss: -0.0320 - val_sharpe_ratio: 0.0537\n",
      "Epoch 128/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1655 - sharpe_ratio: 0.1991 - val_loss: -0.0403 - val_sharpe_ratio: 0.0668\n",
      "Epoch 129/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1442 - sharpe_ratio: 0.1843 - val_loss: -0.0564 - val_sharpe_ratio: 0.1214\n",
      "Epoch 130/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1462 - sharpe_ratio: 0.1908 - val_loss: -0.0957 - val_sharpe_ratio: 0.1507\n",
      "Epoch 131/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1406 - sharpe_ratio: 0.1870 - val_loss: -0.0326 - val_sharpe_ratio: 0.0925\n",
      "Epoch 132/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1701 - sharpe_ratio: 0.2001 - val_loss: -0.0536 - val_sharpe_ratio: 0.0893\n",
      "Epoch 133/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1595 - sharpe_ratio: 0.1978 - val_loss: -0.0566 - val_sharpe_ratio: 0.0958\n",
      "Epoch 134/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1626 - sharpe_ratio: 0.1960 - val_loss: -0.0442 - val_sharpe_ratio: 0.0543\n",
      "Epoch 135/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1644 - sharpe_ratio: 0.2009 - val_loss: -0.0894 - val_sharpe_ratio: 0.1362\n",
      "Epoch 136/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1608 - sharpe_ratio: 0.1969 - val_loss: -0.0216 - val_sharpe_ratio: 0.0620\n",
      "Epoch 137/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1582 - sharpe_ratio: 0.1918 - val_loss: -0.0555 - val_sharpe_ratio: 0.0758\n",
      "Epoch 138/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1521 - sharpe_ratio: 0.1879 - val_loss: -0.0216 - val_sharpe_ratio: 0.0618\n",
      "Epoch 139/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1256 - sharpe_ratio: 0.1858 - val_loss: -0.0433 - val_sharpe_ratio: 0.0906\n",
      "Epoch 140/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1491 - sharpe_ratio: 0.1865 - val_loss: -0.0258 - val_sharpe_ratio: 0.0686\n",
      "Epoch 141/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1276 - sharpe_ratio: 0.1758 - val_loss: -0.0256 - val_sharpe_ratio: 0.1003\n",
      "Epoch 142/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1297 - sharpe_ratio: 0.1785 - val_loss: -0.0133 - val_sharpe_ratio: 0.0492\n",
      "Epoch 143/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1450 - sharpe_ratio: 0.1822 - val_loss: -0.0168 - val_sharpe_ratio: 0.0534\n",
      "Epoch 144/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1259 - sharpe_ratio: 0.1802 - val_loss: 0.0124 - val_sharpe_ratio: 0.0580\n",
      "Epoch 145/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1351 - sharpe_ratio: 0.1832 - val_loss: -0.0191 - val_sharpe_ratio: 0.0601\n",
      "Epoch 146/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1583 - sharpe_ratio: 0.2009 - val_loss: -0.1413 - val_sharpe_ratio: 0.1938\n",
      "Epoch 147/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1151 - sharpe_ratio: 0.1755 - val_loss: -0.0398 - val_sharpe_ratio: 0.1001\n",
      "Epoch 148/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1541 - sharpe_ratio: 0.1980 - val_loss: -0.0133 - val_sharpe_ratio: 0.0504\n",
      "Epoch 149/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1248 - sharpe_ratio: 0.1837 - val_loss: 0.0128 - val_sharpe_ratio: 0.0303\n",
      "Epoch 150/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1595 - sharpe_ratio: 0.1958 - val_loss: -0.0155 - val_sharpe_ratio: 0.0264\n",
      "Epoch 151/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1509 - sharpe_ratio: 0.1907 - val_loss: -0.1053 - val_sharpe_ratio: 0.1321\n",
      "Epoch 152/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1575 - sharpe_ratio: 0.1928 - val_loss: -0.0408 - val_sharpe_ratio: 0.0531\n",
      "Epoch 153/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1762 - sharpe_ratio: 0.2031 - val_loss: -0.0278 - val_sharpe_ratio: 0.0546\n",
      "Epoch 154/300\n",
      "41/41 [==============================] - 1s 28ms/step - loss: -0.1606 - sharpe_ratio: 0.1926 - val_loss: -0.0504 - val_sharpe_ratio: 0.0836\n",
      "Epoch 155/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1529 - sharpe_ratio: 0.1860 - val_loss: -0.0270 - val_sharpe_ratio: 0.0611\n",
      "Epoch 156/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1611 - sharpe_ratio: 0.2005 - val_loss: -0.0529 - val_sharpe_ratio: 0.0907\n",
      "Epoch 157/300\n",
      "41/41 [==============================] - 2s 37ms/step - loss: -0.1388 - sharpe_ratio: 0.1842 - val_loss: -0.0349 - val_sharpe_ratio: 0.0961\n",
      "Epoch 158/300\n",
      "41/41 [==============================] - 1s 36ms/step - loss: -0.1647 - sharpe_ratio: 0.2007 - val_loss: -0.0622 - val_sharpe_ratio: 0.1349\n",
      "Epoch 159/300\n",
      "41/41 [==============================] - 2s 39ms/step - loss: -0.1390 - sharpe_ratio: 0.1738 - val_loss: 0.0113 - val_sharpe_ratio: 0.0297\n",
      "Epoch 160/300\n",
      "41/41 [==============================] - 2s 37ms/step - loss: -0.1563 - sharpe_ratio: 0.1923 - val_loss: -0.1085 - val_sharpe_ratio: 0.1297\n",
      "Epoch 161/300\n",
      "41/41 [==============================] - 2s 38ms/step - loss: -0.1548 - sharpe_ratio: 0.1892 - val_loss: -0.1431 - val_sharpe_ratio: 0.1912\n",
      "Epoch 162/300\n",
      "41/41 [==============================] - 1s 35ms/step - loss: -0.1413 - sharpe_ratio: 0.1794 - val_loss: -0.0087 - val_sharpe_ratio: 0.0517\n",
      "Epoch 163/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1579 - sharpe_ratio: 0.1890 - val_loss: 0.0134 - val_sharpe_ratio: 0.0303\n",
      "Epoch 164/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1706 - sharpe_ratio: 0.1938 - val_loss: -0.0530 - val_sharpe_ratio: 0.0706\n",
      "Epoch 165/300\n",
      "41/41 [==============================] - 1s 36ms/step - loss: -0.1578 - sharpe_ratio: 0.1888 - val_loss: -0.1002 - val_sharpe_ratio: 0.1456\n",
      "Epoch 166/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1368 - sharpe_ratio: 0.1868 - val_loss: -0.0067 - val_sharpe_ratio: 0.0688\n",
      "Epoch 167/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.0871 - sharpe_ratio: 0.1836 - val_loss: 0.0298 - val_sharpe_ratio: 0.0670\n",
      "Epoch 168/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1359 - sharpe_ratio: 0.1817 - val_loss: -0.0349 - val_sharpe_ratio: 0.0876\n",
      "Epoch 169/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.0946 - sharpe_ratio: 0.1775 - val_loss: 0.0191 - val_sharpe_ratio: 0.0649\n",
      "Epoch 170/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1061 - sharpe_ratio: 0.1850 - val_loss: -0.0153 - val_sharpe_ratio: 0.1030\n",
      "Epoch 171/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1451 - sharpe_ratio: 0.2000 - val_loss: -0.0468 - val_sharpe_ratio: 0.1074\n",
      "Epoch 172/300\n",
      "41/41 [==============================] - 1s 37ms/step - loss: -0.1394 - sharpe_ratio: 0.1940 - val_loss: 0.0410 - val_sharpe_ratio: 0.0375\n",
      "Epoch 173/300\n",
      "41/41 [==============================] - 1s 35ms/step - loss: -0.1540 - sharpe_ratio: 0.1970 - val_loss: -0.0609 - val_sharpe_ratio: 0.0673\n",
      "Epoch 174/300\n",
      "41/41 [==============================] - 1s 36ms/step - loss: -0.1489 - sharpe_ratio: 0.1831 - val_loss: -0.0435 - val_sharpe_ratio: 0.0887\n",
      "Epoch 175/300\n",
      "41/41 [==============================] - 1s 36ms/step - loss: -0.1377 - sharpe_ratio: 0.1856 - val_loss: 0.0080 - val_sharpe_ratio: 0.0270\n",
      "Epoch 176/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1321 - sharpe_ratio: 0.1911 - val_loss: -0.0468 - val_sharpe_ratio: 0.0938\n",
      "Epoch 177/300\n",
      "41/41 [==============================] - 1s 36ms/step - loss: -0.1478 - sharpe_ratio: 0.1916 - val_loss: -0.0354 - val_sharpe_ratio: 0.0772\n",
      "Epoch 178/300\n",
      "41/41 [==============================] - 2s 37ms/step - loss: -0.1558 - sharpe_ratio: 0.1971 - val_loss: -0.0179 - val_sharpe_ratio: 0.0517\n",
      "Epoch 179/300\n",
      "41/41 [==============================] - 2s 38ms/step - loss: -0.1584 - sharpe_ratio: 0.1916 - val_loss: -0.0409 - val_sharpe_ratio: 0.0680\n",
      "Epoch 180/300\n",
      "41/41 [==============================] - 2s 37ms/step - loss: -0.1609 - sharpe_ratio: 0.1922 - val_loss: -0.0196 - val_sharpe_ratio: 0.0513\n",
      "Epoch 181/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1609 - sharpe_ratio: 0.1945 - val_loss: -0.0283 - val_sharpe_ratio: 0.0603\n",
      "Epoch 182/300\n",
      "41/41 [==============================] - 1s 35ms/step - loss: -0.1583 - sharpe_ratio: 0.1975 - val_loss: -0.0510 - val_sharpe_ratio: 0.0807\n",
      "Epoch 183/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1344 - sharpe_ratio: 0.1847 - val_loss: -0.0097 - val_sharpe_ratio: 0.0643\n",
      "Epoch 184/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1577 - sharpe_ratio: 0.1976 - val_loss: 3.5537e-04 - val_sharpe_ratio: 0.0303\n",
      "Epoch 185/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1384 - sharpe_ratio: 0.1754 - val_loss: -0.0162 - val_sharpe_ratio: 0.0702\n",
      "Epoch 186/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1432 - sharpe_ratio: 0.1852 - val_loss: -0.0717 - val_sharpe_ratio: 0.1117\n",
      "Epoch 187/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1449 - sharpe_ratio: 0.1833 - val_loss: -0.0881 - val_sharpe_ratio: 0.1264\n",
      "Epoch 188/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1564 - sharpe_ratio: 0.1962 - val_loss: -0.0217 - val_sharpe_ratio: 0.0602\n",
      "Epoch 189/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1581 - sharpe_ratio: 0.1919 - val_loss: -0.0129 - val_sharpe_ratio: 0.0617\n",
      "Epoch 190/300\n",
      "41/41 [==============================] - 1s 35ms/step - loss: -0.1596 - sharpe_ratio: 0.1952 - val_loss: 0.0240 - val_sharpe_ratio: 0.0038\n",
      "Epoch 191/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1483 - sharpe_ratio: 0.1911 - val_loss: -0.0228 - val_sharpe_ratio: 0.0741\n",
      "Epoch 192/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1516 - sharpe_ratio: 0.1910 - val_loss: -0.0267 - val_sharpe_ratio: 0.0650\n",
      "Epoch 193/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1367 - sharpe_ratio: 0.1764 - val_loss: -0.0366 - val_sharpe_ratio: 0.0687\n",
      "Epoch 194/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1514 - sharpe_ratio: 0.1899 - val_loss: -0.0019 - val_sharpe_ratio: 0.0481\n",
      "Epoch 195/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1409 - sharpe_ratio: 0.1815 - val_loss: -0.0736 - val_sharpe_ratio: 0.1250\n",
      "Epoch 196/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1521 - sharpe_ratio: 0.1878 - val_loss: -0.0214 - val_sharpe_ratio: 0.0560\n",
      "Epoch 197/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1114 - sharpe_ratio: 0.1881 - val_loss: 0.0218 - val_sharpe_ratio: 0.0423\n",
      "Epoch 198/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1339 - sharpe_ratio: 0.1755 - val_loss: 0.0132 - val_sharpe_ratio: 0.0535\n",
      "Epoch 199/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1336 - sharpe_ratio: 0.1866 - val_loss: -0.0653 - val_sharpe_ratio: 0.1052\n",
      "Epoch 200/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1548 - sharpe_ratio: 0.1963 - val_loss: 0.0041 - val_sharpe_ratio: 0.0341\n",
      "Epoch 201/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1268 - sharpe_ratio: 0.1889 - val_loss: -0.0322 - val_sharpe_ratio: 0.0724\n",
      "Epoch 202/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1529 - sharpe_ratio: 0.1821 - val_loss: -0.0254 - val_sharpe_ratio: 0.0603\n",
      "Epoch 203/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1638 - sharpe_ratio: 0.1951 - val_loss: -0.0609 - val_sharpe_ratio: 0.1033\n",
      "Epoch 204/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1709 - sharpe_ratio: 0.1983 - val_loss: -0.0377 - val_sharpe_ratio: 0.0801\n",
      "Epoch 205/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1651 - sharpe_ratio: 0.2010 - val_loss: -0.0352 - val_sharpe_ratio: 0.0795\n",
      "Epoch 206/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1462 - sharpe_ratio: 0.1876 - val_loss: -0.0559 - val_sharpe_ratio: 0.1141\n",
      "Epoch 207/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1117 - sharpe_ratio: 0.1819 - val_loss: -0.0378 - val_sharpe_ratio: 0.1209\n",
      "Epoch 208/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1537 - sharpe_ratio: 0.1941 - val_loss: -0.0693 - val_sharpe_ratio: 0.1054\n",
      "Epoch 209/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1350 - sharpe_ratio: 0.1782 - val_loss: -0.0211 - val_sharpe_ratio: 0.0805\n",
      "Epoch 210/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1300 - sharpe_ratio: 0.1775 - val_loss: -0.0134 - val_sharpe_ratio: 0.0477\n",
      "Epoch 211/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1507 - sharpe_ratio: 0.1879 - val_loss: -0.0541 - val_sharpe_ratio: 0.0932\n",
      "Epoch 212/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1513 - sharpe_ratio: 0.1916 - val_loss: -0.0039 - val_sharpe_ratio: 0.0647\n",
      "Epoch 213/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1106 - sharpe_ratio: 0.1809 - val_loss: -0.0547 - val_sharpe_ratio: 0.0941\n",
      "Epoch 214/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1305 - sharpe_ratio: 0.1789 - val_loss: -0.0430 - val_sharpe_ratio: 0.0872\n",
      "Epoch 215/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1267 - sharpe_ratio: 0.1835 - val_loss: -0.0298 - val_sharpe_ratio: 0.0765\n",
      "Epoch 216/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1513 - sharpe_ratio: 0.1908 - val_loss: -0.0375 - val_sharpe_ratio: 0.0749\n",
      "Epoch 217/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1503 - sharpe_ratio: 0.1904 - val_loss: -0.0276 - val_sharpe_ratio: 0.0607\n",
      "Epoch 218/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1483 - sharpe_ratio: 0.1918 - val_loss: -0.0460 - val_sharpe_ratio: 0.1080\n",
      "Epoch 219/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1562 - sharpe_ratio: 0.1909 - val_loss: -0.0117 - val_sharpe_ratio: 0.0602\n",
      "Epoch 220/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1542 - sharpe_ratio: 0.1934 - val_loss: -0.0054 - val_sharpe_ratio: 0.0405\n",
      "Epoch 221/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1466 - sharpe_ratio: 0.1965 - val_loss: 0.0062 - val_sharpe_ratio: 0.0266\n",
      "Epoch 222/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1197 - sharpe_ratio: 0.1702 - val_loss: 0.0124 - val_sharpe_ratio: 0.0375\n",
      "Epoch 223/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1353 - sharpe_ratio: 0.1743 - val_loss: -0.0320 - val_sharpe_ratio: 0.0753\n",
      "Epoch 224/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1371 - sharpe_ratio: 0.1816 - val_loss: -0.1412 - val_sharpe_ratio: 0.1594\n",
      "Epoch 225/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1536 - sharpe_ratio: 0.1888 - val_loss: -0.0416 - val_sharpe_ratio: 0.0774\n",
      "Epoch 226/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1633 - sharpe_ratio: 0.2001 - val_loss: 0.0234 - val_sharpe_ratio: 0.0236\n",
      "Epoch 227/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1420 - sharpe_ratio: 0.1887 - val_loss: -0.0401 - val_sharpe_ratio: 0.0905\n",
      "Epoch 228/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1433 - sharpe_ratio: 0.1877 - val_loss: -0.0527 - val_sharpe_ratio: 0.0763\n",
      "Epoch 229/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1608 - sharpe_ratio: 0.1914 - val_loss: -0.0443 - val_sharpe_ratio: 0.0949\n",
      "Epoch 230/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1597 - sharpe_ratio: 0.1927 - val_loss: -0.0544 - val_sharpe_ratio: 0.0770\n",
      "Epoch 231/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1515 - sharpe_ratio: 0.1948 - val_loss: -0.0252 - val_sharpe_ratio: 0.0669\n",
      "Epoch 232/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1563 - sharpe_ratio: 0.1882 - val_loss: -0.0374 - val_sharpe_ratio: 0.0851\n",
      "Epoch 233/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1568 - sharpe_ratio: 0.1951 - val_loss: -0.0215 - val_sharpe_ratio: 0.0556\n",
      "Epoch 234/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1760 - sharpe_ratio: 0.2043 - val_loss: -0.0432 - val_sharpe_ratio: 0.0758\n",
      "Epoch 235/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1631 - sharpe_ratio: 0.1966 - val_loss: -0.0319 - val_sharpe_ratio: 0.0645\n",
      "Epoch 236/300\n",
      "41/41 [==============================] - 1s 28ms/step - loss: -0.1608 - sharpe_ratio: 0.1954 - val_loss: -0.0112 - val_sharpe_ratio: 0.0328\n",
      "Epoch 237/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1519 - sharpe_ratio: 0.1888 - val_loss: -0.0486 - val_sharpe_ratio: 0.0861\n",
      "Epoch 238/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1400 - sharpe_ratio: 0.1885 - val_loss: -0.0756 - val_sharpe_ratio: 0.1306\n",
      "Epoch 239/300\n",
      "41/41 [==============================] - 1s 36ms/step - loss: -0.1252 - sharpe_ratio: 0.1821 - val_loss: 0.0624 - val_sharpe_ratio: 0.0644\n",
      "Epoch 240/300\n",
      "41/41 [==============================] - 2s 37ms/step - loss: -0.1035 - sharpe_ratio: 0.1803 - val_loss: -0.1219 - val_sharpe_ratio: 0.1745\n",
      "Epoch 241/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 35ms/step - loss: -0.1390 - sharpe_ratio: 0.1888 - val_loss: -0.0248 - val_sharpe_ratio: 0.0691\n",
      "Epoch 242/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1338 - sharpe_ratio: 0.1737 - val_loss: -0.0129 - val_sharpe_ratio: 0.0931\n",
      "Epoch 243/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.0743 - sharpe_ratio: 0.1750 - val_loss: -0.0151 - val_sharpe_ratio: 0.0867\n",
      "Epoch 244/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.0965 - sharpe_ratio: 0.1787 - val_loss: -0.0058 - val_sharpe_ratio: 0.1141\n",
      "Epoch 245/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1248 - sharpe_ratio: 0.1923 - val_loss: -0.0168 - val_sharpe_ratio: 0.0783\n",
      "Epoch 246/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1249 - sharpe_ratio: 0.1795 - val_loss: 0.0484 - val_sharpe_ratio: 0.0518\n",
      "Epoch 247/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1085 - sharpe_ratio: 0.1909 - val_loss: 0.0298 - val_sharpe_ratio: 0.0303\n",
      "Epoch 248/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1095 - sharpe_ratio: 0.1712 - val_loss: -0.0258 - val_sharpe_ratio: 0.1035\n",
      "Epoch 249/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1315 - sharpe_ratio: 0.1913 - val_loss: 0.0327 - val_sharpe_ratio: 0.0423\n",
      "Epoch 250/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1322 - sharpe_ratio: 0.1897 - val_loss: -0.0150 - val_sharpe_ratio: 0.0787\n",
      "Epoch 251/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1304 - sharpe_ratio: 0.1865 - val_loss: 0.0368 - val_sharpe_ratio: 0.0578\n",
      "Epoch 252/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1070 - sharpe_ratio: 0.1790 - val_loss: -0.0349 - val_sharpe_ratio: 0.0929\n",
      "Epoch 253/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1374 - sharpe_ratio: 0.1959 - val_loss: -0.0040 - val_sharpe_ratio: 0.0697\n",
      "Epoch 254/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1428 - sharpe_ratio: 0.1871 - val_loss: 0.0112 - val_sharpe_ratio: 0.0906\n",
      "Epoch 255/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1279 - sharpe_ratio: 0.1988 - val_loss: 6.3336e-04 - val_sharpe_ratio: 0.0843\n",
      "Epoch 256/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1421 - sharpe_ratio: 0.1859 - val_loss: -0.0335 - val_sharpe_ratio: 0.0740\n",
      "Epoch 257/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1463 - sharpe_ratio: 0.1881 - val_loss: -0.0251 - val_sharpe_ratio: 0.0800\n",
      "Epoch 258/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1568 - sharpe_ratio: 0.1963 - val_loss: -0.0587 - val_sharpe_ratio: 0.0801\n",
      "Epoch 259/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1549 - sharpe_ratio: 0.1976 - val_loss: -0.0195 - val_sharpe_ratio: 0.1013\n",
      "Epoch 260/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1407 - sharpe_ratio: 0.1910 - val_loss: -0.0148 - val_sharpe_ratio: 0.0770\n",
      "Epoch 261/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1363 - sharpe_ratio: 0.1848 - val_loss: -0.0170 - val_sharpe_ratio: 0.0832\n",
      "Epoch 262/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1326 - sharpe_ratio: 0.1857 - val_loss: 0.0289 - val_sharpe_ratio: 0.0417\n",
      "Epoch 263/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1504 - sharpe_ratio: 0.1900 - val_loss: -0.0712 - val_sharpe_ratio: 0.1163\n",
      "Epoch 264/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1705 - sharpe_ratio: 0.2028 - val_loss: -0.0407 - val_sharpe_ratio: 0.0803\n",
      "Epoch 265/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1489 - sharpe_ratio: 0.1899 - val_loss: -0.0774 - val_sharpe_ratio: 0.1237\n",
      "Epoch 266/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1378 - sharpe_ratio: 0.1952 - val_loss: -0.0408 - val_sharpe_ratio: 0.0971\n",
      "Epoch 267/300\n",
      "41/41 [==============================] - 1s 36ms/step - loss: -0.1324 - sharpe_ratio: 0.1810 - val_loss: 0.0154 - val_sharpe_ratio: 0.0520\n",
      "Epoch 268/300\n",
      "41/41 [==============================] - 1s 35ms/step - loss: -0.1342 - sharpe_ratio: 0.1878 - val_loss: 0.0097 - val_sharpe_ratio: 0.0479\n",
      "Epoch 269/300\n",
      "41/41 [==============================] - 1s 36ms/step - loss: -0.1265 - sharpe_ratio: 0.1839 - val_loss: -0.0316 - val_sharpe_ratio: 0.0905\n",
      "Epoch 270/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1335 - sharpe_ratio: 0.1771 - val_loss: -0.0191 - val_sharpe_ratio: 0.0625\n",
      "Epoch 271/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1291 - sharpe_ratio: 0.1795 - val_loss: -0.0231 - val_sharpe_ratio: 0.0798\n",
      "Epoch 272/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1512 - sharpe_ratio: 0.1955 - val_loss: -0.0096 - val_sharpe_ratio: 0.0755\n",
      "Epoch 273/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1553 - sharpe_ratio: 0.1885 - val_loss: -0.0695 - val_sharpe_ratio: 0.1155\n",
      "Epoch 274/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1491 - sharpe_ratio: 0.1881 - val_loss: -0.0080 - val_sharpe_ratio: 0.0480\n",
      "Epoch 275/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1353 - sharpe_ratio: 0.1797 - val_loss: 0.0053 - val_sharpe_ratio: 0.0433\n",
      "Epoch 276/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1162 - sharpe_ratio: 0.1735 - val_loss: 0.0208 - val_sharpe_ratio: 0.0700\n",
      "Epoch 277/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1202 - sharpe_ratio: 0.1746 - val_loss: -0.0163 - val_sharpe_ratio: 0.0621\n",
      "Epoch 278/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1322 - sharpe_ratio: 0.1901 - val_loss: -0.0756 - val_sharpe_ratio: 0.1153\n",
      "Epoch 279/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1411 - sharpe_ratio: 0.1919 - val_loss: -0.0057 - val_sharpe_ratio: 0.0543\n",
      "Epoch 280/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1366 - sharpe_ratio: 0.1817 - val_loss: 0.0169 - val_sharpe_ratio: 0.0335\n",
      "Epoch 281/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1292 - sharpe_ratio: 0.1818 - val_loss: -0.0615 - val_sharpe_ratio: 0.1117\n",
      "Epoch 282/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1512 - sharpe_ratio: 0.1868 - val_loss: -0.0916 - val_sharpe_ratio: 0.1316\n",
      "Epoch 283/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1432 - sharpe_ratio: 0.1925 - val_loss: -0.0357 - val_sharpe_ratio: 0.0793\n",
      "Epoch 284/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1311 - sharpe_ratio: 0.1714 - val_loss: -0.0198 - val_sharpe_ratio: 0.0709\n",
      "Epoch 285/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1335 - sharpe_ratio: 0.1822 - val_loss: -0.0313 - val_sharpe_ratio: 0.0978\n",
      "Epoch 286/300\n",
      "41/41 [==============================] - 1s 37ms/step - loss: -0.1544 - sharpe_ratio: 0.1914 - val_loss: -0.0234 - val_sharpe_ratio: 0.0503\n",
      "Epoch 287/300\n",
      "41/41 [==============================] - 1s 34ms/step - loss: -0.1624 - sharpe_ratio: 0.1992 - val_loss: -0.0024 - val_sharpe_ratio: 0.0353\n",
      "Epoch 288/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1643 - sharpe_ratio: 0.1992 - val_loss: -0.0874 - val_sharpe_ratio: 0.1205\n",
      "Epoch 289/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1485 - sharpe_ratio: 0.1849 - val_loss: -0.0098 - val_sharpe_ratio: 0.0496\n",
      "Epoch 290/300\n",
      "41/41 [==============================] - 2s 38ms/step - loss: -0.1500 - sharpe_ratio: 0.1949 - val_loss: -0.0606 - val_sharpe_ratio: 0.1170\n",
      "Epoch 291/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1230 - sharpe_ratio: 0.1716 - val_loss: -0.0322 - val_sharpe_ratio: 0.0860\n",
      "Epoch 292/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1470 - sharpe_ratio: 0.1871 - val_loss: -0.0249 - val_sharpe_ratio: 0.0517\n",
      "Epoch 293/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1264 - sharpe_ratio: 0.1836 - val_loss: 0.0261 - val_sharpe_ratio: 0.0563\n",
      "Epoch 294/300\n",
      "41/41 [==============================] - 1s 31ms/step - loss: -0.1178 - sharpe_ratio: 0.1843 - val_loss: -0.0383 - val_sharpe_ratio: 0.0822\n",
      "Epoch 295/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1460 - sharpe_ratio: 0.1858 - val_loss: 4.0353e-04 - val_sharpe_ratio: 0.0307\n",
      "Epoch 296/300\n",
      "41/41 [==============================] - 1s 33ms/step - loss: -0.1519 - sharpe_ratio: 0.1951 - val_loss: -0.0017 - val_sharpe_ratio: 0.0438\n",
      "Epoch 297/300\n",
      "41/41 [==============================] - 1s 32ms/step - loss: -0.1562 - sharpe_ratio: 0.1916 - val_loss: -0.0801 - val_sharpe_ratio: 0.1203\n",
      "Epoch 298/300\n",
      "41/41 [==============================] - 1s 30ms/step - loss: -0.1536 - sharpe_ratio: 0.1956 - val_loss: 0.0219 - val_sharpe_ratio: 0.0146\n",
      "Epoch 299/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1578 - sharpe_ratio: 0.1981 - val_loss: -0.0277 - val_sharpe_ratio: 0.0766\n",
      "Epoch 300/300\n",
      "41/41 [==============================] - 1s 29ms/step - loss: -0.1406 - sharpe_ratio: 0.1915 - val_loss: -0.0153 - val_sharpe_ratio: 0.0701\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "There are total 11 samples to predict\n",
      "Sample 0 : [ DRREDDY.NS HDFC.NS HDFCBANK.NS MARUTI.NS SUNPHARMA.NS ]\n",
      "Sample 1 : [ DRREDDY.NS HDFC.NS INFY.NS MARUTI.NS SUNPHARMA.NS ]\n",
      "Sample 2 : [ DRREDDY.NS INFY.NS MARUTI.NS SUNPHARMA.NS ]\n",
      "Sample 3 : [ DRREDDY.NS INFY.NS MARUTI.NS ]\n",
      "Sample 4 : [ DRREDDY.NS INFY.NS MARUTI.NS ]\n",
      "Sample 5 : [ DRREDDY.NS INFY.NS MARUTI.NS ]\n",
      "Sample 6 : [ DRREDDY.NS INFY.NS MARUTI.NS ]\n",
      "Sample 7 : [ DRREDDY.NS INFY.NS MARUTI.NS ]\n",
      "Sample 8 : [ DRREDDY.NS INFY.NS MARUTI.NS ]\n",
      "Sample 9 : [ DRREDDY.NS INFY.NS MARUTI.NS ]\n",
      "Sample 10 : [ DRREDDY.NS INFY.NS MARUTI.NS ]\n",
      "Sharpe ratio of this portfolio: [-0.009011970375272453, 2.305463504008628, -0.29720313905001816, 0.540940978441869, 1.1438341830472345, 0.08840196689589012, -0.6525493766687197, -0.2659620497152935, 0.07075521580952218, 1.1699332110012153, -0.7323890890448286]\n",
      "write file log at C:/Users/yv67/Documents/12FundsHK_ToShare/deeplearningdata/logs/GRU\\log_869.txt\n",
      "Epoch 1/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1187 - sharpe_ratio: 0.1617 - val_loss: -0.0898 - val_sharpe_ratio: 0.1315\n",
      "Epoch 2/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1077 - sharpe_ratio: 0.1538 - val_loss: -0.0289 - val_sharpe_ratio: 0.1046\n",
      "Epoch 3/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1324 - sharpe_ratio: 0.1715 - val_loss: -0.0957 - val_sharpe_ratio: 0.1437\n",
      "Epoch 4/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1179 - sharpe_ratio: 0.1673 - val_loss: -0.0480 - val_sharpe_ratio: 0.1437\n",
      "Epoch 5/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: -0.1024 - sharpe_ratio: 0.1635 - val_loss: -0.1299 - val_sharpe_ratio: 0.1905\n",
      "Epoch 6/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: -0.1130 - sharpe_ratio: 0.1593 - val_loss: -0.0705 - val_sharpe_ratio: 0.1448\n",
      "Epoch 7/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1172 - sharpe_ratio: 0.1670 - val_loss: -0.0605 - val_sharpe_ratio: 0.1261\n",
      "Epoch 8/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: -0.1242 - sharpe_ratio: 0.1638 - val_loss: -0.1366 - val_sharpe_ratio: 0.1837\n",
      "Epoch 9/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: -0.1308 - sharpe_ratio: 0.1757 - val_loss: -0.1790 - val_sharpe_ratio: 0.2311\n",
      "Epoch 10/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: -0.1253 - sharpe_ratio: 0.1689 - val_loss: -0.2001 - val_sharpe_ratio: 0.2492\n",
      "Epoch 11/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: -0.1243 - sharpe_ratio: 0.1747 - val_loss: -0.1455 - val_sharpe_ratio: 0.1785\n",
      "Epoch 12/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1048 - sharpe_ratio: 0.1595 - val_loss: -0.0664 - val_sharpe_ratio: 0.1071\n",
      "Epoch 13/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: -0.1151 - sharpe_ratio: 0.1658 - val_loss: -0.2002 - val_sharpe_ratio: 0.2669\n",
      "Epoch 14/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1132 - sharpe_ratio: 0.1652 - val_loss: -0.1338 - val_sharpe_ratio: 0.1869\n",
      "Epoch 15/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1215 - sharpe_ratio: 0.1619 - val_loss: -0.1666 - val_sharpe_ratio: 0.2127\n",
      "Epoch 16/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: -0.1091 - sharpe_ratio: 0.1707 - val_loss: -0.1375 - val_sharpe_ratio: 0.2384\n",
      "Epoch 17/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: -0.0864 - sharpe_ratio: 0.1675 - val_loss: -0.1348 - val_sharpe_ratio: 0.2009\n",
      "Epoch 18/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.0970 - sharpe_ratio: 0.1636 - val_loss: -0.2071 - val_sharpe_ratio: 0.2512\n",
      "Epoch 19/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: -0.1256 - sharpe_ratio: 0.1634 - val_loss: -0.0955 - val_sharpe_ratio: 0.1606\n",
      "Epoch 20/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: -0.1174 - sharpe_ratio: 0.1693 - val_loss: -0.0839 - val_sharpe_ratio: 0.1420\n",
      "Epoch 21/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: -0.1183 - sharpe_ratio: 0.1728 - val_loss: -0.0925 - val_sharpe_ratio: 0.1451\n",
      "Epoch 22/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1167 - sharpe_ratio: 0.1677 - val_loss: -0.1294 - val_sharpe_ratio: 0.1701\n",
      "Epoch 23/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1435 - sharpe_ratio: 0.1714 - val_loss: -0.2244 - val_sharpe_ratio: 0.2418\n",
      "Epoch 24/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1211 - sharpe_ratio: 0.1655 - val_loss: -0.1190 - val_sharpe_ratio: 0.1731\n",
      "Epoch 25/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1298 - sharpe_ratio: 0.1701 - val_loss: -0.1594 - val_sharpe_ratio: 0.1907\n",
      "Epoch 26/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1335 - sharpe_ratio: 0.1726 - val_loss: -0.1294 - val_sharpe_ratio: 0.1725\n",
      "Epoch 27/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1288 - sharpe_ratio: 0.1732 - val_loss: -0.1668 - val_sharpe_ratio: 0.2250\n",
      "Epoch 28/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1225 - sharpe_ratio: 0.1730 - val_loss: -0.1029 - val_sharpe_ratio: 0.1308\n",
      "Epoch 29/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.0914 - sharpe_ratio: 0.1459 - val_loss: -0.1785 - val_sharpe_ratio: 0.2494\n",
      "Epoch 30/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.0984 - sharpe_ratio: 0.1574 - val_loss: -0.0525 - val_sharpe_ratio: 0.1175\n",
      "Epoch 31/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1182 - sharpe_ratio: 0.1606 - val_loss: -0.1978 - val_sharpe_ratio: 0.2461\n",
      "Epoch 32/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1309 - sharpe_ratio: 0.1684 - val_loss: -0.0942 - val_sharpe_ratio: 0.1084\n",
      "Epoch 33/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: -0.1361 - sharpe_ratio: 0.1683 - val_loss: -0.0540 - val_sharpe_ratio: 0.0576\n",
      "Epoch 34/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: -0.1289 - sharpe_ratio: 0.1708 - val_loss: -0.1601 - val_sharpe_ratio: 0.1950\n",
      "Epoch 35/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1387 - sharpe_ratio: 0.1742 - val_loss: -0.0400 - val_sharpe_ratio: 0.1000\n",
      "Epoch 36/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1292 - sharpe_ratio: 0.1730 - val_loss: -0.1475 - val_sharpe_ratio: 0.1957\n",
      "Epoch 37/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.0994 - sharpe_ratio: 0.1600 - val_loss: -0.1528 - val_sharpe_ratio: 0.2482\n",
      "Epoch 38/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1202 - sharpe_ratio: 0.1635 - val_loss: -0.0425 - val_sharpe_ratio: 0.0746\n",
      "Epoch 39/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1316 - sharpe_ratio: 0.1707 - val_loss: -0.1217 - val_sharpe_ratio: 0.1771\n",
      "Epoch 40/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1167 - sharpe_ratio: 0.1680 - val_loss: -0.0962 - val_sharpe_ratio: 0.1331\n",
      "Epoch 41/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1284 - sharpe_ratio: 0.1687 - val_loss: -0.1392 - val_sharpe_ratio: 0.1490\n",
      "Epoch 42/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1300 - sharpe_ratio: 0.1746 - val_loss: -0.2082 - val_sharpe_ratio: 0.2242\n",
      "Epoch 43/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1317 - sharpe_ratio: 0.1682 - val_loss: -0.1692 - val_sharpe_ratio: 0.2127\n",
      "Epoch 44/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1443 - sharpe_ratio: 0.1795 - val_loss: -0.1740 - val_sharpe_ratio: 0.2009\n",
      "Epoch 45/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: -0.1233 - sharpe_ratio: 0.1713 - val_loss: -0.0122 - val_sharpe_ratio: 0.1081\n",
      "Epoch 46/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1183 - sharpe_ratio: 0.1727 - val_loss: -0.1308 - val_sharpe_ratio: 0.1664\n",
      "Epoch 47/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1381 - sharpe_ratio: 0.1739 - val_loss: -0.0762 - val_sharpe_ratio: 0.1084\n",
      "Epoch 48/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1195 - sharpe_ratio: 0.1698 - val_loss: -0.1956 - val_sharpe_ratio: 0.2612\n",
      "Epoch 49/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1346 - sharpe_ratio: 0.1746 - val_loss: -0.2282 - val_sharpe_ratio: 0.2403\n",
      "Epoch 50/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1317 - sharpe_ratio: 0.1675 - val_loss: -0.1926 - val_sharpe_ratio: 0.2244\n",
      "Epoch 51/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1226 - sharpe_ratio: 0.1617 - val_loss: -0.2220 - val_sharpe_ratio: 0.2646\n",
      "Epoch 52/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1227 - sharpe_ratio: 0.1603 - val_loss: -0.0764 - val_sharpe_ratio: 0.0802\n",
      "Epoch 53/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1157 - sharpe_ratio: 0.1594 - val_loss: -0.1460 - val_sharpe_ratio: 0.1823\n",
      "Epoch 54/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1345 - sharpe_ratio: 0.1699 - val_loss: -0.0382 - val_sharpe_ratio: 0.0576\n",
      "Epoch 55/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1267 - sharpe_ratio: 0.1614 - val_loss: -0.0443 - val_sharpe_ratio: 0.0928\n",
      "Epoch 56/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1361 - sharpe_ratio: 0.1669 - val_loss: -0.1631 - val_sharpe_ratio: 0.1761\n",
      "Epoch 57/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1344 - sharpe_ratio: 0.1668 - val_loss: -0.2344 - val_sharpe_ratio: 0.2612\n",
      "Epoch 58/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1239 - sharpe_ratio: 0.1636 - val_loss: -0.0621 - val_sharpe_ratio: 0.1256\n",
      "Epoch 59/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: -0.1264 - sharpe_ratio: 0.1634 - val_loss: -0.1247 - val_sharpe_ratio: 0.1657\n",
      "Epoch 60/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1412 - sharpe_ratio: 0.1652 - val_loss: -0.2182 - val_sharpe_ratio: 0.2685\n",
      "Epoch 61/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1268 - sharpe_ratio: 0.1681 - val_loss: -0.1625 - val_sharpe_ratio: 0.2508\n",
      "Epoch 62/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1395 - sharpe_ratio: 0.1635 - val_loss: -0.1614 - val_sharpe_ratio: 0.1761\n",
      "Epoch 63/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1450 - sharpe_ratio: 0.1731 - val_loss: -0.1762 - val_sharpe_ratio: 0.1950\n",
      "Epoch 64/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: -0.1386 - sharpe_ratio: 0.1754 - val_loss: -0.1512 - val_sharpe_ratio: 0.1838\n",
      "Epoch 65/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1401 - sharpe_ratio: 0.1659 - val_loss: -0.1235 - val_sharpe_ratio: 0.1893\n",
      "Epoch 66/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1207 - sharpe_ratio: 0.1633 - val_loss: -0.2176 - val_sharpe_ratio: 0.2756\n",
      "Epoch 67/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1432 - sharpe_ratio: 0.1746 - val_loss: -0.1462 - val_sharpe_ratio: 0.1632\n",
      "Epoch 68/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1151 - sharpe_ratio: 0.1711 - val_loss: -0.2071 - val_sharpe_ratio: 0.2362\n",
      "Epoch 69/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1082 - sharpe_ratio: 0.1684 - val_loss: -0.1175 - val_sharpe_ratio: 0.1576\n",
      "Epoch 70/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: -0.1053 - sharpe_ratio: 0.1490 - val_loss: -0.0360 - val_sharpe_ratio: 0.1046\n",
      "Epoch 71/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: -0.1205 - sharpe_ratio: 0.1752 - val_loss: -0.1393 - val_sharpe_ratio: 0.1717\n",
      "Epoch 72/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1267 - sharpe_ratio: 0.1680 - val_loss: -0.1506 - val_sharpe_ratio: 0.1786\n",
      "Epoch 73/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: -0.1230 - sharpe_ratio: 0.1615 - val_loss: -0.1819 - val_sharpe_ratio: 0.1949\n",
      "Epoch 74/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: -0.1124 - sharpe_ratio: 0.1594 - val_loss: -0.1581 - val_sharpe_ratio: 0.1651\n",
      "Epoch 75/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1368 - sharpe_ratio: 0.1756 - val_loss: -0.1360 - val_sharpe_ratio: 0.2015\n",
      "Epoch 76/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1331 - sharpe_ratio: 0.1698 - val_loss: -0.1818 - val_sharpe_ratio: 0.2254\n",
      "Epoch 77/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1383 - sharpe_ratio: 0.1674 - val_loss: -0.2404 - val_sharpe_ratio: 0.2559\n",
      "Epoch 78/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1489 - sharpe_ratio: 0.1693 - val_loss: -0.2106 - val_sharpe_ratio: 0.2127\n",
      "Epoch 79/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1443 - sharpe_ratio: 0.1634 - val_loss: -0.2116 - val_sharpe_ratio: 0.2424\n",
      "Epoch 80/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1415 - sharpe_ratio: 0.1656 - val_loss: -0.1118 - val_sharpe_ratio: 0.1638\n",
      "Epoch 81/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: -0.1298 - sharpe_ratio: 0.1614 - val_loss: -0.1429 - val_sharpe_ratio: 0.2348\n",
      "Epoch 82/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1073 - sharpe_ratio: 0.1764 - val_loss: -0.2187 - val_sharpe_ratio: 0.2612\n",
      "Epoch 83/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1253 - sharpe_ratio: 0.1678 - val_loss: -0.2119 - val_sharpe_ratio: 0.2651\n",
      "Epoch 84/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1094 - sharpe_ratio: 0.1645 - val_loss: -0.1414 - val_sharpe_ratio: 0.2051\n",
      "Epoch 85/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1120 - sharpe_ratio: 0.1647 - val_loss: -0.1611 - val_sharpe_ratio: 0.2213\n",
      "Epoch 86/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1127 - sharpe_ratio: 0.1663 - val_loss: -0.0270 - val_sharpe_ratio: 0.1000\n",
      "Epoch 87/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1317 - sharpe_ratio: 0.1688 - val_loss: -0.1427 - val_sharpe_ratio: 0.1978\n",
      "Epoch 88/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1396 - sharpe_ratio: 0.1689 - val_loss: -0.1441 - val_sharpe_ratio: 0.2022\n",
      "Epoch 89/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1357 - sharpe_ratio: 0.1692 - val_loss: -0.1299 - val_sharpe_ratio: 0.1685\n",
      "Epoch 90/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1335 - sharpe_ratio: 0.1652 - val_loss: -0.2144 - val_sharpe_ratio: 0.2411\n",
      "Epoch 91/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1433 - sharpe_ratio: 0.1721 - val_loss: -0.1786 - val_sharpe_ratio: 0.2127\n",
      "Epoch 92/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1283 - sharpe_ratio: 0.1674 - val_loss: -0.1924 - val_sharpe_ratio: 0.2215\n",
      "Epoch 93/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1226 - sharpe_ratio: 0.1676 - val_loss: -0.1462 - val_sharpe_ratio: 0.1875\n",
      "Epoch 94/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1385 - sharpe_ratio: 0.1714 - val_loss: -0.2148 - val_sharpe_ratio: 0.2447\n",
      "Epoch 95/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1400 - sharpe_ratio: 0.1761 - val_loss: -0.1901 - val_sharpe_ratio: 0.2050\n",
      "Epoch 96/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1223 - sharpe_ratio: 0.1654 - val_loss: -0.1956 - val_sharpe_ratio: 0.2257\n",
      "Epoch 97/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1401 - sharpe_ratio: 0.1671 - val_loss: -0.1545 - val_sharpe_ratio: 0.1650\n",
      "Epoch 98/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1256 - sharpe_ratio: 0.1645 - val_loss: -0.1268 - val_sharpe_ratio: 0.1600\n",
      "Epoch 99/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1305 - sharpe_ratio: 0.1618 - val_loss: -0.1864 - val_sharpe_ratio: 0.2240\n",
      "Epoch 100/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1466 - sharpe_ratio: 0.1712 - val_loss: -0.2311 - val_sharpe_ratio: 0.2612\n",
      "Epoch 101/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1405 - sharpe_ratio: 0.1700 - val_loss: -0.1410 - val_sharpe_ratio: 0.1571\n",
      "Epoch 102/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1090 - sharpe_ratio: 0.1559 - val_loss: -0.0745 - val_sharpe_ratio: 0.1534\n",
      "Epoch 103/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1236 - sharpe_ratio: 0.1748 - val_loss: -0.1917 - val_sharpe_ratio: 0.2257\n",
      "Epoch 104/300\n",
      "55/55 [==============================] - 2s 27ms/step - loss: -0.1387 - sharpe_ratio: 0.1728 - val_loss: -0.1408 - val_sharpe_ratio: 0.1744\n",
      "Epoch 105/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1398 - sharpe_ratio: 0.1720 - val_loss: -0.1032 - val_sharpe_ratio: 0.1520\n",
      "Epoch 106/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1304 - sharpe_ratio: 0.1707 - val_loss: -0.1260 - val_sharpe_ratio: 0.1389\n",
      "Epoch 107/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1070 - sharpe_ratio: 0.1687 - val_loss: -0.2021 - val_sharpe_ratio: 0.2612\n",
      "Epoch 108/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.0943 - sharpe_ratio: 0.1523 - val_loss: -0.2063 - val_sharpe_ratio: 0.2612\n",
      "Epoch 109/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1052 - sharpe_ratio: 0.1612 - val_loss: -0.1401 - val_sharpe_ratio: 0.1955\n",
      "Epoch 110/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.0934 - sharpe_ratio: 0.1515 - val_loss: -0.1700 - val_sharpe_ratio: 0.2127\n",
      "Epoch 111/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1292 - sharpe_ratio: 0.1685 - val_loss: -0.1238 - val_sharpe_ratio: 0.1749\n",
      "Epoch 112/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: -0.1379 - sharpe_ratio: 0.1645 - val_loss: -0.1969 - val_sharpe_ratio: 0.2257\n",
      "Epoch 113/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1317 - sharpe_ratio: 0.1658 - val_loss: -0.2190 - val_sharpe_ratio: 0.2416\n",
      "Epoch 114/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1318 - sharpe_ratio: 0.1654 - val_loss: -0.1641 - val_sharpe_ratio: 0.2024\n",
      "Epoch 115/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1220 - sharpe_ratio: 0.1630 - val_loss: -0.1100 - val_sharpe_ratio: 0.1584\n",
      "Epoch 116/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1386 - sharpe_ratio: 0.1711 - val_loss: -0.1809 - val_sharpe_ratio: 0.2130\n",
      "Epoch 117/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1486 - sharpe_ratio: 0.1745 - val_loss: -0.2153 - val_sharpe_ratio: 0.2398\n",
      "Epoch 118/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1436 - sharpe_ratio: 0.1645 - val_loss: -0.2013 - val_sharpe_ratio: 0.2257\n",
      "Epoch 119/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1280 - sharpe_ratio: 0.1622 - val_loss: -0.1394 - val_sharpe_ratio: 0.1775\n",
      "Epoch 120/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1370 - sharpe_ratio: 0.1675 - val_loss: -0.2346 - val_sharpe_ratio: 0.2612\n",
      "Epoch 121/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1154 - sharpe_ratio: 0.1645 - val_loss: -0.1380 - val_sharpe_ratio: 0.2685\n",
      "Epoch 122/300\n",
      "55/55 [==============================] - 1s 27ms/step - loss: -0.1101 - sharpe_ratio: 0.1632 - val_loss: -0.0930 - val_sharpe_ratio: 0.1474\n",
      "Epoch 123/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1365 - sharpe_ratio: 0.1741 - val_loss: -0.0975 - val_sharpe_ratio: 0.1099\n",
      "Epoch 124/300\n",
      "55/55 [==============================] - 1s 27ms/step - loss: -0.1164 - sharpe_ratio: 0.1600 - val_loss: -0.1801 - val_sharpe_ratio: 0.2367\n",
      "Epoch 125/300\n",
      "55/55 [==============================] - 1s 27ms/step - loss: -0.1139 - sharpe_ratio: 0.1555 - val_loss: -0.1130 - val_sharpe_ratio: 0.1506\n",
      "Epoch 126/300\n",
      "55/55 [==============================] - 1s 27ms/step - loss: -0.1354 - sharpe_ratio: 0.1698 - val_loss: -0.1099 - val_sharpe_ratio: 0.1356\n",
      "Epoch 127/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1249 - sharpe_ratio: 0.1678 - val_loss: -0.1551 - val_sharpe_ratio: 0.1803\n",
      "Epoch 128/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: -0.1305 - sharpe_ratio: 0.1680 - val_loss: -0.0858 - val_sharpe_ratio: 0.1437\n",
      "Epoch 129/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: -0.0940 - sharpe_ratio: 0.1598 - val_loss: -0.1274 - val_sharpe_ratio: 0.2304\n",
      "Epoch 130/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1134 - sharpe_ratio: 0.1732 - val_loss: -0.0058 - val_sharpe_ratio: 0.0702\n",
      "Epoch 131/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: -0.1190 - sharpe_ratio: 0.1710 - val_loss: -0.1963 - val_sharpe_ratio: 0.2276\n",
      "Epoch 132/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: -0.1304 - sharpe_ratio: 0.1634 - val_loss: -0.1713 - val_sharpe_ratio: 0.1962\n",
      "Epoch 133/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1200 - sharpe_ratio: 0.1642 - val_loss: -0.1326 - val_sharpe_ratio: 0.2246\n",
      "Epoch 134/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1306 - sharpe_ratio: 0.1708 - val_loss: -0.1099 - val_sharpe_ratio: 0.1658\n",
      "Epoch 135/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1364 - sharpe_ratio: 0.1724 - val_loss: -0.1247 - val_sharpe_ratio: 0.1471\n",
      "Epoch 136/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1185 - sharpe_ratio: 0.1639 - val_loss: -0.1777 - val_sharpe_ratio: 0.1982\n",
      "Epoch 137/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1304 - sharpe_ratio: 0.1661 - val_loss: -0.1932 - val_sharpe_ratio: 0.2206\n",
      "Epoch 138/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1379 - sharpe_ratio: 0.1710 - val_loss: -0.1610 - val_sharpe_ratio: 0.1931\n",
      "Epoch 139/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1305 - sharpe_ratio: 0.1694 - val_loss: -0.0477 - val_sharpe_ratio: 0.1084\n",
      "Epoch 140/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1263 - sharpe_ratio: 0.1616 - val_loss: -0.0489 - val_sharpe_ratio: 0.0856\n",
      "Epoch 141/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1404 - sharpe_ratio: 0.1740 - val_loss: -0.1026 - val_sharpe_ratio: 0.1544\n",
      "Epoch 142/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1349 - sharpe_ratio: 0.1730 - val_loss: -0.1631 - val_sharpe_ratio: 0.1886\n",
      "Epoch 143/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1236 - sharpe_ratio: 0.1668 - val_loss: -0.1339 - val_sharpe_ratio: 0.1775\n",
      "Epoch 144/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1385 - sharpe_ratio: 0.1683 - val_loss: -0.0866 - val_sharpe_ratio: 0.1080\n",
      "Epoch 145/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1200 - sharpe_ratio: 0.1679 - val_loss: -0.1707 - val_sharpe_ratio: 0.1872\n",
      "Epoch 146/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1251 - sharpe_ratio: 0.1638 - val_loss: -0.1470 - val_sharpe_ratio: 0.2325\n",
      "Epoch 147/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1167 - sharpe_ratio: 0.1656 - val_loss: -0.1287 - val_sharpe_ratio: 0.1790\n",
      "Epoch 148/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1005 - sharpe_ratio: 0.1685 - val_loss: -0.2265 - val_sharpe_ratio: 0.2663\n",
      "Epoch 149/300\n",
      "55/55 [==============================] - 2s 27ms/step - loss: -0.1240 - sharpe_ratio: 0.1742 - val_loss: -0.1791 - val_sharpe_ratio: 0.2311\n",
      "Epoch 150/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1288 - sharpe_ratio: 0.1642 - val_loss: -0.2171 - val_sharpe_ratio: 0.2612\n",
      "Epoch 151/300\n",
      "55/55 [==============================] - 1s 27ms/step - loss: -0.1167 - sharpe_ratio: 0.1688 - val_loss: -0.0096 - val_sharpe_ratio: 0.0549\n",
      "Epoch 152/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1185 - sharpe_ratio: 0.1590 - val_loss: -0.0666 - val_sharpe_ratio: 0.0661\n",
      "Epoch 153/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1417 - sharpe_ratio: 0.1771 - val_loss: -0.1463 - val_sharpe_ratio: 0.1960\n",
      "Epoch 154/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1228 - sharpe_ratio: 0.1632 - val_loss: -0.1224 - val_sharpe_ratio: 0.1895\n",
      "Epoch 155/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: -0.1372 - sharpe_ratio: 0.1710 - val_loss: -0.2029 - val_sharpe_ratio: 0.2612\n",
      "Epoch 156/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: -0.1231 - sharpe_ratio: 0.1660 - val_loss: -0.0979 - val_sharpe_ratio: 0.1729\n",
      "Epoch 157/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: -0.1165 - sharpe_ratio: 0.1685 - val_loss: -0.1815 - val_sharpe_ratio: 0.2335\n",
      "Epoch 158/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: -0.1210 - sharpe_ratio: 0.1631 - val_loss: -0.1112 - val_sharpe_ratio: 0.1726\n",
      "Epoch 159/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: -0.1357 - sharpe_ratio: 0.1710 - val_loss: -0.1920 - val_sharpe_ratio: 0.2259\n",
      "Epoch 160/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: -0.1200 - sharpe_ratio: 0.1678 - val_loss: -0.2074 - val_sharpe_ratio: 0.2456\n",
      "Epoch 161/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: -0.1458 - sharpe_ratio: 0.1749 - val_loss: -0.0918 - val_sharpe_ratio: 0.1568\n",
      "Epoch 162/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: -0.1551 - sharpe_ratio: 0.1744 - val_loss: -0.1267 - val_sharpe_ratio: 0.1921\n",
      "Epoch 163/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: -0.1500 - sharpe_ratio: 0.1765 - val_loss: -0.2212 - val_sharpe_ratio: 0.2291\n",
      "Epoch 164/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1458 - sharpe_ratio: 0.1760 - val_loss: -0.2025 - val_sharpe_ratio: 0.2156\n",
      "Epoch 165/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1400 - sharpe_ratio: 0.1688 - val_loss: -0.1300 - val_sharpe_ratio: 0.1547\n",
      "Epoch 166/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1346 - sharpe_ratio: 0.1810 - val_loss: 3.6452e-04 - val_sharpe_ratio: 0.0549\n",
      "Epoch 167/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1351 - sharpe_ratio: 0.1734 - val_loss: -0.1562 - val_sharpe_ratio: 0.1576\n",
      "Epoch 168/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1262 - sharpe_ratio: 0.1547 - val_loss: -0.1908 - val_sharpe_ratio: 0.2097\n",
      "Epoch 169/300\n",
      "55/55 [==============================] - 2s 27ms/step - loss: -0.1273 - sharpe_ratio: 0.1648 - val_loss: -0.1611 - val_sharpe_ratio: 0.2127\n",
      "Epoch 170/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.0755 - sharpe_ratio: 0.1636 - val_loss: -0.0191 - val_sharpe_ratio: 0.2069\n",
      "Epoch 171/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.0805 - sharpe_ratio: 0.1722 - val_loss: -0.2033 - val_sharpe_ratio: 0.2233\n",
      "Epoch 172/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1347 - sharpe_ratio: 0.1693 - val_loss: -0.1007 - val_sharpe_ratio: 0.1659\n",
      "Epoch 173/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1252 - sharpe_ratio: 0.1665 - val_loss: -0.1720 - val_sharpe_ratio: 0.2257\n",
      "Epoch 174/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1244 - sharpe_ratio: 0.1714 - val_loss: -0.1144 - val_sharpe_ratio: 0.1885\n",
      "Epoch 175/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1403 - sharpe_ratio: 0.1749 - val_loss: -0.2047 - val_sharpe_ratio: 0.2439\n",
      "Epoch 176/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1421 - sharpe_ratio: 0.1782 - val_loss: -0.0198 - val_sharpe_ratio: 0.0576\n",
      "Epoch 177/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1296 - sharpe_ratio: 0.1684 - val_loss: -0.0750 - val_sharpe_ratio: 0.1196\n",
      "Epoch 178/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: -0.1350 - sharpe_ratio: 0.1724 - val_loss: -0.1173 - val_sharpe_ratio: 0.1686\n",
      "Epoch 179/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: -0.0906 - sharpe_ratio: 0.1681 - val_loss: -0.1276 - val_sharpe_ratio: 0.2069\n",
      "Epoch 180/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: -0.1107 - sharpe_ratio: 0.1624 - val_loss: -0.1701 - val_sharpe_ratio: 0.2262\n",
      "Epoch 181/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1008 - sharpe_ratio: 0.1692 - val_loss: -0.2098 - val_sharpe_ratio: 0.2454\n",
      "Epoch 182/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1098 - sharpe_ratio: 0.1622 - val_loss: -0.0503 - val_sharpe_ratio: 0.1083\n",
      "Epoch 183/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1103 - sharpe_ratio: 0.1675 - val_loss: -0.0764 - val_sharpe_ratio: 0.1811\n",
      "Epoch 184/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: -0.1204 - sharpe_ratio: 0.1666 - val_loss: -0.1599 - val_sharpe_ratio: 0.1985\n",
      "Epoch 185/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1358 - sharpe_ratio: 0.1742 - val_loss: -0.2045 - val_sharpe_ratio: 0.2172\n",
      "Epoch 186/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1267 - sharpe_ratio: 0.1735 - val_loss: -0.0828 - val_sharpe_ratio: 0.1700\n",
      "Epoch 187/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1216 - sharpe_ratio: 0.1691 - val_loss: -0.0779 - val_sharpe_ratio: 0.1315\n",
      "Epoch 188/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1366 - sharpe_ratio: 0.1690 - val_loss: -0.1106 - val_sharpe_ratio: 0.0867\n",
      "Epoch 189/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1228 - sharpe_ratio: 0.1696 - val_loss: -0.1187 - val_sharpe_ratio: 0.1474\n",
      "Epoch 190/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1174 - sharpe_ratio: 0.1587 - val_loss: -0.1943 - val_sharpe_ratio: 0.2531\n",
      "Epoch 191/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1254 - sharpe_ratio: 0.1674 - val_loss: -0.1247 - val_sharpe_ratio: 0.1493\n",
      "Epoch 192/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1295 - sharpe_ratio: 0.1733 - val_loss: -0.0370 - val_sharpe_ratio: 0.0600\n",
      "Epoch 193/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: -0.1271 - sharpe_ratio: 0.1790 - val_loss: -0.1791 - val_sharpe_ratio: 0.2612\n",
      "Epoch 194/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: -0.1140 - sharpe_ratio: 0.1671 - val_loss: -0.0156 - val_sharpe_ratio: 0.0594\n",
      "Epoch 195/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: -0.1410 - sharpe_ratio: 0.1674 - val_loss: -0.1337 - val_sharpe_ratio: 0.1200\n",
      "Epoch 196/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: -0.1252 - sharpe_ratio: 0.1731 - val_loss: -0.0600 - val_sharpe_ratio: 0.1092\n",
      "Epoch 197/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: -0.1220 - sharpe_ratio: 0.1746 - val_loss: -0.0949 - val_sharpe_ratio: 0.1307\n",
      "Epoch 198/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1233 - sharpe_ratio: 0.1731 - val_loss: -0.0378 - val_sharpe_ratio: 0.1014\n",
      "Epoch 199/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1069 - sharpe_ratio: 0.1631 - val_loss: -0.1806 - val_sharpe_ratio: 0.2310\n",
      "Epoch 200/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1212 - sharpe_ratio: 0.1668 - val_loss: -0.1773 - val_sharpe_ratio: 0.1917\n",
      "Epoch 201/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1224 - sharpe_ratio: 0.1725 - val_loss: -0.1620 - val_sharpe_ratio: 0.2337\n",
      "Epoch 202/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1058 - sharpe_ratio: 0.1707 - val_loss: -0.1760 - val_sharpe_ratio: 0.2321\n",
      "Epoch 203/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1046 - sharpe_ratio: 0.1725 - val_loss: -0.0663 - val_sharpe_ratio: 0.1058\n",
      "Epoch 204/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.0906 - sharpe_ratio: 0.1622 - val_loss: -0.0597 - val_sharpe_ratio: 0.1274\n",
      "Epoch 205/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1211 - sharpe_ratio: 0.1737 - val_loss: -0.1011 - val_sharpe_ratio: 0.1840\n",
      "Epoch 206/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1066 - sharpe_ratio: 0.1713 - val_loss: -0.0467 - val_sharpe_ratio: 0.1040\n",
      "Epoch 207/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1269 - sharpe_ratio: 0.1674 - val_loss: -0.1283 - val_sharpe_ratio: 0.1474\n",
      "Epoch 208/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1145 - sharpe_ratio: 0.1762 - val_loss: -0.1044 - val_sharpe_ratio: 0.1587\n",
      "Epoch 209/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: -0.1222 - sharpe_ratio: 0.1721 - val_loss: -0.0910 - val_sharpe_ratio: 0.1443\n",
      "Epoch 210/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: -0.1036 - sharpe_ratio: 0.1697 - val_loss: -0.1450 - val_sharpe_ratio: 0.1584\n",
      "Epoch 211/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: -0.1150 - sharpe_ratio: 0.1760 - val_loss: -0.0795 - val_sharpe_ratio: 0.1468\n",
      "Epoch 212/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1223 - sharpe_ratio: 0.1719 - val_loss: -0.2201 - val_sharpe_ratio: 0.2623\n",
      "Epoch 213/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1366 - sharpe_ratio: 0.1790 - val_loss: -0.0878 - val_sharpe_ratio: 0.1063\n",
      "Epoch 214/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1217 - sharpe_ratio: 0.1738 - val_loss: -0.1212 - val_sharpe_ratio: 0.1863\n",
      "Epoch 215/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: -0.1002 - sharpe_ratio: 0.1691 - val_loss: -0.1586 - val_sharpe_ratio: 0.2303\n",
      "Epoch 216/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1222 - sharpe_ratio: 0.1791 - val_loss: -0.1105 - val_sharpe_ratio: 0.2003\n",
      "Epoch 217/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.0987 - sharpe_ratio: 0.1694 - val_loss: -0.0860 - val_sharpe_ratio: 0.1458\n",
      "Epoch 218/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1222 - sharpe_ratio: 0.1674 - val_loss: -0.0984 - val_sharpe_ratio: 0.1122\n",
      "Epoch 219/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1099 - sharpe_ratio: 0.1773 - val_loss: -0.2054 - val_sharpe_ratio: 0.2612\n",
      "Epoch 220/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1238 - sharpe_ratio: 0.1788 - val_loss: -0.1351 - val_sharpe_ratio: 0.1657\n",
      "Epoch 221/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1394 - sharpe_ratio: 0.1792 - val_loss: -0.1171 - val_sharpe_ratio: 0.1570\n",
      "Epoch 222/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1312 - sharpe_ratio: 0.1775 - val_loss: -0.2140 - val_sharpe_ratio: 0.3058\n",
      "Epoch 223/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1097 - sharpe_ratio: 0.1700 - val_loss: -0.1538 - val_sharpe_ratio: 0.2018\n",
      "Epoch 224/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1078 - sharpe_ratio: 0.1693 - val_loss: -0.1950 - val_sharpe_ratio: 0.2623\n",
      "Epoch 225/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1240 - sharpe_ratio: 0.1712 - val_loss: -0.1504 - val_sharpe_ratio: 0.2127\n",
      "Epoch 226/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1219 - sharpe_ratio: 0.1743 - val_loss: -0.1363 - val_sharpe_ratio: 0.2284\n",
      "Epoch 227/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1157 - sharpe_ratio: 0.1717 - val_loss: -0.1418 - val_sharpe_ratio: 0.2335\n",
      "Epoch 228/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: -0.1217 - sharpe_ratio: 0.1702 - val_loss: -0.1476 - val_sharpe_ratio: 0.1972\n",
      "Epoch 229/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: -0.1360 - sharpe_ratio: 0.1783 - val_loss: -0.2178 - val_sharpe_ratio: 0.2125\n",
      "Epoch 230/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1411 - sharpe_ratio: 0.1795 - val_loss: -0.2024 - val_sharpe_ratio: 0.2612\n",
      "Epoch 231/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1352 - sharpe_ratio: 0.1800 - val_loss: -0.1009 - val_sharpe_ratio: 0.1541\n",
      "Epoch 232/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1213 - sharpe_ratio: 0.1776 - val_loss: -0.0514 - val_sharpe_ratio: 0.1918\n",
      "Epoch 233/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1183 - sharpe_ratio: 0.1660 - val_loss: -0.1556 - val_sharpe_ratio: 0.2196\n",
      "Epoch 234/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1270 - sharpe_ratio: 0.1680 - val_loss: -0.1741 - val_sharpe_ratio: 0.2455\n",
      "Epoch 235/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1223 - sharpe_ratio: 0.1696 - val_loss: -0.1514 - val_sharpe_ratio: 0.2296\n",
      "Epoch 236/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1261 - sharpe_ratio: 0.1756 - val_loss: -0.1815 - val_sharpe_ratio: 0.2000\n",
      "Epoch 237/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1197 - sharpe_ratio: 0.1585 - val_loss: -0.1290 - val_sharpe_ratio: 0.1839\n",
      "Epoch 238/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1411 - sharpe_ratio: 0.1838 - val_loss: -0.1554 - val_sharpe_ratio: 0.2045\n",
      "Epoch 239/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1274 - sharpe_ratio: 0.1715 - val_loss: -0.1174 - val_sharpe_ratio: 0.2209\n",
      "Epoch 240/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1287 - sharpe_ratio: 0.1790 - val_loss: -0.1554 - val_sharpe_ratio: 0.2041\n",
      "Epoch 241/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1334 - sharpe_ratio: 0.1717 - val_loss: -0.0853 - val_sharpe_ratio: 0.1679\n",
      "Epoch 242/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: -0.1441 - sharpe_ratio: 0.1783 - val_loss: -0.1901 - val_sharpe_ratio: 0.2425\n",
      "Epoch 243/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1060 - sharpe_ratio: 0.1654 - val_loss: -0.1150 - val_sharpe_ratio: 0.2029\n",
      "Epoch 244/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1189 - sharpe_ratio: 0.1710 - val_loss: -0.1700 - val_sharpe_ratio: 0.2153\n",
      "Epoch 245/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1262 - sharpe_ratio: 0.1662 - val_loss: -0.1639 - val_sharpe_ratio: 0.2368\n",
      "Epoch 246/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1387 - sharpe_ratio: 0.1674 - val_loss: -0.1304 - val_sharpe_ratio: 0.1601\n",
      "Epoch 247/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1241 - sharpe_ratio: 0.1690 - val_loss: -0.1916 - val_sharpe_ratio: 0.2617\n",
      "Epoch 248/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1399 - sharpe_ratio: 0.1788 - val_loss: -0.1529 - val_sharpe_ratio: 0.2071\n",
      "Epoch 249/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1308 - sharpe_ratio: 0.1772 - val_loss: -0.1364 - val_sharpe_ratio: 0.1752\n",
      "Epoch 250/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1341 - sharpe_ratio: 0.1729 - val_loss: -0.0938 - val_sharpe_ratio: 0.1777\n",
      "Epoch 251/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1400 - sharpe_ratio: 0.1733 - val_loss: -0.1073 - val_sharpe_ratio: 0.1797\n",
      "Epoch 252/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1344 - sharpe_ratio: 0.1725 - val_loss: -0.1935 - val_sharpe_ratio: 0.2418\n",
      "Epoch 253/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1164 - sharpe_ratio: 0.1712 - val_loss: -0.1931 - val_sharpe_ratio: 0.2246\n",
      "Epoch 254/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1434 - sharpe_ratio: 0.1780 - val_loss: -0.0906 - val_sharpe_ratio: 0.1553\n",
      "Epoch 255/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1184 - sharpe_ratio: 0.1654 - val_loss: -0.0209 - val_sharpe_ratio: 0.0919\n",
      "Epoch 256/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1347 - sharpe_ratio: 0.1781 - val_loss: -0.1022 - val_sharpe_ratio: 0.1069\n",
      "Epoch 257/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1349 - sharpe_ratio: 0.1660 - val_loss: -0.1656 - val_sharpe_ratio: 0.1920\n",
      "Epoch 258/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1363 - sharpe_ratio: 0.1691 - val_loss: -0.2126 - val_sharpe_ratio: 0.2430\n",
      "Epoch 259/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1222 - sharpe_ratio: 0.1711 - val_loss: -0.1698 - val_sharpe_ratio: 0.2187\n",
      "Epoch 260/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1278 - sharpe_ratio: 0.1660 - val_loss: -0.1269 - val_sharpe_ratio: 0.1431\n",
      "Epoch 261/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1271 - sharpe_ratio: 0.1725 - val_loss: -0.1571 - val_sharpe_ratio: 0.2477\n",
      "Epoch 262/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1175 - sharpe_ratio: 0.1686 - val_loss: -0.2109 - val_sharpe_ratio: 0.2627\n",
      "Epoch 263/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1392 - sharpe_ratio: 0.1695 - val_loss: -0.1415 - val_sharpe_ratio: 0.1879\n",
      "Epoch 264/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1419 - sharpe_ratio: 0.1728 - val_loss: -0.0788 - val_sharpe_ratio: 0.1579\n",
      "Epoch 265/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1364 - sharpe_ratio: 0.1729 - val_loss: -0.2165 - val_sharpe_ratio: 0.2955\n",
      "Epoch 266/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: -0.1380 - sharpe_ratio: 0.1758 - val_loss: -0.1604 - val_sharpe_ratio: 0.2350\n",
      "Epoch 267/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1212 - sharpe_ratio: 0.1639 - val_loss: -0.1880 - val_sharpe_ratio: 0.2329\n",
      "Epoch 268/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1438 - sharpe_ratio: 0.1712 - val_loss: -0.1402 - val_sharpe_ratio: 0.1963\n",
      "Epoch 269/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1301 - sharpe_ratio: 0.1688 - val_loss: -0.1359 - val_sharpe_ratio: 0.2143\n",
      "Epoch 270/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1356 - sharpe_ratio: 0.1766 - val_loss: -0.1589 - val_sharpe_ratio: 0.1987\n",
      "Epoch 271/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1428 - sharpe_ratio: 0.1815 - val_loss: -0.1166 - val_sharpe_ratio: 0.0859\n",
      "Epoch 272/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1326 - sharpe_ratio: 0.1750 - val_loss: -0.1408 - val_sharpe_ratio: 0.2173\n",
      "Epoch 273/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1402 - sharpe_ratio: 0.1692 - val_loss: -0.2061 - val_sharpe_ratio: 0.2731\n",
      "Epoch 274/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1340 - sharpe_ratio: 0.1781 - val_loss: -0.0949 - val_sharpe_ratio: 0.1519\n",
      "Epoch 275/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1283 - sharpe_ratio: 0.1688 - val_loss: -0.0299 - val_sharpe_ratio: 0.1096\n",
      "Epoch 276/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1139 - sharpe_ratio: 0.1696 - val_loss: -0.1614 - val_sharpe_ratio: 0.2122\n",
      "Epoch 277/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1146 - sharpe_ratio: 0.1772 - val_loss: -0.1977 - val_sharpe_ratio: 0.2301\n",
      "Epoch 278/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1068 - sharpe_ratio: 0.1690 - val_loss: -0.1680 - val_sharpe_ratio: 0.2537\n",
      "Epoch 279/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.0805 - sharpe_ratio: 0.1703 - val_loss: -0.1295 - val_sharpe_ratio: 0.2112\n",
      "Epoch 280/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1431 - sharpe_ratio: 0.1702 - val_loss: -0.2052 - val_sharpe_ratio: 0.2427\n",
      "Epoch 281/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: -0.1464 - sharpe_ratio: 0.1778 - val_loss: -0.1098 - val_sharpe_ratio: 0.1338\n",
      "Epoch 282/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: -0.1450 - sharpe_ratio: 0.1727 - val_loss: -0.1045 - val_sharpe_ratio: 0.1439\n",
      "Epoch 283/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: -0.1358 - sharpe_ratio: 0.1723 - val_loss: -0.2107 - val_sharpe_ratio: 0.2454\n",
      "Epoch 284/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: -0.1303 - sharpe_ratio: 0.1703 - val_loss: -0.1927 - val_sharpe_ratio: 0.2257\n",
      "Epoch 285/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1358 - sharpe_ratio: 0.1738 - val_loss: -0.1340 - val_sharpe_ratio: 0.2205\n",
      "Epoch 286/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1370 - sharpe_ratio: 0.1747 - val_loss: -0.1536 - val_sharpe_ratio: 0.2067\n",
      "Epoch 287/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1479 - sharpe_ratio: 0.1685 - val_loss: -0.2224 - val_sharpe_ratio: 0.2344\n",
      "Epoch 288/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1360 - sharpe_ratio: 0.1653 - val_loss: -0.2058 - val_sharpe_ratio: 0.2253\n",
      "Epoch 289/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1280 - sharpe_ratio: 0.1545 - val_loss: -0.1467 - val_sharpe_ratio: 0.2006\n",
      "Epoch 290/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: -0.1311 - sharpe_ratio: 0.1670 - val_loss: -0.1924 - val_sharpe_ratio: 0.2286\n",
      "Epoch 291/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1341 - sharpe_ratio: 0.1683 - val_loss: -0.1150 - val_sharpe_ratio: 0.1915\n",
      "Epoch 292/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1285 - sharpe_ratio: 0.1637 - val_loss: -0.1262 - val_sharpe_ratio: 0.2064\n",
      "Epoch 293/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: -0.1226 - sharpe_ratio: 0.1695 - val_loss: -0.1888 - val_sharpe_ratio: 0.1869\n",
      "Epoch 294/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1382 - sharpe_ratio: 0.1718 - val_loss: -0.0567 - val_sharpe_ratio: 0.1019\n",
      "Epoch 295/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1171 - sharpe_ratio: 0.1702 - val_loss: -0.1005 - val_sharpe_ratio: 0.1672\n",
      "Epoch 296/300\n",
      "55/55 [==============================] - 2s 29ms/step - loss: -0.1022 - sharpe_ratio: 0.1663 - val_loss: -0.1711 - val_sharpe_ratio: 0.1814\n",
      "Epoch 297/300\n",
      "55/55 [==============================] - 2s 30ms/step - loss: -0.1324 - sharpe_ratio: 0.1703 - val_loss: -0.1844 - val_sharpe_ratio: 0.2371\n",
      "Epoch 298/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1479 - sharpe_ratio: 0.1716 - val_loss: -0.1885 - val_sharpe_ratio: 0.2352\n",
      "Epoch 299/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1444 - sharpe_ratio: 0.1683 - val_loss: -0.1302 - val_sharpe_ratio: 0.1918\n",
      "Epoch 300/300\n",
      "55/55 [==============================] - 2s 28ms/step - loss: -0.1186 - sharpe_ratio: 0.1723 - val_loss: -0.0889 - val_sharpe_ratio: 0.1710\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "There are total 11 samples to predict\n",
      "Sample 0 : [ HDFCBANK.NS MARUTI.NS ]\n",
      "Sample 1 : [ HDFCBANK.NS MARUTI.NS SUNPHARMA.NS ]\n",
      "Sample 2 : [ HCLTECH.NS HDFCBANK.NS INFY.NS MARUTI.NS SUNPHARMA.NS ]\n",
      "Sample 3 : [ HDFCBANK.NS MARUTI.NS SUNPHARMA.NS ]\n",
      "Sample 4 : [ DRREDDY.NS HDFC.NS MARUTI.NS ]\n",
      "Sample 5 : [ HCLTECH.NS HDFCBANK.NS INFY.NS MARUTI.NS SUNPHARMA.NS ]\n",
      "Sample 6 : [ HCLTECH.NS HDFCBANK.NS INFY.NS MARUTI.NS SUNPHARMA.NS ]\n",
      "Sample 7 : [ HCLTECH.NS HDFCBANK.NS INFY.NS MARUTI.NS SUNPHARMA.NS ]\n",
      "Sample 8 : [ HCLTECH.NS HDFCBANK.NS INFY.NS MARUTI.NS SUNPHARMA.NS ]\n",
      "Sample 9 : [ HCLTECH.NS HDFCBANK.NS INFY.NS MARUTI.NS SUNPHARMA.NS ]\n",
      "Sample 10 : [ HCLTECH.NS HDFCBANK.NS INFY.NS MARUTI.NS SUNPHARMA.NS ]\n",
      "Sharpe ratio of this portfolio: [2.1553652294404233, 0.1633339064006492, -0.10477477932336088, 1.914966837453154, -1.6841011982013296, 0.33695552599711837, 0.5838845070979848, 0.33185406469863155, 0.11055302623143556, 2.297423456627567, 2.095545915304265]\n",
      "write file log at C:/Users/yv67/Documents/12FundsHK_ToShare/deeplearningdata/logs/GRU\\log_1085.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1309 - sharpe_ratio: 0.1793 - val_loss: -8.7459e-04 - val_sharpe_ratio: 0.0412\n",
      "Epoch 2/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1378 - sharpe_ratio: 0.1774 - val_loss: 0.0040 - val_sharpe_ratio: 0.0533\n",
      "Epoch 3/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1522 - sharpe_ratio: 0.1815 - val_loss: -6.6026e-04 - val_sharpe_ratio: 0.0183\n",
      "Epoch 4/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1378 - sharpe_ratio: 0.1763 - val_loss: -0.0181 - val_sharpe_ratio: 0.0516\n",
      "Epoch 5/300\n",
      "68/68 [==============================] - 2s 35ms/step - loss: -0.1363 - sharpe_ratio: 0.1785 - val_loss: -0.0163 - val_sharpe_ratio: 0.0183\n",
      "Epoch 6/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1648 - sharpe_ratio: 0.1808 - val_loss: -0.0320 - val_sharpe_ratio: 0.0489\n",
      "Epoch 7/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1549 - sharpe_ratio: 0.1782 - val_loss: 0.0105 - val_sharpe_ratio: 0.0316\n",
      "Epoch 8/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1395 - sharpe_ratio: 0.1780 - val_loss: 0.0318 - val_sharpe_ratio: 0.0183\n",
      "Epoch 9/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1415 - sharpe_ratio: 0.1800 - val_loss: -0.0056 - val_sharpe_ratio: 0.0225\n",
      "Epoch 10/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1574 - sharpe_ratio: 0.1805 - val_loss: -0.0153 - val_sharpe_ratio: 0.0459\n",
      "Epoch 11/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1600 - sharpe_ratio: 0.1847 - val_loss: 0.0110 - val_sharpe_ratio: 0.0290\n",
      "Epoch 12/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1444 - sharpe_ratio: 0.1812 - val_loss: -0.0609 - val_sharpe_ratio: 0.0953\n",
      "Epoch 13/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1517 - sharpe_ratio: 0.1778 - val_loss: -0.0095 - val_sharpe_ratio: 0.0208\n",
      "Epoch 14/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1513 - sharpe_ratio: 0.1844 - val_loss: 6.7962e-04 - val_sharpe_ratio: 0.0431\n",
      "Epoch 15/300\n",
      "68/68 [==============================] - 2s 33ms/step - loss: -0.1485 - sharpe_ratio: 0.1850 - val_loss: 0.0459 - val_sharpe_ratio: 0.0050\n",
      "Epoch 16/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1507 - sharpe_ratio: 0.1869 - val_loss: 0.0067 - val_sharpe_ratio: 0.0232\n",
      "Epoch 17/300\n",
      "68/68 [==============================] - 2s 33ms/step - loss: -0.1491 - sharpe_ratio: 0.1815 - val_loss: 9.9174e-04 - val_sharpe_ratio: 0.0183\n",
      "Epoch 18/300\n",
      "68/68 [==============================] - 2s 36ms/step - loss: -0.1538 - sharpe_ratio: 0.1811 - val_loss: -0.0204 - val_sharpe_ratio: 0.0604\n",
      "Epoch 19/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1480 - sharpe_ratio: 0.1813 - val_loss: 0.0084 - val_sharpe_ratio: 0.0269\n",
      "Epoch 20/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1606 - sharpe_ratio: 0.1813 - val_loss: -0.0189 - val_sharpe_ratio: 0.0183\n",
      "Epoch 21/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1226 - sharpe_ratio: 0.1776 - val_loss: 0.0598 - val_sharpe_ratio: 0.0135\n",
      "Epoch 22/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1379 - sharpe_ratio: 0.1787 - val_loss: 0.0143 - val_sharpe_ratio: 0.0183\n",
      "Epoch 23/300\n",
      "68/68 [==============================] - 2s 35ms/step - loss: -0.1570 - sharpe_ratio: 0.1796 - val_loss: -0.0206 - val_sharpe_ratio: 0.0131\n",
      "Epoch 24/300\n",
      "68/68 [==============================] - 2s 33ms/step - loss: -0.1514 - sharpe_ratio: 0.1783 - val_loss: -0.0138 - val_sharpe_ratio: 0.0556\n",
      "Epoch 25/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1536 - sharpe_ratio: 0.1804 - val_loss: -0.0391 - val_sharpe_ratio: 0.0697\n",
      "Epoch 26/300\n",
      "68/68 [==============================] - 2s 35ms/step - loss: -0.1574 - sharpe_ratio: 0.1835 - val_loss: -0.0011 - val_sharpe_ratio: 0.0083\n",
      "Epoch 27/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1526 - sharpe_ratio: 0.1851 - val_loss: -0.0349 - val_sharpe_ratio: 0.0621\n",
      "Epoch 28/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1427 - sharpe_ratio: 0.1825 - val_loss: -0.0274 - val_sharpe_ratio: 0.0866\n",
      "Epoch 29/300\n",
      "68/68 [==============================] - 2s 35ms/step - loss: -0.1502 - sharpe_ratio: 0.1790 - val_loss: 0.0016 - val_sharpe_ratio: 0.0499\n",
      "Epoch 30/300\n",
      "68/68 [==============================] - 2s 34ms/step - loss: -0.1509 - sharpe_ratio: 0.1805 - val_loss: -0.0043 - val_sharpe_ratio: 0.0077\n",
      "Epoch 31/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1652 - sharpe_ratio: 0.1836 - val_loss: -0.0334 - val_sharpe_ratio: 0.0504\n",
      "Epoch 32/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1580 - sharpe_ratio: 0.1850 - val_loss: -0.0270 - val_sharpe_ratio: 0.0183\n",
      "Epoch 33/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1437 - sharpe_ratio: 0.1801 - val_loss: -0.0412 - val_sharpe_ratio: 0.0602\n",
      "Epoch 34/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1450 - sharpe_ratio: 0.1794 - val_loss: -0.0129 - val_sharpe_ratio: 0.0207\n",
      "Epoch 35/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1559 - sharpe_ratio: 0.1838 - val_loss: -0.0055 - val_sharpe_ratio: 0.0183\n",
      "Epoch 36/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1606 - sharpe_ratio: 0.1867 - val_loss: -0.0059 - val_sharpe_ratio: 0.0291\n",
      "Epoch 37/300\n",
      "68/68 [==============================] - 2s 35ms/step - loss: -0.1493 - sharpe_ratio: 0.1826 - val_loss: -0.0278 - val_sharpe_ratio: 0.0274\n",
      "Epoch 38/300\n",
      "68/68 [==============================] - 2s 35ms/step - loss: -0.1542 - sharpe_ratio: 0.1826 - val_loss: -0.0161 - val_sharpe_ratio: 0.0216\n",
      "Epoch 39/300\n",
      "68/68 [==============================] - 2s 34ms/step - loss: -0.1530 - sharpe_ratio: 0.1891 - val_loss: -0.0209 - val_sharpe_ratio: 0.0676\n",
      "Epoch 40/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1519 - sharpe_ratio: 0.1849 - val_loss: -0.0113 - val_sharpe_ratio: 0.0645\n",
      "Epoch 41/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1583 - sharpe_ratio: 0.1893 - val_loss: -0.0724 - val_sharpe_ratio: 0.0996\n",
      "Epoch 42/300\n",
      "68/68 [==============================] - 2s 34ms/step - loss: -0.1442 - sharpe_ratio: 0.1823 - val_loss: -0.0116 - val_sharpe_ratio: 0.0663\n",
      "Epoch 43/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1429 - sharpe_ratio: 0.1773 - val_loss: -0.0544 - val_sharpe_ratio: 0.1045\n",
      "Epoch 44/300\n",
      "68/68 [==============================] - 2s 34ms/step - loss: -0.1586 - sharpe_ratio: 0.1811 - val_loss: -0.0311 - val_sharpe_ratio: 0.0382\n",
      "Epoch 45/300\n",
      "68/68 [==============================] - 2s 33ms/step - loss: -0.1593 - sharpe_ratio: 0.1849 - val_loss: -0.0215 - val_sharpe_ratio: 0.0619\n",
      "Epoch 46/300\n",
      "68/68 [==============================] - 2s 37ms/step - loss: -0.1524 - sharpe_ratio: 0.1834 - val_loss: -0.0265 - val_sharpe_ratio: 0.0183\n",
      "Epoch 47/300\n",
      "68/68 [==============================] - 2s 35ms/step - loss: -0.1607 - sharpe_ratio: 0.1807 - val_loss: -0.0082 - val_sharpe_ratio: 0.0265\n",
      "Epoch 48/300\n",
      "68/68 [==============================] - 2s 34ms/step - loss: -0.1536 - sharpe_ratio: 0.1834 - val_loss: 3.7039e-04 - val_sharpe_ratio: 0.0266\n",
      "Epoch 49/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1623 - sharpe_ratio: 0.1909 - val_loss: -0.0154 - val_sharpe_ratio: 0.0564\n",
      "Epoch 50/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1405 - sharpe_ratio: 0.1859 - val_loss: 0.0574 - val_sharpe_ratio: 0.0323\n",
      "Epoch 51/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1448 - sharpe_ratio: 0.1835 - val_loss: -0.0105 - val_sharpe_ratio: 0.0412\n",
      "Epoch 52/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1504 - sharpe_ratio: 0.1838 - val_loss: 0.0012 - val_sharpe_ratio: 0.0183\n",
      "Epoch 53/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1468 - sharpe_ratio: 0.1817 - val_loss: -0.0104 - val_sharpe_ratio: 0.0376\n",
      "Epoch 54/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1551 - sharpe_ratio: 0.1880 - val_loss: -0.0171 - val_sharpe_ratio: 0.0423\n",
      "Epoch 55/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1425 - sharpe_ratio: 0.1799 - val_loss: -0.0657 - val_sharpe_ratio: 0.1030\n",
      "Epoch 56/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1507 - sharpe_ratio: 0.1884 - val_loss: -0.0382 - val_sharpe_ratio: 0.0862\n",
      "Epoch 57/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1548 - sharpe_ratio: 0.1873 - val_loss: -0.0272 - val_sharpe_ratio: 0.0757\n",
      "Epoch 58/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1545 - sharpe_ratio: 0.1855 - val_loss: -0.0050 - val_sharpe_ratio: 0.0183\n",
      "Epoch 59/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1576 - sharpe_ratio: 0.1844 - val_loss: 0.0785 - val_sharpe_ratio: -0.0376\n",
      "Epoch 60/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1516 - sharpe_ratio: 0.1867 - val_loss: -0.0152 - val_sharpe_ratio: 0.0378\n",
      "Epoch 61/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1570 - sharpe_ratio: 0.1830 - val_loss: -0.0072 - val_sharpe_ratio: 0.0196\n",
      "Epoch 62/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1638 - sharpe_ratio: 0.1861 - val_loss: -0.0287 - val_sharpe_ratio: 0.0531\n",
      "Epoch 63/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1631 - sharpe_ratio: 0.1817 - val_loss: -0.0079 - val_sharpe_ratio: 0.0451\n",
      "Epoch 64/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1661 - sharpe_ratio: 0.1892 - val_loss: -0.0046 - val_sharpe_ratio: 0.0302\n",
      "Epoch 65/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1639 - sharpe_ratio: 0.1863 - val_loss: -0.0157 - val_sharpe_ratio: 0.0423\n",
      "Epoch 66/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1585 - sharpe_ratio: 0.1849 - val_loss: 0.0072 - val_sharpe_ratio: 0.0266\n",
      "Epoch 67/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1499 - sharpe_ratio: 0.1819 - val_loss: -0.0407 - val_sharpe_ratio: 0.0649\n",
      "Epoch 68/300\n",
      "68/68 [==============================] - 2s 35ms/step - loss: -0.1514 - sharpe_ratio: 0.1886 - val_loss: 0.0140 - val_sharpe_ratio: 0.0253\n",
      "Epoch 69/300\n",
      "68/68 [==============================] - 2s 34ms/step - loss: -0.1463 - sharpe_ratio: 0.1862 - val_loss: -0.0118 - val_sharpe_ratio: 0.0569\n",
      "Epoch 70/300\n",
      "68/68 [==============================] - 2s 37ms/step - loss: -0.1585 - sharpe_ratio: 0.1842 - val_loss: 0.0159 - val_sharpe_ratio: -0.0296\n",
      "Epoch 71/300\n",
      "68/68 [==============================] - 2s 34ms/step - loss: -0.1577 - sharpe_ratio: 0.1864 - val_loss: -0.0013 - val_sharpe_ratio: 0.0438\n",
      "Epoch 72/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1590 - sharpe_ratio: 0.1869 - val_loss: -0.0443 - val_sharpe_ratio: 0.0789\n",
      "Epoch 73/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1651 - sharpe_ratio: 0.1886 - val_loss: -0.0054 - val_sharpe_ratio: 0.0266\n",
      "Epoch 74/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1557 - sharpe_ratio: 0.1869 - val_loss: 0.0460 - val_sharpe_ratio: -0.0376\n",
      "Epoch 75/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1518 - sharpe_ratio: 0.1855 - val_loss: -0.0098 - val_sharpe_ratio: 0.0134\n",
      "Epoch 76/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1559 - sharpe_ratio: 0.1811 - val_loss: 0.0066 - val_sharpe_ratio: 0.0183\n",
      "Epoch 77/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1572 - sharpe_ratio: 0.1861 - val_loss: 0.0382 - val_sharpe_ratio: -0.0252\n",
      "Epoch 78/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1549 - sharpe_ratio: 0.1843 - val_loss: -0.0226 - val_sharpe_ratio: 0.0493\n",
      "Epoch 79/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1581 - sharpe_ratio: 0.1894 - val_loss: -0.0408 - val_sharpe_ratio: 0.0866\n",
      "Epoch 80/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1578 - sharpe_ratio: 0.1863 - val_loss: -0.0340 - val_sharpe_ratio: 0.0756\n",
      "Epoch 81/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1512 - sharpe_ratio: 0.1796 - val_loss: -0.0216 - val_sharpe_ratio: 0.0511\n",
      "Epoch 82/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1473 - sharpe_ratio: 0.1818 - val_loss: -0.0422 - val_sharpe_ratio: 0.0789\n",
      "Epoch 83/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1595 - sharpe_ratio: 0.1867 - val_loss: 0.0100 - val_sharpe_ratio: 0.0266\n",
      "Epoch 84/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1366 - sharpe_ratio: 0.1723 - val_loss: -0.0217 - val_sharpe_ratio: 0.0531\n",
      "Epoch 85/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1563 - sharpe_ratio: 0.1863 - val_loss: -0.0499 - val_sharpe_ratio: 0.0789\n",
      "Epoch 86/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1554 - sharpe_ratio: 0.1858 - val_loss: 0.0024 - val_sharpe_ratio: -0.0267\n",
      "Epoch 87/300\n",
      "68/68 [==============================] - 2s 35ms/step - loss: -0.1672 - sharpe_ratio: 0.1931 - val_loss: -0.0409 - val_sharpe_ratio: 0.0789\n",
      "Epoch 88/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1536 - sharpe_ratio: 0.1879 - val_loss: -0.0138 - val_sharpe_ratio: 0.0598\n",
      "Epoch 89/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1514 - sharpe_ratio: 0.1866 - val_loss: -0.0472 - val_sharpe_ratio: 0.0783\n",
      "Epoch 90/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1668 - sharpe_ratio: 0.1899 - val_loss: -0.0533 - val_sharpe_ratio: 0.0757\n",
      "Epoch 91/300\n",
      "68/68 [==============================] - 2s 34ms/step - loss: -0.1583 - sharpe_ratio: 0.1902 - val_loss: -0.0387 - val_sharpe_ratio: 0.0531\n",
      "Epoch 92/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1569 - sharpe_ratio: 0.1873 - val_loss: -0.0245 - val_sharpe_ratio: 0.0480\n",
      "Epoch 93/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1359 - sharpe_ratio: 0.1805 - val_loss: -0.0200 - val_sharpe_ratio: 0.0514\n",
      "Epoch 94/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1486 - sharpe_ratio: 0.1833 - val_loss: -0.0047 - val_sharpe_ratio: 0.0531\n",
      "Epoch 95/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1575 - sharpe_ratio: 0.1951 - val_loss: -0.0390 - val_sharpe_ratio: 0.0918\n",
      "Epoch 96/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1426 - sharpe_ratio: 0.1863 - val_loss: -0.0374 - val_sharpe_ratio: 0.0531\n",
      "Epoch 97/300\n",
      "68/68 [==============================] - 2s 35ms/step - loss: -0.1601 - sharpe_ratio: 0.1916 - val_loss: -0.0291 - val_sharpe_ratio: 0.0531\n",
      "Epoch 98/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1521 - sharpe_ratio: 0.1842 - val_loss: -0.0200 - val_sharpe_ratio: 0.0531\n",
      "Epoch 99/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1519 - sharpe_ratio: 0.1904 - val_loss: 0.0289 - val_sharpe_ratio: 0.0183\n",
      "Epoch 100/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1542 - sharpe_ratio: 0.1875 - val_loss: -0.0073 - val_sharpe_ratio: -0.0028\n",
      "Epoch 101/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1480 - sharpe_ratio: 0.1828 - val_loss: -0.0428 - val_sharpe_ratio: 0.0486\n",
      "Epoch 102/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1561 - sharpe_ratio: 0.1857 - val_loss: -0.0250 - val_sharpe_ratio: 0.0560\n",
      "Epoch 103/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1495 - sharpe_ratio: 0.1871 - val_loss: -0.0246 - val_sharpe_ratio: 0.0664\n",
      "Epoch 104/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1537 - sharpe_ratio: 0.1866 - val_loss: -0.0178 - val_sharpe_ratio: 0.0577\n",
      "Epoch 105/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1424 - sharpe_ratio: 0.1867 - val_loss: -0.0264 - val_sharpe_ratio: 0.0567\n",
      "Epoch 106/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1596 - sharpe_ratio: 0.1908 - val_loss: 0.0242 - val_sharpe_ratio: -0.0020\n",
      "Epoch 107/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1539 - sharpe_ratio: 0.1892 - val_loss: -0.0203 - val_sharpe_ratio: 0.0421\n",
      "Epoch 108/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1467 - sharpe_ratio: 0.1859 - val_loss: -0.0037 - val_sharpe_ratio: 0.0639\n",
      "Epoch 109/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1504 - sharpe_ratio: 0.1871 - val_loss: -0.0095 - val_sharpe_ratio: 0.0266\n",
      "Epoch 110/300\n",
      "68/68 [==============================] - 2s 35ms/step - loss: -0.1548 - sharpe_ratio: 0.1878 - val_loss: -0.0162 - val_sharpe_ratio: 0.0619\n",
      "Epoch 111/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1420 - sharpe_ratio: 0.1887 - val_loss: -0.0027 - val_sharpe_ratio: 0.0456\n",
      "Epoch 112/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1487 - sharpe_ratio: 0.1885 - val_loss: -0.0166 - val_sharpe_ratio: 0.0689\n",
      "Epoch 113/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1546 - sharpe_ratio: 0.1923 - val_loss: -0.0033 - val_sharpe_ratio: 0.0474\n",
      "Epoch 114/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1516 - sharpe_ratio: 0.1876 - val_loss: -0.0508 - val_sharpe_ratio: 0.0868\n",
      "Epoch 115/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1471 - sharpe_ratio: 0.1904 - val_loss: 0.0050 - val_sharpe_ratio: 0.0204\n",
      "Epoch 116/300\n",
      "68/68 [==============================] - 2s 33ms/step - loss: -0.1507 - sharpe_ratio: 0.1877 - val_loss: -0.0165 - val_sharpe_ratio: 0.0451\n",
      "Epoch 117/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1491 - sharpe_ratio: 0.1831 - val_loss: -0.0490 - val_sharpe_ratio: 0.0838\n",
      "Epoch 118/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1584 - sharpe_ratio: 0.1887 - val_loss: -0.0264 - val_sharpe_ratio: 0.0789\n",
      "Epoch 119/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1591 - sharpe_ratio: 0.1921 - val_loss: -0.0218 - val_sharpe_ratio: 0.0562\n",
      "Epoch 120/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1659 - sharpe_ratio: 0.1932 - val_loss: -0.0143 - val_sharpe_ratio: 0.0501\n",
      "Epoch 121/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1470 - sharpe_ratio: 0.1881 - val_loss: -0.0555 - val_sharpe_ratio: 0.0910\n",
      "Epoch 122/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1547 - sharpe_ratio: 0.1850 - val_loss: -0.0493 - val_sharpe_ratio: 0.0778\n",
      "Epoch 123/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1518 - sharpe_ratio: 0.1878 - val_loss: -0.0474 - val_sharpe_ratio: 0.0979\n",
      "Epoch 124/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1459 - sharpe_ratio: 0.1853 - val_loss: -0.0143 - val_sharpe_ratio: 0.0619\n",
      "Epoch 125/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1514 - sharpe_ratio: 0.1891 - val_loss: -0.0773 - val_sharpe_ratio: 0.1173\n",
      "Epoch 126/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1577 - sharpe_ratio: 0.1910 - val_loss: -0.0421 - val_sharpe_ratio: 0.0912\n",
      "Epoch 127/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1475 - sharpe_ratio: 0.1858 - val_loss: -0.0831 - val_sharpe_ratio: 0.1039\n",
      "Epoch 128/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1585 - sharpe_ratio: 0.1899 - val_loss: -0.0212 - val_sharpe_ratio: 0.0497\n",
      "Epoch 129/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1508 - sharpe_ratio: 0.1886 - val_loss: -0.0126 - val_sharpe_ratio: 0.0618\n",
      "Epoch 130/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1610 - sharpe_ratio: 0.1907 - val_loss: -0.0862 - val_sharpe_ratio: 0.1149\n",
      "Epoch 131/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1387 - sharpe_ratio: 0.1855 - val_loss: 0.0040 - val_sharpe_ratio: 0.0230\n",
      "Epoch 132/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1396 - sharpe_ratio: 0.1862 - val_loss: 0.0142 - val_sharpe_ratio: 0.0571\n",
      "Epoch 133/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1502 - sharpe_ratio: 0.1916 - val_loss: 0.0431 - val_sharpe_ratio: 0.0082\n",
      "Epoch 134/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1384 - sharpe_ratio: 0.1837 - val_loss: -0.0012 - val_sharpe_ratio: 0.0895\n",
      "Epoch 135/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1438 - sharpe_ratio: 0.1904 - val_loss: -0.0092 - val_sharpe_ratio: 0.0832\n",
      "Epoch 136/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1509 - sharpe_ratio: 0.1852 - val_loss: -0.0734 - val_sharpe_ratio: 0.1122\n",
      "Epoch 137/300\n",
      "68/68 [==============================] - 2s 27ms/step - loss: -0.1556 - sharpe_ratio: 0.1936 - val_loss: -0.0404 - val_sharpe_ratio: 0.1191\n",
      "Epoch 138/300\n",
      "68/68 [==============================] - 2s 27ms/step - loss: -0.1437 - sharpe_ratio: 0.1898 - val_loss: 0.0269 - val_sharpe_ratio: -0.0061\n",
      "Epoch 139/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1561 - sharpe_ratio: 0.1974 - val_loss: -0.0567 - val_sharpe_ratio: 0.1015\n",
      "Epoch 140/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1480 - sharpe_ratio: 0.1856 - val_loss: -0.0527 - val_sharpe_ratio: 0.0841\n",
      "Epoch 141/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1523 - sharpe_ratio: 0.1906 - val_loss: -0.0419 - val_sharpe_ratio: 0.0822\n",
      "Epoch 142/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1346 - sharpe_ratio: 0.1896 - val_loss: 0.0234 - val_sharpe_ratio: 0.0412\n",
      "Epoch 143/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1458 - sharpe_ratio: 0.1822 - val_loss: -0.0680 - val_sharpe_ratio: 0.1202\n",
      "Epoch 144/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1570 - sharpe_ratio: 0.1991 - val_loss: -0.0280 - val_sharpe_ratio: 0.0763\n",
      "Epoch 145/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1522 - sharpe_ratio: 0.1908 - val_loss: -0.0392 - val_sharpe_ratio: 0.0789\n",
      "Epoch 146/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1534 - sharpe_ratio: 0.1930 - val_loss: -0.0792 - val_sharpe_ratio: 0.1286\n",
      "Epoch 147/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1535 - sharpe_ratio: 0.1898 - val_loss: -0.0423 - val_sharpe_ratio: 0.0864\n",
      "Epoch 148/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1535 - sharpe_ratio: 0.1879 - val_loss: 0.0351 - val_sharpe_ratio: -0.0142\n",
      "Epoch 149/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1632 - sharpe_ratio: 0.1961 - val_loss: -0.0775 - val_sharpe_ratio: 0.1235\n",
      "Epoch 150/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1683 - sharpe_ratio: 0.1986 - val_loss: -0.0980 - val_sharpe_ratio: 0.1291\n",
      "Epoch 151/300\n",
      "68/68 [==============================] - 2s 27ms/step - loss: -0.1605 - sharpe_ratio: 0.1901 - val_loss: -0.0726 - val_sharpe_ratio: 0.1006\n",
      "Epoch 152/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1620 - sharpe_ratio: 0.1905 - val_loss: -0.0811 - val_sharpe_ratio: 0.1215\n",
      "Epoch 153/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1579 - sharpe_ratio: 0.1951 - val_loss: -0.0591 - val_sharpe_ratio: 0.1106\n",
      "Epoch 154/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1504 - sharpe_ratio: 0.1870 - val_loss: -0.0070 - val_sharpe_ratio: 0.0557\n",
      "Epoch 155/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1603 - sharpe_ratio: 0.1953 - val_loss: -0.0199 - val_sharpe_ratio: 0.0545\n",
      "Epoch 156/300\n",
      "68/68 [==============================] - 2s 27ms/step - loss: -0.1666 - sharpe_ratio: 0.1942 - val_loss: -0.0651 - val_sharpe_ratio: 0.1252\n",
      "Epoch 157/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1555 - sharpe_ratio: 0.1988 - val_loss: -0.0474 - val_sharpe_ratio: 0.0846\n",
      "Epoch 158/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1438 - sharpe_ratio: 0.1935 - val_loss: -0.0573 - val_sharpe_ratio: 0.1203\n",
      "Epoch 159/300\n",
      "68/68 [==============================] - 2s 27ms/step - loss: -0.1487 - sharpe_ratio: 0.1902 - val_loss: -0.0593 - val_sharpe_ratio: 0.1335\n",
      "Epoch 160/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1583 - sharpe_ratio: 0.1940 - val_loss: 0.0308 - val_sharpe_ratio: 0.0090\n",
      "Epoch 161/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1502 - sharpe_ratio: 0.1881 - val_loss: -0.0055 - val_sharpe_ratio: 0.0470\n",
      "Epoch 162/300\n",
      "68/68 [==============================] - 2s 33ms/step - loss: -0.1409 - sharpe_ratio: 0.1869 - val_loss: -0.0607 - val_sharpe_ratio: 0.0871\n",
      "Epoch 163/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1333 - sharpe_ratio: 0.1865 - val_loss: 0.0021 - val_sharpe_ratio: 0.0760\n",
      "Epoch 164/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1445 - sharpe_ratio: 0.1983 - val_loss: -0.0155 - val_sharpe_ratio: 0.0469\n",
      "Epoch 165/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1439 - sharpe_ratio: 0.1869 - val_loss: -0.0011 - val_sharpe_ratio: 0.0370\n",
      "Epoch 166/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1249 - sharpe_ratio: 0.1826 - val_loss: -0.0158 - val_sharpe_ratio: 0.0660\n",
      "Epoch 167/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1300 - sharpe_ratio: 0.1876 - val_loss: -0.0539 - val_sharpe_ratio: 0.1040\n",
      "Epoch 168/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1443 - sharpe_ratio: 0.1888 - val_loss: -0.0433 - val_sharpe_ratio: 0.0778\n",
      "Epoch 169/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1365 - sharpe_ratio: 0.1868 - val_loss: 0.0155 - val_sharpe_ratio: -0.0177\n",
      "Epoch 170/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1569 - sharpe_ratio: 0.1994 - val_loss: -0.0763 - val_sharpe_ratio: 0.1110\n",
      "Epoch 171/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1509 - sharpe_ratio: 0.1964 - val_loss: -0.0460 - val_sharpe_ratio: 0.0911\n",
      "Epoch 172/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1321 - sharpe_ratio: 0.1882 - val_loss: -0.0873 - val_sharpe_ratio: 0.1181\n",
      "Epoch 173/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1467 - sharpe_ratio: 0.1908 - val_loss: -0.0201 - val_sharpe_ratio: 0.0585\n",
      "Epoch 174/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1532 - sharpe_ratio: 0.1935 - val_loss: -0.0335 - val_sharpe_ratio: 0.0747\n",
      "Epoch 175/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1559 - sharpe_ratio: 0.1967 - val_loss: -0.0444 - val_sharpe_ratio: 0.0962\n",
      "Epoch 176/300\n",
      "68/68 [==============================] - 2s 27ms/step - loss: -0.1569 - sharpe_ratio: 0.1988 - val_loss: -0.0304 - val_sharpe_ratio: 0.0947\n",
      "Epoch 177/300\n",
      "68/68 [==============================] - 2s 27ms/step - loss: -0.1468 - sharpe_ratio: 0.1897 - val_loss: -0.0540 - val_sharpe_ratio: 0.1214\n",
      "Epoch 178/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1184 - sharpe_ratio: 0.1869 - val_loss: 0.0083 - val_sharpe_ratio: 0.0689\n",
      "Epoch 179/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1443 - sharpe_ratio: 0.1980 - val_loss: -0.0234 - val_sharpe_ratio: 0.0586\n",
      "Epoch 180/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1346 - sharpe_ratio: 0.1923 - val_loss: -0.0082 - val_sharpe_ratio: 0.0699\n",
      "Epoch 181/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1520 - sharpe_ratio: 0.1967 - val_loss: 0.0063 - val_sharpe_ratio: 0.0303\n",
      "Epoch 182/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1517 - sharpe_ratio: 0.1867 - val_loss: -0.0422 - val_sharpe_ratio: 0.0843\n",
      "Epoch 183/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1538 - sharpe_ratio: 0.1914 - val_loss: -0.0811 - val_sharpe_ratio: 0.1252\n",
      "Epoch 184/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1508 - sharpe_ratio: 0.1888 - val_loss: -0.0281 - val_sharpe_ratio: 0.0649\n",
      "Epoch 185/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1491 - sharpe_ratio: 0.1958 - val_loss: -0.0393 - val_sharpe_ratio: 0.0920\n",
      "Epoch 186/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1424 - sharpe_ratio: 0.1894 - val_loss: -0.0601 - val_sharpe_ratio: 0.0683\n",
      "Epoch 187/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1391 - sharpe_ratio: 0.1897 - val_loss: -0.0434 - val_sharpe_ratio: 0.0881\n",
      "Epoch 188/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1561 - sharpe_ratio: 0.1923 - val_loss: -0.0886 - val_sharpe_ratio: 0.1500\n",
      "Epoch 189/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1381 - sharpe_ratio: 0.1948 - val_loss: -0.0201 - val_sharpe_ratio: 0.0724\n",
      "Epoch 190/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1386 - sharpe_ratio: 0.1911 - val_loss: 0.1140 - val_sharpe_ratio: -0.0128\n",
      "Epoch 191/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1362 - sharpe_ratio: 0.1920 - val_loss: -0.0530 - val_sharpe_ratio: 0.1198\n",
      "Epoch 192/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1425 - sharpe_ratio: 0.1912 - val_loss: -0.0211 - val_sharpe_ratio: 0.0802\n",
      "Epoch 193/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1475 - sharpe_ratio: 0.1893 - val_loss: 0.0163 - val_sharpe_ratio: 0.0282\n",
      "Epoch 194/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1380 - sharpe_ratio: 0.1835 - val_loss: -0.0015 - val_sharpe_ratio: 0.0675\n",
      "Epoch 195/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1476 - sharpe_ratio: 0.1889 - val_loss: -0.0931 - val_sharpe_ratio: 0.1359\n",
      "Epoch 196/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1525 - sharpe_ratio: 0.1922 - val_loss: -0.0164 - val_sharpe_ratio: 0.0570\n",
      "Epoch 197/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1101 - sharpe_ratio: 0.1893 - val_loss: -0.0557 - val_sharpe_ratio: 0.1088\n",
      "Epoch 198/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1388 - sharpe_ratio: 0.1859 - val_loss: -0.0300 - val_sharpe_ratio: 0.0668\n",
      "Epoch 199/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1435 - sharpe_ratio: 0.1945 - val_loss: -0.0786 - val_sharpe_ratio: 0.1148\n",
      "Epoch 200/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1493 - sharpe_ratio: 0.1969 - val_loss: 0.0194 - val_sharpe_ratio: 0.0233\n",
      "Epoch 201/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1436 - sharpe_ratio: 0.1938 - val_loss: -0.0097 - val_sharpe_ratio: 0.0935\n",
      "Epoch 202/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1402 - sharpe_ratio: 0.1936 - val_loss: -0.0401 - val_sharpe_ratio: 0.0959\n",
      "Epoch 203/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1567 - sharpe_ratio: 0.1973 - val_loss: -0.0322 - val_sharpe_ratio: 0.0782\n",
      "Epoch 204/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1523 - sharpe_ratio: 0.1939 - val_loss: -0.0931 - val_sharpe_ratio: 0.1320\n",
      "Epoch 205/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1563 - sharpe_ratio: 0.1974 - val_loss: -0.0742 - val_sharpe_ratio: 0.1242\n",
      "Epoch 206/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1588 - sharpe_ratio: 0.1945 - val_loss: -0.0696 - val_sharpe_ratio: 0.1292\n",
      "Epoch 207/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1428 - sharpe_ratio: 0.1926 - val_loss: -0.0335 - val_sharpe_ratio: 0.0912\n",
      "Epoch 208/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1466 - sharpe_ratio: 0.1938 - val_loss: -0.0510 - val_sharpe_ratio: 0.0862\n",
      "Epoch 209/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1560 - sharpe_ratio: 0.1958 - val_loss: 0.0509 - val_sharpe_ratio: 0.0167\n",
      "Epoch 210/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1401 - sharpe_ratio: 0.1935 - val_loss: 0.0764 - val_sharpe_ratio: -0.0320\n",
      "Epoch 211/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1530 - sharpe_ratio: 0.1943 - val_loss: 0.0208 - val_sharpe_ratio: 0.0258\n",
      "Epoch 212/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1535 - sharpe_ratio: 0.1959 - val_loss: -0.0336 - val_sharpe_ratio: 0.0680\n",
      "Epoch 213/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1542 - sharpe_ratio: 0.1961 - val_loss: -0.0592 - val_sharpe_ratio: 0.1014\n",
      "Epoch 214/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1374 - sharpe_ratio: 0.1873 - val_loss: -0.0334 - val_sharpe_ratio: 0.0887\n",
      "Epoch 215/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1586 - sharpe_ratio: 0.1955 - val_loss: -0.0410 - val_sharpe_ratio: 0.0915\n",
      "Epoch 216/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1542 - sharpe_ratio: 0.1918 - val_loss: -0.0618 - val_sharpe_ratio: 0.1055\n",
      "Epoch 217/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1455 - sharpe_ratio: 0.1941 - val_loss: 0.0129 - val_sharpe_ratio: 0.0259\n",
      "Epoch 218/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1403 - sharpe_ratio: 0.1883 - val_loss: -0.0369 - val_sharpe_ratio: 0.1194\n",
      "Epoch 219/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1384 - sharpe_ratio: 0.1965 - val_loss: 0.0362 - val_sharpe_ratio: 0.0284\n",
      "Epoch 220/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1481 - sharpe_ratio: 0.1983 - val_loss: 0.0032 - val_sharpe_ratio: 0.0685\n",
      "Epoch 221/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1531 - sharpe_ratio: 0.1987 - val_loss: -0.0191 - val_sharpe_ratio: 0.0651\n",
      "Epoch 222/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1464 - sharpe_ratio: 0.1942 - val_loss: 0.0248 - val_sharpe_ratio: 0.0397\n",
      "Epoch 223/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1489 - sharpe_ratio: 0.1961 - val_loss: -0.0676 - val_sharpe_ratio: 0.1171\n",
      "Epoch 224/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1573 - sharpe_ratio: 0.1994 - val_loss: -0.0489 - val_sharpe_ratio: 0.0895\n",
      "Epoch 225/300\n",
      "68/68 [==============================] - 2s 27ms/step - loss: -0.1485 - sharpe_ratio: 0.1916 - val_loss: -0.0683 - val_sharpe_ratio: 0.1216\n",
      "Epoch 226/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1423 - sharpe_ratio: 0.1924 - val_loss: 0.0168 - val_sharpe_ratio: 0.0477\n",
      "Epoch 227/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1539 - sharpe_ratio: 0.1943 - val_loss: -0.0456 - val_sharpe_ratio: 0.0844\n",
      "Epoch 228/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1368 - sharpe_ratio: 0.1888 - val_loss: 0.0195 - val_sharpe_ratio: 0.0276\n",
      "Epoch 229/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1557 - sharpe_ratio: 0.1935 - val_loss: 0.0652 - val_sharpe_ratio: -0.0114\n",
      "Epoch 230/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1482 - sharpe_ratio: 0.1891 - val_loss: -0.0093 - val_sharpe_ratio: 0.0577\n",
      "Epoch 231/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1545 - sharpe_ratio: 0.1952 - val_loss: -0.0316 - val_sharpe_ratio: 0.0536\n",
      "Epoch 232/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1496 - sharpe_ratio: 0.1970 - val_loss: -0.0026 - val_sharpe_ratio: 0.0490\n",
      "Epoch 233/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1418 - sharpe_ratio: 0.1914 - val_loss: -0.0394 - val_sharpe_ratio: 0.0871\n",
      "Epoch 234/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1453 - sharpe_ratio: 0.1902 - val_loss: -0.0410 - val_sharpe_ratio: 0.1018\n",
      "Epoch 235/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1420 - sharpe_ratio: 0.1924 - val_loss: -0.0566 - val_sharpe_ratio: 0.0926\n",
      "Epoch 236/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1559 - sharpe_ratio: 0.1966 - val_loss: 0.0075 - val_sharpe_ratio: 0.0430\n",
      "Epoch 237/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1576 - sharpe_ratio: 0.1981 - val_loss: -0.0411 - val_sharpe_ratio: 0.0800\n",
      "Epoch 238/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1541 - sharpe_ratio: 0.1976 - val_loss: -0.0329 - val_sharpe_ratio: 0.0732\n",
      "Epoch 239/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1573 - sharpe_ratio: 0.1929 - val_loss: 0.0852 - val_sharpe_ratio: -0.0362\n",
      "Epoch 240/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1506 - sharpe_ratio: 0.1964 - val_loss: -0.0263 - val_sharpe_ratio: 0.0871\n",
      "Epoch 241/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1527 - sharpe_ratio: 0.1975 - val_loss: -0.0849 - val_sharpe_ratio: 0.1249\n",
      "Epoch 242/300\n",
      "68/68 [==============================] - 2s 35ms/step - loss: -0.1489 - sharpe_ratio: 0.1956 - val_loss: -0.0505 - val_sharpe_ratio: 0.1156\n",
      "Epoch 243/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1417 - sharpe_ratio: 0.1868 - val_loss: 0.0097 - val_sharpe_ratio: 0.0587\n",
      "Epoch 244/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1384 - sharpe_ratio: 0.1903 - val_loss: -0.0292 - val_sharpe_ratio: 0.0871\n",
      "Epoch 245/300\n",
      "68/68 [==============================] - 2s 34ms/step - loss: -0.1359 - sharpe_ratio: 0.1911 - val_loss: -0.0477 - val_sharpe_ratio: 0.0993\n",
      "Epoch 246/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1324 - sharpe_ratio: 0.1974 - val_loss: -0.0580 - val_sharpe_ratio: 0.1147\n",
      "Epoch 247/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1419 - sharpe_ratio: 0.1912 - val_loss: -0.0818 - val_sharpe_ratio: 0.1484\n",
      "Epoch 248/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1487 - sharpe_ratio: 0.2014 - val_loss: -0.0426 - val_sharpe_ratio: 0.0938\n",
      "Epoch 249/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1457 - sharpe_ratio: 0.1897 - val_loss: 0.0212 - val_sharpe_ratio: 0.0267\n",
      "Epoch 250/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1509 - sharpe_ratio: 0.1950 - val_loss: 0.0117 - val_sharpe_ratio: 0.0283\n",
      "Epoch 251/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1499 - sharpe_ratio: 0.2003 - val_loss: -0.0945 - val_sharpe_ratio: 0.1369\n",
      "Epoch 252/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1575 - sharpe_ratio: 0.1948 - val_loss: -0.0131 - val_sharpe_ratio: 0.0487\n",
      "Epoch 253/300\n",
      "68/68 [==============================] - 2s 35ms/step - loss: -0.1381 - sharpe_ratio: 0.1897 - val_loss: -0.0763 - val_sharpe_ratio: 0.1357\n",
      "Epoch 254/300\n",
      "68/68 [==============================] - 2s 33ms/step - loss: -0.1512 - sharpe_ratio: 0.1963 - val_loss: -0.0632 - val_sharpe_ratio: 0.1276\n",
      "Epoch 255/300\n",
      "68/68 [==============================] - 2s 34ms/step - loss: -0.1482 - sharpe_ratio: 0.1926 - val_loss: -0.0342 - val_sharpe_ratio: 0.0941\n",
      "Epoch 256/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1457 - sharpe_ratio: 0.1948 - val_loss: -0.0245 - val_sharpe_ratio: 0.0884\n",
      "Epoch 257/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1362 - sharpe_ratio: 0.1863 - val_loss: -0.0162 - val_sharpe_ratio: 0.0250\n",
      "Epoch 258/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1464 - sharpe_ratio: 0.2005 - val_loss: -0.0610 - val_sharpe_ratio: 0.0826\n",
      "Epoch 259/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1620 - sharpe_ratio: 0.1948 - val_loss: -0.0138 - val_sharpe_ratio: 0.0601\n",
      "Epoch 260/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1560 - sharpe_ratio: 0.1946 - val_loss: -0.0553 - val_sharpe_ratio: 0.1098\n",
      "Epoch 261/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1540 - sharpe_ratio: 0.1969 - val_loss: 0.0227 - val_sharpe_ratio: 0.0408\n",
      "Epoch 262/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1427 - sharpe_ratio: 0.1893 - val_loss: -0.0171 - val_sharpe_ratio: 0.0658\n",
      "Epoch 263/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1491 - sharpe_ratio: 0.2013 - val_loss: -0.0619 - val_sharpe_ratio: 0.1378\n",
      "Epoch 264/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1485 - sharpe_ratio: 0.1948 - val_loss: -0.0076 - val_sharpe_ratio: 0.0297\n",
      "Epoch 265/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1338 - sharpe_ratio: 0.1891 - val_loss: -0.0080 - val_sharpe_ratio: 0.0481\n",
      "Epoch 266/300\n",
      "68/68 [==============================] - 2s 35ms/step - loss: -0.1516 - sharpe_ratio: 0.1918 - val_loss: 0.0112 - val_sharpe_ratio: 0.0265\n",
      "Epoch 267/300\n",
      "68/68 [==============================] - 2s 33ms/step - loss: -0.1559 - sharpe_ratio: 0.1932 - val_loss: -0.0617 - val_sharpe_ratio: 0.1140\n",
      "Epoch 268/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1457 - sharpe_ratio: 0.1953 - val_loss: 0.0207 - val_sharpe_ratio: 0.0407\n",
      "Epoch 269/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1419 - sharpe_ratio: 0.1922 - val_loss: -0.1057 - val_sharpe_ratio: 0.1573\n",
      "Epoch 270/300\n",
      "68/68 [==============================] - 2s 33ms/step - loss: -0.1545 - sharpe_ratio: 0.1931 - val_loss: -0.0597 - val_sharpe_ratio: 0.1028\n",
      "Epoch 271/300\n",
      "68/68 [==============================] - 3s 37ms/step - loss: -0.1563 - sharpe_ratio: 0.1921 - val_loss: -0.0488 - val_sharpe_ratio: 0.0966\n",
      "Epoch 272/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1527 - sharpe_ratio: 0.1959 - val_loss: -0.0498 - val_sharpe_ratio: 0.0946\n",
      "Epoch 273/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1453 - sharpe_ratio: 0.1918 - val_loss: -0.0354 - val_sharpe_ratio: 0.0647\n",
      "Epoch 274/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1458 - sharpe_ratio: 0.1875 - val_loss: -0.0912 - val_sharpe_ratio: 0.1691\n",
      "Epoch 275/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1450 - sharpe_ratio: 0.1919 - val_loss: -0.0869 - val_sharpe_ratio: 0.1543\n",
      "Epoch 276/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1471 - sharpe_ratio: 0.1937 - val_loss: -0.0453 - val_sharpe_ratio: 0.0897\n",
      "Epoch 277/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1403 - sharpe_ratio: 0.2012 - val_loss: -0.0370 - val_sharpe_ratio: 0.1076\n",
      "Epoch 278/300\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.1415 - sharpe_ratio: 0.1916 - val_loss: 0.0099 - val_sharpe_ratio: 0.0427\n",
      "Epoch 279/300\n",
      "68/68 [==============================] - 2s 37ms/step - loss: -0.1478 - sharpe_ratio: 0.1899 - val_loss: -0.0506 - val_sharpe_ratio: 0.0982\n",
      "Epoch 280/300\n",
      "68/68 [==============================] - 2s 34ms/step - loss: -0.1582 - sharpe_ratio: 0.2014 - val_loss: -0.0837 - val_sharpe_ratio: 0.1068\n",
      "Epoch 281/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1481 - sharpe_ratio: 0.1957 - val_loss: -0.0543 - val_sharpe_ratio: 0.0722\n",
      "Epoch 282/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1519 - sharpe_ratio: 0.1952 - val_loss: 0.0158 - val_sharpe_ratio: 0.0401\n",
      "Epoch 283/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1391 - sharpe_ratio: 0.1898 - val_loss: -0.0097 - val_sharpe_ratio: 0.0488\n",
      "Epoch 284/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1498 - sharpe_ratio: 0.1925 - val_loss: -0.0734 - val_sharpe_ratio: 0.1329\n",
      "Epoch 285/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1506 - sharpe_ratio: 0.1957 - val_loss: -0.0647 - val_sharpe_ratio: 0.1063\n",
      "Epoch 286/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1573 - sharpe_ratio: 0.1926 - val_loss: -0.0435 - val_sharpe_ratio: 0.0835\n",
      "Epoch 287/300\n",
      "68/68 [==============================] - 2s 32ms/step - loss: -0.1427 - sharpe_ratio: 0.1885 - val_loss: -0.0414 - val_sharpe_ratio: 0.1050\n",
      "Epoch 288/300\n",
      "68/68 [==============================] - 2s 27ms/step - loss: -0.1391 - sharpe_ratio: 0.1899 - val_loss: 0.0282 - val_sharpe_ratio: 0.0595\n",
      "Epoch 289/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1337 - sharpe_ratio: 0.1873 - val_loss: -0.0219 - val_sharpe_ratio: 0.0835\n",
      "Epoch 290/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1323 - sharpe_ratio: 0.1901 - val_loss: -0.0771 - val_sharpe_ratio: 0.1436\n",
      "Epoch 291/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1434 - sharpe_ratio: 0.2022 - val_loss: -0.0144 - val_sharpe_ratio: 0.0650\n",
      "Epoch 292/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1258 - sharpe_ratio: 0.1823 - val_loss: -0.0253 - val_sharpe_ratio: 0.0741\n",
      "Epoch 293/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1493 - sharpe_ratio: 0.1933 - val_loss: 0.0060 - val_sharpe_ratio: 0.0293\n",
      "Epoch 294/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1469 - sharpe_ratio: 0.1979 - val_loss: -0.0233 - val_sharpe_ratio: 0.0949\n",
      "Epoch 295/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1476 - sharpe_ratio: 0.1963 - val_loss: -0.0487 - val_sharpe_ratio: 0.1209\n",
      "Epoch 296/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1359 - sharpe_ratio: 0.1871 - val_loss: -0.0124 - val_sharpe_ratio: 0.0930\n",
      "Epoch 297/300\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.1318 - sharpe_ratio: 0.1881 - val_loss: -0.0734 - val_sharpe_ratio: 0.1177\n",
      "Epoch 298/300\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.1538 - sharpe_ratio: 0.1937 - val_loss: -0.0171 - val_sharpe_ratio: 0.0589\n",
      "Epoch 299/300\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.1482 - sharpe_ratio: 0.1949 - val_loss: -0.0421 - val_sharpe_ratio: 0.0487\n",
      "Epoch 300/300\n",
      "68/68 [==============================] - 2s 36ms/step - loss: -0.1478 - sharpe_ratio: 0.1860 - val_loss: -0.0019 - val_sharpe_ratio: 0.0653\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "There are total 11 samples to predict\n",
      "Sample 0 : [ HDFC.NS HDFCBANK.NS KOTAKBANK.NS MARUTI.NS ]\n",
      "Sample 1 : [ HDFC.NS HDFCBANK.NS KOTAKBANK.NS MARUTI.NS ]\n",
      "Sample 2 : [ HCLTECH.NS MARUTI.NS ]\n",
      "Sample 3 : [ HCLTECH.NS INFY.NS MARUTI.NS ]\n",
      "Sample 4 : [ HCLTECH.NS INFY.NS MARUTI.NS ]\n",
      "Sample 5 : [ HCLTECH.NS INFY.NS MARUTI.NS ]\n",
      "Sample 6 : [ HCLTECH.NS INFY.NS MARUTI.NS ]\n",
      "Sample 7 : [ HCLTECH.NS INFY.NS MARUTI.NS ]\n",
      "Sample 8 : [ HCLTECH.NS INFY.NS MARUTI.NS ]\n",
      "Sample 9 : [ HCLTECH.NS INFY.NS MARUTI.NS ]\n",
      "Sample 10 : [ HCLTECH.NS INFY.NS MARUTI.NS ]\n",
      "Sharpe ratio of this portfolio: [0.7190316855519503, 0.41946182591751224, -0.5769401195024758, 0.47198129849095827, 0.9644804596223701, 1.2650849418211507, 0.6131574326813598, -0.41583255512027795, -1.7464918941974532, 0.8652719721227131, 0.5505324901185796]\n",
      "write file log at C:/Users/yv67/Documents/12FundsHK_ToShare/deeplearningdata/logs/GRU\\log_1301.txt\n",
      "Epoch 1/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1224 - sharpe_ratio: 0.1600 - val_loss: -0.0558 - val_sharpe_ratio: 0.1060\n",
      "Epoch 2/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1180 - sharpe_ratio: 0.1632 - val_loss: -0.0146 - val_sharpe_ratio: 0.0483\n",
      "Epoch 3/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1285 - sharpe_ratio: 0.1702 - val_loss: -0.0272 - val_sharpe_ratio: 0.0762\n",
      "Epoch 4/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1220 - sharpe_ratio: 0.1674 - val_loss: -0.0408 - val_sharpe_ratio: 0.1074\n",
      "Epoch 5/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1180 - sharpe_ratio: 0.1598 - val_loss: -0.0365 - val_sharpe_ratio: 0.0900\n",
      "Epoch 6/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1298 - sharpe_ratio: 0.1698 - val_loss: -0.0063 - val_sharpe_ratio: 0.0594\n",
      "Epoch 7/300\n",
      "82/82 [==============================] - 3s 34ms/step - loss: -0.1325 - sharpe_ratio: 0.1678 - val_loss: -0.0063 - val_sharpe_ratio: 0.0492\n",
      "Epoch 8/300\n",
      "82/82 [==============================] - 3s 33ms/step - loss: -0.1167 - sharpe_ratio: 0.1620 - val_loss: -0.0333 - val_sharpe_ratio: 0.1179\n",
      "Epoch 9/300\n",
      "82/82 [==============================] - 3s 35ms/step - loss: -0.1182 - sharpe_ratio: 0.1643 - val_loss: -0.0420 - val_sharpe_ratio: 0.0798\n",
      "Epoch 10/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1317 - sharpe_ratio: 0.1722 - val_loss: -0.0445 - val_sharpe_ratio: 0.0968\n",
      "Epoch 11/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1273 - sharpe_ratio: 0.1706 - val_loss: 0.0137 - val_sharpe_ratio: -0.0207\n",
      "Epoch 12/300\n",
      "82/82 [==============================] - 3s 33ms/step - loss: -0.1141 - sharpe_ratio: 0.1663 - val_loss: -0.0203 - val_sharpe_ratio: 0.1131\n",
      "Epoch 13/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1157 - sharpe_ratio: 0.1682 - val_loss: -0.0412 - val_sharpe_ratio: 0.0926\n",
      "Epoch 14/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1244 - sharpe_ratio: 0.1649 - val_loss: -0.0390 - val_sharpe_ratio: 0.0896\n",
      "Epoch 15/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1290 - sharpe_ratio: 0.1664 - val_loss: -0.0475 - val_sharpe_ratio: 0.0993\n",
      "Epoch 16/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1357 - sharpe_ratio: 0.1721 - val_loss: -0.0467 - val_sharpe_ratio: 0.1070\n",
      "Epoch 17/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1248 - sharpe_ratio: 0.1661 - val_loss: -0.0475 - val_sharpe_ratio: 0.0962\n",
      "Epoch 18/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1324 - sharpe_ratio: 0.1694 - val_loss: -0.0323 - val_sharpe_ratio: 0.0642\n",
      "Epoch 19/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1342 - sharpe_ratio: 0.1710 - val_loss: -0.0486 - val_sharpe_ratio: 0.0966\n",
      "Epoch 20/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1374 - sharpe_ratio: 0.1732 - val_loss: -0.0528 - val_sharpe_ratio: 0.1095\n",
      "Epoch 21/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1302 - sharpe_ratio: 0.1626 - val_loss: -0.0508 - val_sharpe_ratio: 0.1090\n",
      "Epoch 22/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1312 - sharpe_ratio: 0.1684 - val_loss: -0.0400 - val_sharpe_ratio: 0.0900\n",
      "Epoch 23/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1209 - sharpe_ratio: 0.1705 - val_loss: -0.0507 - val_sharpe_ratio: 0.0911\n",
      "Epoch 24/300\n",
      "82/82 [==============================] - 3s 35ms/step - loss: -0.1305 - sharpe_ratio: 0.1685 - val_loss: -0.0290 - val_sharpe_ratio: 0.0996\n",
      "Epoch 25/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1239 - sharpe_ratio: 0.1703 - val_loss: -0.0360 - val_sharpe_ratio: 0.1010\n",
      "Epoch 26/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1230 - sharpe_ratio: 0.1660 - val_loss: -0.0014 - val_sharpe_ratio: 0.0515\n",
      "Epoch 27/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1152 - sharpe_ratio: 0.1663 - val_loss: 0.0203 - val_sharpe_ratio: 0.0894\n",
      "Epoch 28/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1148 - sharpe_ratio: 0.1628 - val_loss: -0.0513 - val_sharpe_ratio: 0.0942\n",
      "Epoch 29/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1276 - sharpe_ratio: 0.1668 - val_loss: -0.0560 - val_sharpe_ratio: 0.0939\n",
      "Epoch 30/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1258 - sharpe_ratio: 0.1700 - val_loss: -0.0275 - val_sharpe_ratio: 0.0968\n",
      "Epoch 31/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1205 - sharpe_ratio: 0.1677 - val_loss: -0.0163 - val_sharpe_ratio: 0.0783\n",
      "Epoch 32/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1199 - sharpe_ratio: 0.1617 - val_loss: -0.0321 - val_sharpe_ratio: 0.0861\n",
      "Epoch 33/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1136 - sharpe_ratio: 0.1625 - val_loss: -0.0184 - val_sharpe_ratio: 0.0994\n",
      "Epoch 34/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1280 - sharpe_ratio: 0.1673 - val_loss: -0.0333 - val_sharpe_ratio: 0.1007\n",
      "Epoch 35/300\n",
      "82/82 [==============================] - 3s 30ms/step - loss: -0.1263 - sharpe_ratio: 0.1663 - val_loss: -0.0382 - val_sharpe_ratio: 0.0993\n",
      "Epoch 36/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1159 - sharpe_ratio: 0.1576 - val_loss: 0.0050 - val_sharpe_ratio: 0.0320\n",
      "Epoch 37/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1319 - sharpe_ratio: 0.1639 - val_loss: -0.0565 - val_sharpe_ratio: 0.0961\n",
      "Epoch 38/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1405 - sharpe_ratio: 0.1729 - val_loss: -0.0049 - val_sharpe_ratio: 0.0837\n",
      "Epoch 39/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1117 - sharpe_ratio: 0.1696 - val_loss: -0.0422 - val_sharpe_ratio: 0.1000\n",
      "Epoch 40/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1133 - sharpe_ratio: 0.1576 - val_loss: -0.0485 - val_sharpe_ratio: 0.1123\n",
      "Epoch 41/300\n",
      "82/82 [==============================] - 3s 33ms/step - loss: -0.1229 - sharpe_ratio: 0.1657 - val_loss: -0.0366 - val_sharpe_ratio: 0.0748\n",
      "Epoch 42/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1327 - sharpe_ratio: 0.1662 - val_loss: -0.0327 - val_sharpe_ratio: 0.0908\n",
      "Epoch 43/300\n",
      "82/82 [==============================] - 3s 33ms/step - loss: -0.1288 - sharpe_ratio: 0.1726 - val_loss: -0.0201 - val_sharpe_ratio: 0.0644\n",
      "Epoch 44/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1220 - sharpe_ratio: 0.1666 - val_loss: -0.0271 - val_sharpe_ratio: 0.0763\n",
      "Epoch 45/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1120 - sharpe_ratio: 0.1573 - val_loss: -0.0475 - val_sharpe_ratio: 0.0929\n",
      "Epoch 46/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1250 - sharpe_ratio: 0.1682 - val_loss: -0.0567 - val_sharpe_ratio: 0.1007\n",
      "Epoch 47/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1183 - sharpe_ratio: 0.1640 - val_loss: 0.0031 - val_sharpe_ratio: 0.0547\n",
      "Epoch 48/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1257 - sharpe_ratio: 0.1702 - val_loss: -0.0450 - val_sharpe_ratio: 0.0946\n",
      "Epoch 49/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1236 - sharpe_ratio: 0.1661 - val_loss: -0.0351 - val_sharpe_ratio: 0.0891\n",
      "Epoch 50/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1255 - sharpe_ratio: 0.1653 - val_loss: -0.0410 - val_sharpe_ratio: 0.1073\n",
      "Epoch 51/300\n",
      "82/82 [==============================] - 3s 34ms/step - loss: -0.1286 - sharpe_ratio: 0.1651 - val_loss: -0.0490 - val_sharpe_ratio: 0.0814\n",
      "Epoch 52/300\n",
      "82/82 [==============================] - 3s 33ms/step - loss: -0.1325 - sharpe_ratio: 0.1649 - val_loss: -0.0471 - val_sharpe_ratio: 0.0844\n",
      "Epoch 53/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1387 - sharpe_ratio: 0.1727 - val_loss: -0.0392 - val_sharpe_ratio: 0.0939\n",
      "Epoch 54/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1208 - sharpe_ratio: 0.1646 - val_loss: -0.0444 - val_sharpe_ratio: 0.0939\n",
      "Epoch 55/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1326 - sharpe_ratio: 0.1672 - val_loss: -0.0445 - val_sharpe_ratio: 0.0993\n",
      "Epoch 56/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1305 - sharpe_ratio: 0.1698 - val_loss: -0.0462 - val_sharpe_ratio: 0.0883\n",
      "Epoch 57/300\n",
      "82/82 [==============================] - 3s 33ms/step - loss: -0.1268 - sharpe_ratio: 0.1658 - val_loss: -0.0574 - val_sharpe_ratio: 0.1035\n",
      "Epoch 58/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1298 - sharpe_ratio: 0.1699 - val_loss: -0.0667 - val_sharpe_ratio: 0.0921\n",
      "Epoch 59/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1286 - sharpe_ratio: 0.1648 - val_loss: -0.0349 - val_sharpe_ratio: 0.0790\n",
      "Epoch 60/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1307 - sharpe_ratio: 0.1712 - val_loss: 0.0102 - val_sharpe_ratio: 0.0016\n",
      "Epoch 61/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1180 - sharpe_ratio: 0.1669 - val_loss: -0.0248 - val_sharpe_ratio: 0.0855\n",
      "Epoch 62/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1213 - sharpe_ratio: 0.1664 - val_loss: -0.0317 - val_sharpe_ratio: 0.0939\n",
      "Epoch 63/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1167 - sharpe_ratio: 0.1572 - val_loss: -0.0429 - val_sharpe_ratio: 0.0465\n",
      "Epoch 64/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1293 - sharpe_ratio: 0.1761 - val_loss: -0.0381 - val_sharpe_ratio: 0.0924\n",
      "Epoch 65/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1073 - sharpe_ratio: 0.1641 - val_loss: -0.0599 - val_sharpe_ratio: 0.1112\n",
      "Epoch 66/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1270 - sharpe_ratio: 0.1688 - val_loss: -0.0657 - val_sharpe_ratio: 0.1145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1298 - sharpe_ratio: 0.1688 - val_loss: -0.0315 - val_sharpe_ratio: 0.0930\n",
      "Epoch 68/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1277 - sharpe_ratio: 0.1673 - val_loss: -0.0311 - val_sharpe_ratio: 0.0745\n",
      "Epoch 69/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1288 - sharpe_ratio: 0.1681 - val_loss: -0.0330 - val_sharpe_ratio: 0.0755\n",
      "Epoch 70/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1331 - sharpe_ratio: 0.1706 - val_loss: -0.0256 - val_sharpe_ratio: 0.0826\n",
      "Epoch 71/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1265 - sharpe_ratio: 0.1749 - val_loss: -0.0209 - val_sharpe_ratio: 0.0697\n",
      "Epoch 72/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1299 - sharpe_ratio: 0.1678 - val_loss: -0.0431 - val_sharpe_ratio: 0.0957\n",
      "Epoch 73/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1245 - sharpe_ratio: 0.1638 - val_loss: -0.0474 - val_sharpe_ratio: 0.0897\n",
      "Epoch 74/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1267 - sharpe_ratio: 0.1637 - val_loss: -0.0453 - val_sharpe_ratio: 0.1007\n",
      "Epoch 75/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1221 - sharpe_ratio: 0.1671 - val_loss: -0.0279 - val_sharpe_ratio: 0.0925\n",
      "Epoch 76/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1249 - sharpe_ratio: 0.1672 - val_loss: -0.0146 - val_sharpe_ratio: 0.0696\n",
      "Epoch 77/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1241 - sharpe_ratio: 0.1641 - val_loss: -0.0254 - val_sharpe_ratio: 0.0731\n",
      "Epoch 78/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1241 - sharpe_ratio: 0.1643 - val_loss: -0.0397 - val_sharpe_ratio: 0.1219\n",
      "Epoch 79/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1267 - sharpe_ratio: 0.1706 - val_loss: -0.0455 - val_sharpe_ratio: 0.1059\n",
      "Epoch 80/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1356 - sharpe_ratio: 0.1760 - val_loss: -0.0268 - val_sharpe_ratio: 0.0891\n",
      "Epoch 81/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1280 - sharpe_ratio: 0.1657 - val_loss: -0.0355 - val_sharpe_ratio: 0.0891\n",
      "Epoch 82/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1303 - sharpe_ratio: 0.1646 - val_loss: -0.0141 - val_sharpe_ratio: 0.0894\n",
      "Epoch 83/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1194 - sharpe_ratio: 0.1685 - val_loss: -0.0092 - val_sharpe_ratio: 0.0906\n",
      "Epoch 84/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1229 - sharpe_ratio: 0.1639 - val_loss: -0.0238 - val_sharpe_ratio: 0.0579\n",
      "Epoch 85/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1223 - sharpe_ratio: 0.1682 - val_loss: 0.0271 - val_sharpe_ratio: 0.0266\n",
      "Epoch 86/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1171 - sharpe_ratio: 0.1684 - val_loss: -0.0359 - val_sharpe_ratio: 0.0939\n",
      "Epoch 87/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1255 - sharpe_ratio: 0.1638 - val_loss: -0.0337 - val_sharpe_ratio: 0.0891\n",
      "Epoch 88/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1262 - sharpe_ratio: 0.1688 - val_loss: -0.0415 - val_sharpe_ratio: 0.0894\n",
      "Epoch 89/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1255 - sharpe_ratio: 0.1697 - val_loss: -0.0403 - val_sharpe_ratio: 0.0819\n",
      "Epoch 90/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1254 - sharpe_ratio: 0.1631 - val_loss: -0.0354 - val_sharpe_ratio: 0.0748\n",
      "Epoch 91/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1198 - sharpe_ratio: 0.1663 - val_loss: -0.0264 - val_sharpe_ratio: 0.0777\n",
      "Epoch 92/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1228 - sharpe_ratio: 0.1642 - val_loss: -0.0200 - val_sharpe_ratio: 0.0810\n",
      "Epoch 93/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1210 - sharpe_ratio: 0.1675 - val_loss: -0.0448 - val_sharpe_ratio: 0.0989\n",
      "Epoch 94/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1246 - sharpe_ratio: 0.1704 - val_loss: -0.0257 - val_sharpe_ratio: 0.0764\n",
      "Epoch 95/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1260 - sharpe_ratio: 0.1652 - val_loss: -0.0071 - val_sharpe_ratio: 0.0653\n",
      "Epoch 96/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1197 - sharpe_ratio: 0.1654 - val_loss: -0.0199 - val_sharpe_ratio: 0.0763\n",
      "Epoch 97/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1355 - sharpe_ratio: 0.1747 - val_loss: -0.0275 - val_sharpe_ratio: 0.0819\n",
      "Epoch 98/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1205 - sharpe_ratio: 0.1615 - val_loss: -0.0558 - val_sharpe_ratio: 0.0977\n",
      "Epoch 99/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1320 - sharpe_ratio: 0.1672 - val_loss: -0.0461 - val_sharpe_ratio: 0.0952\n",
      "Epoch 100/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1273 - sharpe_ratio: 0.1638 - val_loss: -0.0158 - val_sharpe_ratio: 0.0629\n",
      "Epoch 101/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1323 - sharpe_ratio: 0.1686 - val_loss: -0.0653 - val_sharpe_ratio: 0.0827\n",
      "Epoch 102/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1203 - sharpe_ratio: 0.1692 - val_loss: -0.0371 - val_sharpe_ratio: 0.0983\n",
      "Epoch 103/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1176 - sharpe_ratio: 0.1631 - val_loss: -0.0055 - val_sharpe_ratio: 0.0521\n",
      "Epoch 104/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1304 - sharpe_ratio: 0.1669 - val_loss: -0.0270 - val_sharpe_ratio: 0.0841\n",
      "Epoch 105/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1272 - sharpe_ratio: 0.1658 - val_loss: -0.0463 - val_sharpe_ratio: 0.1035\n",
      "Epoch 106/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1293 - sharpe_ratio: 0.1670 - val_loss: -0.0549 - val_sharpe_ratio: 0.1000\n",
      "Epoch 107/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1261 - sharpe_ratio: 0.1667 - val_loss: -0.0436 - val_sharpe_ratio: 0.0952\n",
      "Epoch 108/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1233 - sharpe_ratio: 0.1695 - val_loss: -0.0459 - val_sharpe_ratio: 0.0895\n",
      "Epoch 109/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1280 - sharpe_ratio: 0.1627 - val_loss: -0.0363 - val_sharpe_ratio: 0.0746\n",
      "Epoch 110/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1294 - sharpe_ratio: 0.1685 - val_loss: 0.0327 - val_sharpe_ratio: 0.0381\n",
      "Epoch 111/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1132 - sharpe_ratio: 0.1630 - val_loss: -0.0410 - val_sharpe_ratio: 0.1074\n",
      "Epoch 112/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1195 - sharpe_ratio: 0.1604 - val_loss: -0.0278 - val_sharpe_ratio: 0.0924\n",
      "Epoch 113/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1328 - sharpe_ratio: 0.1747 - val_loss: 2.3797e-04 - val_sharpe_ratio: 0.0786\n",
      "Epoch 114/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1241 - sharpe_ratio: 0.1674 - val_loss: -0.0409 - val_sharpe_ratio: 0.0869\n",
      "Epoch 115/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1126 - sharpe_ratio: 0.1648 - val_loss: -0.0420 - val_sharpe_ratio: 0.0851\n",
      "Epoch 116/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1360 - sharpe_ratio: 0.1703 - val_loss: -0.0593 - val_sharpe_ratio: 0.1077\n",
      "Epoch 117/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1328 - sharpe_ratio: 0.1713 - val_loss: -0.0413 - val_sharpe_ratio: 0.0595\n",
      "Epoch 118/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1366 - sharpe_ratio: 0.1683 - val_loss: -0.0193 - val_sharpe_ratio: 0.0734\n",
      "Epoch 119/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1256 - sharpe_ratio: 0.1700 - val_loss: -0.0259 - val_sharpe_ratio: 0.0717\n",
      "Epoch 120/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1324 - sharpe_ratio: 0.1730 - val_loss: -0.0448 - val_sharpe_ratio: 0.0872\n",
      "Epoch 121/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1287 - sharpe_ratio: 0.1698 - val_loss: -0.0105 - val_sharpe_ratio: 0.0598\n",
      "Epoch 122/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1192 - sharpe_ratio: 0.1673 - val_loss: -0.0550 - val_sharpe_ratio: 0.0918\n",
      "Epoch 123/300\n",
      "82/82 [==============================] - 3s 33ms/step - loss: -0.1185 - sharpe_ratio: 0.1696 - val_loss: -0.0418 - val_sharpe_ratio: 0.0885\n",
      "Epoch 124/300\n",
      "82/82 [==============================] - 3s 35ms/step - loss: -0.1200 - sharpe_ratio: 0.1644 - val_loss: -0.0430 - val_sharpe_ratio: 0.0808\n",
      "Epoch 125/300\n",
      "82/82 [==============================] - 3s 33ms/step - loss: -0.1282 - sharpe_ratio: 0.1634 - val_loss: -0.0208 - val_sharpe_ratio: 0.0813\n",
      "Epoch 126/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1243 - sharpe_ratio: 0.1703 - val_loss: -0.0411 - val_sharpe_ratio: 0.0739\n",
      "Epoch 127/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1266 - sharpe_ratio: 0.1606 - val_loss: -0.0530 - val_sharpe_ratio: 0.0570\n",
      "Epoch 128/300\n",
      "82/82 [==============================] - 3s 34ms/step - loss: -0.1287 - sharpe_ratio: 0.1727 - val_loss: -0.0657 - val_sharpe_ratio: 0.1000\n",
      "Epoch 129/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1317 - sharpe_ratio: 0.1703 - val_loss: -0.0396 - val_sharpe_ratio: 0.0813\n",
      "Epoch 130/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1097 - sharpe_ratio: 0.1607 - val_loss: -0.0327 - val_sharpe_ratio: 0.0772\n",
      "Epoch 131/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1278 - sharpe_ratio: 0.1679 - val_loss: -0.0380 - val_sharpe_ratio: 0.0791\n",
      "Epoch 132/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1189 - sharpe_ratio: 0.1679 - val_loss: -0.0403 - val_sharpe_ratio: 0.0997\n",
      "Epoch 133/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1340 - sharpe_ratio: 0.1696 - val_loss: -0.0390 - val_sharpe_ratio: 0.0810\n",
      "Epoch 134/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1381 - sharpe_ratio: 0.1709 - val_loss: -0.0261 - val_sharpe_ratio: 0.0838\n",
      "Epoch 135/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1355 - sharpe_ratio: 0.1700 - val_loss: -0.0171 - val_sharpe_ratio: 0.0733\n",
      "Epoch 136/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1306 - sharpe_ratio: 0.1713 - val_loss: -0.0345 - val_sharpe_ratio: 0.0810\n",
      "Epoch 137/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1256 - sharpe_ratio: 0.1658 - val_loss: -0.0389 - val_sharpe_ratio: 0.0924\n",
      "Epoch 138/300\n",
      "82/82 [==============================] - 3s 33ms/step - loss: -0.1304 - sharpe_ratio: 0.1702 - val_loss: -0.0625 - val_sharpe_ratio: 0.1152\n",
      "Epoch 139/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1250 - sharpe_ratio: 0.1626 - val_loss: -0.0498 - val_sharpe_ratio: 0.1046\n",
      "Epoch 140/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1312 - sharpe_ratio: 0.1643 - val_loss: -0.0535 - val_sharpe_ratio: 0.1029\n",
      "Epoch 141/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1157 - sharpe_ratio: 0.1641 - val_loss: 0.0128 - val_sharpe_ratio: 0.0810\n",
      "Epoch 142/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1036 - sharpe_ratio: 0.1675 - val_loss: -0.0168 - val_sharpe_ratio: 0.1007\n",
      "Epoch 143/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1203 - sharpe_ratio: 0.1642 - val_loss: -0.0467 - val_sharpe_ratio: 0.1127\n",
      "Epoch 144/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1123 - sharpe_ratio: 0.1662 - val_loss: -0.0034 - val_sharpe_ratio: 0.0842\n",
      "Epoch 145/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1219 - sharpe_ratio: 0.1657 - val_loss: -0.0220 - val_sharpe_ratio: 0.0826\n",
      "Epoch 146/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1232 - sharpe_ratio: 0.1713 - val_loss: -0.0187 - val_sharpe_ratio: 0.0749\n",
      "Epoch 147/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1091 - sharpe_ratio: 0.1656 - val_loss: -0.0386 - val_sharpe_ratio: 0.1046\n",
      "Epoch 148/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1240 - sharpe_ratio: 0.1658 - val_loss: -0.0389 - val_sharpe_ratio: 0.0773\n",
      "Epoch 149/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1234 - sharpe_ratio: 0.1624 - val_loss: -0.0077 - val_sharpe_ratio: 0.1143\n",
      "Epoch 150/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1219 - sharpe_ratio: 0.1625 - val_loss: -0.0276 - val_sharpe_ratio: 0.0790\n",
      "Epoch 151/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1276 - sharpe_ratio: 0.1605 - val_loss: -0.0502 - val_sharpe_ratio: 0.0978\n",
      "Epoch 152/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1318 - sharpe_ratio: 0.1661 - val_loss: -0.0325 - val_sharpe_ratio: 0.0870\n",
      "Epoch 153/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1289 - sharpe_ratio: 0.1645 - val_loss: -2.6616e-04 - val_sharpe_ratio: 0.0414\n",
      "Epoch 154/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1271 - sharpe_ratio: 0.1655 - val_loss: -0.0458 - val_sharpe_ratio: 0.0993\n",
      "Epoch 155/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1251 - sharpe_ratio: 0.1700 - val_loss: -0.0456 - val_sharpe_ratio: 0.0744\n",
      "Epoch 156/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1292 - sharpe_ratio: 0.1681 - val_loss: -0.0322 - val_sharpe_ratio: 0.0961\n",
      "Epoch 157/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1255 - sharpe_ratio: 0.1694 - val_loss: -0.0400 - val_sharpe_ratio: 0.1000\n",
      "Epoch 158/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1243 - sharpe_ratio: 0.1665 - val_loss: -0.0357 - val_sharpe_ratio: 0.0907\n",
      "Epoch 159/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1303 - sharpe_ratio: 0.1736 - val_loss: -0.0674 - val_sharpe_ratio: 0.0924\n",
      "Epoch 160/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1400 - sharpe_ratio: 0.1658 - val_loss: -0.0471 - val_sharpe_ratio: 0.0852\n",
      "Epoch 161/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1321 - sharpe_ratio: 0.1666 - val_loss: -0.0417 - val_sharpe_ratio: 0.0883\n",
      "Epoch 162/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1372 - sharpe_ratio: 0.1669 - val_loss: -0.0348 - val_sharpe_ratio: 0.1133\n",
      "Epoch 163/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1377 - sharpe_ratio: 0.1697 - val_loss: -0.0450 - val_sharpe_ratio: 0.0696\n",
      "Epoch 164/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1423 - sharpe_ratio: 0.1747 - val_loss: -0.0731 - val_sharpe_ratio: 0.1115\n",
      "Epoch 165/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1291 - sharpe_ratio: 0.1625 - val_loss: -0.0301 - val_sharpe_ratio: 0.0888\n",
      "Epoch 166/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1351 - sharpe_ratio: 0.1706 - val_loss: -0.0258 - val_sharpe_ratio: 0.0773\n",
      "Epoch 167/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1243 - sharpe_ratio: 0.1686 - val_loss: -0.0058 - val_sharpe_ratio: 0.0535\n",
      "Epoch 168/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1337 - sharpe_ratio: 0.1706 - val_loss: -0.0206 - val_sharpe_ratio: 0.0381\n",
      "Epoch 169/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1212 - sharpe_ratio: 0.1654 - val_loss: 0.0055 - val_sharpe_ratio: 0.0827\n",
      "Epoch 170/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1208 - sharpe_ratio: 0.1667 - val_loss: -0.0222 - val_sharpe_ratio: 0.1000\n",
      "Epoch 171/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1070 - sharpe_ratio: 0.1660 - val_loss: -0.0153 - val_sharpe_ratio: 0.0954\n",
      "Epoch 172/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1252 - sharpe_ratio: 0.1663 - val_loss: -0.0278 - val_sharpe_ratio: 0.0696\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1331 - sharpe_ratio: 0.1634 - val_loss: -0.0489 - val_sharpe_ratio: 0.0767\n",
      "Epoch 174/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1226 - sharpe_ratio: 0.1634 - val_loss: -0.0539 - val_sharpe_ratio: 0.0993\n",
      "Epoch 175/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1352 - sharpe_ratio: 0.1718 - val_loss: -0.0258 - val_sharpe_ratio: 0.0773\n",
      "Epoch 176/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1262 - sharpe_ratio: 0.1680 - val_loss: -0.0258 - val_sharpe_ratio: 0.0937\n",
      "Epoch 177/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1131 - sharpe_ratio: 0.1621 - val_loss: -0.0284 - val_sharpe_ratio: 0.0376\n",
      "Epoch 178/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1248 - sharpe_ratio: 0.1635 - val_loss: -0.0338 - val_sharpe_ratio: 0.0774\n",
      "Epoch 179/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1245 - sharpe_ratio: 0.1671 - val_loss: -0.0315 - val_sharpe_ratio: 0.0800\n",
      "Epoch 180/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1223 - sharpe_ratio: 0.1690 - val_loss: -0.0125 - val_sharpe_ratio: 0.1023\n",
      "Epoch 181/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1148 - sharpe_ratio: 0.1727 - val_loss: -0.0450 - val_sharpe_ratio: 0.1055\n",
      "Epoch 182/300\n",
      "82/82 [==============================] - 3s 33ms/step - loss: -0.1226 - sharpe_ratio: 0.1723 - val_loss: -0.0415 - val_sharpe_ratio: 0.1031\n",
      "Epoch 183/300\n",
      "82/82 [==============================] - 3s 33ms/step - loss: -0.1306 - sharpe_ratio: 0.1749 - val_loss: -0.0461 - val_sharpe_ratio: 0.1007\n",
      "Epoch 184/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1231 - sharpe_ratio: 0.1706 - val_loss: -0.0363 - val_sharpe_ratio: 0.1117\n",
      "Epoch 185/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1223 - sharpe_ratio: 0.1661 - val_loss: -0.0290 - val_sharpe_ratio: 0.0976\n",
      "Epoch 186/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1072 - sharpe_ratio: 0.1656 - val_loss: -0.0403 - val_sharpe_ratio: 0.0896\n",
      "Epoch 187/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1162 - sharpe_ratio: 0.1635 - val_loss: -0.0495 - val_sharpe_ratio: 0.1000\n",
      "Epoch 188/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1237 - sharpe_ratio: 0.1668 - val_loss: -0.0480 - val_sharpe_ratio: 0.1063\n",
      "Epoch 189/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1330 - sharpe_ratio: 0.1686 - val_loss: -0.0395 - val_sharpe_ratio: 0.0900\n",
      "Epoch 190/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1227 - sharpe_ratio: 0.1676 - val_loss: -0.0295 - val_sharpe_ratio: 0.0445\n",
      "Epoch 191/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1276 - sharpe_ratio: 0.1683 - val_loss: -0.0176 - val_sharpe_ratio: 0.0820\n",
      "Epoch 192/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1294 - sharpe_ratio: 0.1689 - val_loss: 0.0383 - val_sharpe_ratio: 0.0250\n",
      "Epoch 193/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1236 - sharpe_ratio: 0.1689 - val_loss: -0.0187 - val_sharpe_ratio: 0.0578\n",
      "Epoch 194/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1162 - sharpe_ratio: 0.1700 - val_loss: -0.0144 - val_sharpe_ratio: 0.0388\n",
      "Epoch 195/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1295 - sharpe_ratio: 0.1682 - val_loss: -0.0178 - val_sharpe_ratio: 0.0725\n",
      "Epoch 196/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1231 - sharpe_ratio: 0.1692 - val_loss: -0.0075 - val_sharpe_ratio: 0.0431\n",
      "Epoch 197/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1325 - sharpe_ratio: 0.1709 - val_loss: -0.0655 - val_sharpe_ratio: 0.1104\n",
      "Epoch 198/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1256 - sharpe_ratio: 0.1677 - val_loss: -0.0618 - val_sharpe_ratio: 0.1387\n",
      "Epoch 199/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1271 - sharpe_ratio: 0.1656 - val_loss: -0.0379 - val_sharpe_ratio: 0.0999\n",
      "Epoch 200/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1198 - sharpe_ratio: 0.1694 - val_loss: -0.0165 - val_sharpe_ratio: 0.0810\n",
      "Epoch 201/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1284 - sharpe_ratio: 0.1695 - val_loss: -0.0241 - val_sharpe_ratio: 0.0897\n",
      "Epoch 202/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1250 - sharpe_ratio: 0.1719 - val_loss: -0.0310 - val_sharpe_ratio: 0.0962\n",
      "Epoch 203/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1079 - sharpe_ratio: 0.1573 - val_loss: -0.0451 - val_sharpe_ratio: 0.1243\n",
      "Epoch 204/300\n",
      "82/82 [==============================] - 2s 31ms/step - loss: -0.1253 - sharpe_ratio: 0.1722 - val_loss: -0.0493 - val_sharpe_ratio: 0.1043\n",
      "Epoch 205/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1179 - sharpe_ratio: 0.1648 - val_loss: -0.0259 - val_sharpe_ratio: 0.0797\n",
      "Epoch 206/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1167 - sharpe_ratio: 0.1613 - val_loss: -0.0465 - val_sharpe_ratio: 0.1023\n",
      "Epoch 207/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1275 - sharpe_ratio: 0.1682 - val_loss: -0.0525 - val_sharpe_ratio: 0.1062\n",
      "Epoch 208/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1249 - sharpe_ratio: 0.1672 - val_loss: -0.0223 - val_sharpe_ratio: 0.0759\n",
      "Epoch 209/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1316 - sharpe_ratio: 0.1716 - val_loss: -0.0385 - val_sharpe_ratio: 0.1009\n",
      "Epoch 210/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1304 - sharpe_ratio: 0.1704 - val_loss: -0.0468 - val_sharpe_ratio: 0.0815\n",
      "Epoch 211/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1284 - sharpe_ratio: 0.1674 - val_loss: -0.0434 - val_sharpe_ratio: 0.1149\n",
      "Epoch 212/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1081 - sharpe_ratio: 0.1578 - val_loss: -0.0349 - val_sharpe_ratio: 0.1073\n",
      "Epoch 213/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1233 - sharpe_ratio: 0.1626 - val_loss: -0.0193 - val_sharpe_ratio: 0.0400\n",
      "Epoch 214/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1093 - sharpe_ratio: 0.1672 - val_loss: -0.0443 - val_sharpe_ratio: 0.1067\n",
      "Epoch 215/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1070 - sharpe_ratio: 0.1624 - val_loss: -3.6015e-04 - val_sharpe_ratio: 0.0533\n",
      "Epoch 216/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1234 - sharpe_ratio: 0.1683 - val_loss: -0.0239 - val_sharpe_ratio: 0.0588\n",
      "Epoch 217/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1292 - sharpe_ratio: 0.1707 - val_loss: -0.0349 - val_sharpe_ratio: 0.0949\n",
      "Epoch 218/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1161 - sharpe_ratio: 0.1679 - val_loss: -0.0433 - val_sharpe_ratio: 0.0926\n",
      "Epoch 219/300\n",
      "82/82 [==============================] - 3s 33ms/step - loss: -0.1420 - sharpe_ratio: 0.1763 - val_loss: -0.0470 - val_sharpe_ratio: 0.0769\n",
      "Epoch 220/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1354 - sharpe_ratio: 0.1720 - val_loss: -0.0481 - val_sharpe_ratio: 0.0894\n",
      "Epoch 221/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1346 - sharpe_ratio: 0.1671 - val_loss: -0.0437 - val_sharpe_ratio: 0.1013\n",
      "Epoch 222/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1083 - sharpe_ratio: 0.1696 - val_loss: -0.0239 - val_sharpe_ratio: 0.0878\n",
      "Epoch 223/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1315 - sharpe_ratio: 0.1689 - val_loss: -0.0270 - val_sharpe_ratio: 0.0861\n",
      "Epoch 224/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1306 - sharpe_ratio: 0.1674 - val_loss: -0.0175 - val_sharpe_ratio: 0.0957\n",
      "Epoch 225/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1319 - sharpe_ratio: 0.1724 - val_loss: -0.0480 - val_sharpe_ratio: 0.1055\n",
      "Epoch 226/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1279 - sharpe_ratio: 0.1665 - val_loss: -0.0041 - val_sharpe_ratio: 0.0632\n",
      "Epoch 227/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1204 - sharpe_ratio: 0.1697 - val_loss: -0.0377 - val_sharpe_ratio: 0.0895\n",
      "Epoch 228/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1331 - sharpe_ratio: 0.1732 - val_loss: -0.0275 - val_sharpe_ratio: 0.0930\n",
      "Epoch 229/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1312 - sharpe_ratio: 0.1673 - val_loss: -0.0015 - val_sharpe_ratio: 0.0709\n",
      "Epoch 230/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1326 - sharpe_ratio: 0.1704 - val_loss: -0.0578 - val_sharpe_ratio: 0.0905\n",
      "Epoch 231/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1354 - sharpe_ratio: 0.1689 - val_loss: -0.0496 - val_sharpe_ratio: 0.0868\n",
      "Epoch 232/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1354 - sharpe_ratio: 0.1699 - val_loss: -0.0468 - val_sharpe_ratio: 0.0894\n",
      "Epoch 233/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1365 - sharpe_ratio: 0.1714 - val_loss: -0.0267 - val_sharpe_ratio: 0.0800\n",
      "Epoch 234/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1289 - sharpe_ratio: 0.1721 - val_loss: -0.0126 - val_sharpe_ratio: 0.0511\n",
      "Epoch 235/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1294 - sharpe_ratio: 0.1615 - val_loss: -0.0344 - val_sharpe_ratio: 0.0612\n",
      "Epoch 236/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1399 - sharpe_ratio: 0.1687 - val_loss: -0.0328 - val_sharpe_ratio: 0.0365\n",
      "Epoch 237/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1322 - sharpe_ratio: 0.1671 - val_loss: -0.0590 - val_sharpe_ratio: 0.0807\n",
      "Epoch 238/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1343 - sharpe_ratio: 0.1667 - val_loss: -0.0253 - val_sharpe_ratio: 0.0841\n",
      "Epoch 239/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1211 - sharpe_ratio: 0.1648 - val_loss: -0.0021 - val_sharpe_ratio: 0.0588\n",
      "Epoch 240/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1274 - sharpe_ratio: 0.1654 - val_loss: -0.0118 - val_sharpe_ratio: 0.0563\n",
      "Epoch 241/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1213 - sharpe_ratio: 0.1665 - val_loss: -0.0544 - val_sharpe_ratio: 0.1153\n",
      "Epoch 242/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1345 - sharpe_ratio: 0.1741 - val_loss: -0.0553 - val_sharpe_ratio: 0.0937\n",
      "Epoch 243/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1271 - sharpe_ratio: 0.1639 - val_loss: -0.0587 - val_sharpe_ratio: 0.0946\n",
      "Epoch 244/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1312 - sharpe_ratio: 0.1713 - val_loss: -0.0519 - val_sharpe_ratio: 0.0999\n",
      "Epoch 245/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1306 - sharpe_ratio: 0.1702 - val_loss: -0.0117 - val_sharpe_ratio: 0.0867\n",
      "Epoch 246/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1196 - sharpe_ratio: 0.1657 - val_loss: -0.0144 - val_sharpe_ratio: 0.0661\n",
      "Epoch 247/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1280 - sharpe_ratio: 0.1681 - val_loss: -0.0436 - val_sharpe_ratio: 0.0894\n",
      "Epoch 248/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1178 - sharpe_ratio: 0.1694 - val_loss: -0.0390 - val_sharpe_ratio: 0.1003\n",
      "Epoch 249/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1314 - sharpe_ratio: 0.1748 - val_loss: -0.0266 - val_sharpe_ratio: 0.0600\n",
      "Epoch 250/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1082 - sharpe_ratio: 0.1674 - val_loss: -0.0160 - val_sharpe_ratio: 0.0637\n",
      "Epoch 251/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1208 - sharpe_ratio: 0.1672 - val_loss: -0.0077 - val_sharpe_ratio: 0.0250\n",
      "Epoch 252/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1226 - sharpe_ratio: 0.1699 - val_loss: -0.0420 - val_sharpe_ratio: 0.1002\n",
      "Epoch 253/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1286 - sharpe_ratio: 0.1677 - val_loss: -0.0289 - val_sharpe_ratio: 0.0721\n",
      "Epoch 254/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1334 - sharpe_ratio: 0.1731 - val_loss: -0.0160 - val_sharpe_ratio: 0.0843\n",
      "Epoch 255/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1284 - sharpe_ratio: 0.1757 - val_loss: -0.0060 - val_sharpe_ratio: 0.0603\n",
      "Epoch 256/300\n",
      "82/82 [==============================] - 3s 36ms/step - loss: -0.1147 - sharpe_ratio: 0.1650 - val_loss: -0.0274 - val_sharpe_ratio: 0.0976\n",
      "Epoch 257/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1303 - sharpe_ratio: 0.1652 - val_loss: -0.0507 - val_sharpe_ratio: 0.1085\n",
      "Epoch 258/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1368 - sharpe_ratio: 0.1709 - val_loss: -0.0420 - val_sharpe_ratio: 0.0866\n",
      "Epoch 259/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1267 - sharpe_ratio: 0.1672 - val_loss: -0.0355 - val_sharpe_ratio: 0.1001\n",
      "Epoch 260/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1150 - sharpe_ratio: 0.1680 - val_loss: -0.0483 - val_sharpe_ratio: 0.0899\n",
      "Epoch 261/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1243 - sharpe_ratio: 0.1681 - val_loss: -0.0469 - val_sharpe_ratio: 0.0806\n",
      "Epoch 262/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1303 - sharpe_ratio: 0.1674 - val_loss: -0.0607 - val_sharpe_ratio: 0.1082\n",
      "Epoch 263/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1250 - sharpe_ratio: 0.1668 - val_loss: 0.0210 - val_sharpe_ratio: 0.0356\n",
      "Epoch 264/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1196 - sharpe_ratio: 0.1690 - val_loss: 0.0180 - val_sharpe_ratio: 0.0263\n",
      "Epoch 265/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1301 - sharpe_ratio: 0.1719 - val_loss: -0.0460 - val_sharpe_ratio: 0.0988\n",
      "Epoch 266/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1323 - sharpe_ratio: 0.1740 - val_loss: -0.0449 - val_sharpe_ratio: 0.1106\n",
      "Epoch 267/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1276 - sharpe_ratio: 0.1706 - val_loss: -0.0452 - val_sharpe_ratio: 0.0945\n",
      "Epoch 268/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1359 - sharpe_ratio: 0.1764 - val_loss: -0.0505 - val_sharpe_ratio: 0.0958\n",
      "Epoch 269/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1262 - sharpe_ratio: 0.1727 - val_loss: -0.0334 - val_sharpe_ratio: 0.0621\n",
      "Epoch 270/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1361 - sharpe_ratio: 0.1776 - val_loss: -0.0226 - val_sharpe_ratio: 0.0637\n",
      "Epoch 271/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1353 - sharpe_ratio: 0.1686 - val_loss: -0.0165 - val_sharpe_ratio: 0.0718\n",
      "Epoch 272/300\n",
      "82/82 [==============================] - 2s 27ms/step - loss: -0.1302 - sharpe_ratio: 0.1680 - val_loss: -0.0233 - val_sharpe_ratio: 0.0989\n",
      "Epoch 273/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1295 - sharpe_ratio: 0.1716 - val_loss: -0.0119 - val_sharpe_ratio: 0.0627\n",
      "Epoch 274/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1292 - sharpe_ratio: 0.1696 - val_loss: -0.0352 - val_sharpe_ratio: 0.1034\n",
      "Epoch 275/300\n",
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1282 - sharpe_ratio: 0.1714 - val_loss: -0.0309 - val_sharpe_ratio: 0.0878\n",
      "Epoch 276/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1271 - sharpe_ratio: 0.1650 - val_loss: -0.0188 - val_sharpe_ratio: 0.0819\n",
      "Epoch 277/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1277 - sharpe_ratio: 0.1733 - val_loss: -0.0618 - val_sharpe_ratio: 0.1257\n",
      "Epoch 278/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1280 - sharpe_ratio: 0.1684 - val_loss: -0.0261 - val_sharpe_ratio: 0.0993\n",
      "Epoch 279/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 3s 32ms/step - loss: -0.1277 - sharpe_ratio: 0.1700 - val_loss: -0.0216 - val_sharpe_ratio: 0.0878\n",
      "Epoch 280/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1069 - sharpe_ratio: 0.1630 - val_loss: -0.0169 - val_sharpe_ratio: 0.0767\n",
      "Epoch 281/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1209 - sharpe_ratio: 0.1704 - val_loss: -0.0388 - val_sharpe_ratio: 0.0971\n",
      "Epoch 282/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1312 - sharpe_ratio: 0.1706 - val_loss: -0.0711 - val_sharpe_ratio: 0.1032\n",
      "Epoch 283/300\n",
      "82/82 [==============================] - 3s 36ms/step - loss: -0.1367 - sharpe_ratio: 0.1727 - val_loss: -0.0117 - val_sharpe_ratio: 0.0384\n",
      "Epoch 284/300\n",
      "82/82 [==============================] - 3s 33ms/step - loss: -0.1286 - sharpe_ratio: 0.1698 - val_loss: -0.0494 - val_sharpe_ratio: 0.1035\n",
      "Epoch 285/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1361 - sharpe_ratio: 0.1682 - val_loss: -0.0681 - val_sharpe_ratio: 0.1184\n",
      "Epoch 286/300\n",
      "82/82 [==============================] - 3s 35ms/step - loss: -0.1330 - sharpe_ratio: 0.1696 - val_loss: 0.0023 - val_sharpe_ratio: 0.0485\n",
      "Epoch 287/300\n",
      "82/82 [==============================] - 3s 35ms/step - loss: -0.1222 - sharpe_ratio: 0.1685 - val_loss: -0.0564 - val_sharpe_ratio: 0.1117\n",
      "Epoch 288/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1303 - sharpe_ratio: 0.1722 - val_loss: -0.0659 - val_sharpe_ratio: 0.1152\n",
      "Epoch 289/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1363 - sharpe_ratio: 0.1713 - val_loss: -0.0427 - val_sharpe_ratio: 0.0972\n",
      "Epoch 290/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1308 - sharpe_ratio: 0.1728 - val_loss: -0.0532 - val_sharpe_ratio: 0.0891\n",
      "Epoch 291/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1168 - sharpe_ratio: 0.1662 - val_loss: -0.0494 - val_sharpe_ratio: 0.1090\n",
      "Epoch 292/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1307 - sharpe_ratio: 0.1669 - val_loss: -0.0236 - val_sharpe_ratio: 0.0947\n",
      "Epoch 293/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1307 - sharpe_ratio: 0.1732 - val_loss: -0.0616 - val_sharpe_ratio: 0.0894\n",
      "Epoch 294/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1403 - sharpe_ratio: 0.1750 - val_loss: -0.0367 - val_sharpe_ratio: 0.1038\n",
      "Epoch 295/300\n",
      "82/82 [==============================] - 2s 30ms/step - loss: -0.1308 - sharpe_ratio: 0.1698 - val_loss: -0.0136 - val_sharpe_ratio: 0.0379\n",
      "Epoch 296/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1249 - sharpe_ratio: 0.1642 - val_loss: -0.0607 - val_sharpe_ratio: 0.0894\n",
      "Epoch 297/300\n",
      "82/82 [==============================] - 3s 36ms/step - loss: -0.1276 - sharpe_ratio: 0.1750 - val_loss: -0.0367 - val_sharpe_ratio: 0.0863\n",
      "Epoch 298/300\n",
      "82/82 [==============================] - 3s 31ms/step - loss: -0.1172 - sharpe_ratio: 0.1642 - val_loss: -0.0292 - val_sharpe_ratio: 0.1067\n",
      "Epoch 299/300\n",
      "82/82 [==============================] - 2s 28ms/step - loss: -0.1094 - sharpe_ratio: 0.1623 - val_loss: -0.0320 - val_sharpe_ratio: 0.1022\n",
      "Epoch 300/300\n",
      "82/82 [==============================] - 2s 29ms/step - loss: -0.1140 - sharpe_ratio: 0.1664 - val_loss: -0.0116 - val_sharpe_ratio: 0.0816\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "There are total 11 samples to predict\n",
      "Sample 0 : [ HDFCBANK.NS INFY.NS MARUTI.NS TCS.NS ]\n",
      "Sample 1 : [ HDFCBANK.NS INFY.NS MARUTI.NS TCS.NS ]\n",
      "Sample 2 : [ HDFCBANK.NS INFY.NS KOTAKBANK.NS MARUTI.NS TCS.NS ]\n",
      "Sample 3 : [ HDFCBANK.NS INFY.NS MARUTI.NS TCS.NS ]\n",
      "Sample 4 : [ HDFCBANK.NS INFY.NS MARUTI.NS TCS.NS ]\n",
      "Sample 5 : [ HDFCBANK.NS INFY.NS MARUTI.NS TCS.NS ]\n",
      "Sample 6 : [ HDFCBANK.NS INFY.NS MARUTI.NS TCS.NS ]\n",
      "Sample 7 : [ HDFCBANK.NS INFY.NS MARUTI.NS TCS.NS ]\n",
      "Sample 8 : [ HDFCBANK.NS INFY.NS MARUTI.NS TCS.NS ]\n",
      "Sample 9 : [ HDFCBANK.NS INFY.NS MARUTI.NS TCS.NS ]\n",
      "Sample 10 : [ HDFCBANK.NS INFY.NS MARUTI.NS TCS.NS ]\n",
      "Sharpe ratio of this portfolio: [0.41296645413721944, -0.05593299534206121, 0.8400714949588947, 0.8061485370927568, -0.0250664971199467, 0.7800807605178248, -0.3597108701040845, -0.5377283216122686, 1.4005043036303644, 0.232809672101308, 0.42056090450918804]\n",
      "write file log at C:/Users/yv67/Documents/12FundsHK_ToShare/deeplearningdata/logs/GRU\\log_1517.txt\n",
      "Epoch 1/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1052 - sharpe_ratio: 0.1555 - val_loss: -0.0355 - val_sharpe_ratio: 0.0814\n",
      "Epoch 2/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1093 - sharpe_ratio: 0.1528 - val_loss: 0.0060 - val_sharpe_ratio: 0.0565\n",
      "Epoch 3/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1062 - sharpe_ratio: 0.1566 - val_loss: 0.0173 - val_sharpe_ratio: 0.0229\n",
      "Epoch 4/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1109 - sharpe_ratio: 0.1541 - val_loss: 0.0177 - val_sharpe_ratio: 0.0348\n",
      "Epoch 5/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1050 - sharpe_ratio: 0.1493 - val_loss: 0.0051 - val_sharpe_ratio: 0.0527\n",
      "Epoch 6/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1212 - sharpe_ratio: 0.1497 - val_loss: -0.0061 - val_sharpe_ratio: 0.0520\n",
      "Epoch 7/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.0998 - sharpe_ratio: 0.1475 - val_loss: -0.0396 - val_sharpe_ratio: 0.1237\n",
      "Epoch 8/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1210 - sharpe_ratio: 0.1590 - val_loss: -0.0376 - val_sharpe_ratio: 0.0747\n",
      "Epoch 9/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1214 - sharpe_ratio: 0.1559 - val_loss: -0.0673 - val_sharpe_ratio: 0.1264\n",
      "Epoch 10/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1163 - sharpe_ratio: 0.1540 - val_loss: 0.0225 - val_sharpe_ratio: 0.0150\n",
      "Epoch 11/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1226 - sharpe_ratio: 0.1555 - val_loss: -0.0232 - val_sharpe_ratio: 0.0638\n",
      "Epoch 12/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1129 - sharpe_ratio: 0.1551 - val_loss: -0.0138 - val_sharpe_ratio: 0.0881\n",
      "Epoch 13/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1150 - sharpe_ratio: 0.1526 - val_loss: -0.0466 - val_sharpe_ratio: 0.0847\n",
      "Epoch 14/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1204 - sharpe_ratio: 0.1574 - val_loss: -0.0262 - val_sharpe_ratio: 0.0775\n",
      "Epoch 15/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1175 - sharpe_ratio: 0.1568 - val_loss: -0.0679 - val_sharpe_ratio: 0.1185\n",
      "Epoch 16/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1136 - sharpe_ratio: 0.1529 - val_loss: -0.0346 - val_sharpe_ratio: 0.0715\n",
      "Epoch 17/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1113 - sharpe_ratio: 0.1524 - val_loss: -0.0284 - val_sharpe_ratio: 0.0690\n",
      "Epoch 18/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1074 - sharpe_ratio: 0.1548 - val_loss: -0.0412 - val_sharpe_ratio: 0.0822\n",
      "Epoch 19/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.0970 - sharpe_ratio: 0.1537 - val_loss: -0.0415 - val_sharpe_ratio: 0.1133\n",
      "Epoch 20/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1001 - sharpe_ratio: 0.1526 - val_loss: 0.0284 - val_sharpe_ratio: 0.0380\n",
      "Epoch 21/300\n",
      "95/95 [==============================] - 3s 32ms/step - loss: -0.1073 - sharpe_ratio: 0.1553 - val_loss: -0.0263 - val_sharpe_ratio: 0.0806\n",
      "Epoch 22/300\n",
      "95/95 [==============================] - 3s 31ms/step - loss: -0.1163 - sharpe_ratio: 0.1589 - val_loss: -0.0325 - val_sharpe_ratio: 0.0795\n",
      "Epoch 23/300\n",
      "95/95 [==============================] - 3s 32ms/step - loss: -0.1120 - sharpe_ratio: 0.1562 - val_loss: -0.0960 - val_sharpe_ratio: 0.1525\n",
      "Epoch 24/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1174 - sharpe_ratio: 0.1510 - val_loss: -0.0141 - val_sharpe_ratio: 0.0550\n",
      "Epoch 25/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1138 - sharpe_ratio: 0.1562 - val_loss: -0.0369 - val_sharpe_ratio: 0.0945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1149 - sharpe_ratio: 0.1549 - val_loss: -0.0573 - val_sharpe_ratio: 0.1061\n",
      "Epoch 27/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1111 - sharpe_ratio: 0.1560 - val_loss: -0.0149 - val_sharpe_ratio: 0.0671\n",
      "Epoch 28/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1104 - sharpe_ratio: 0.1522 - val_loss: -0.0515 - val_sharpe_ratio: 0.1024\n",
      "Epoch 29/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1095 - sharpe_ratio: 0.1531 - val_loss: 0.0105 - val_sharpe_ratio: 0.0374\n",
      "Epoch 30/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1137 - sharpe_ratio: 0.1570 - val_loss: -0.0094 - val_sharpe_ratio: 0.0555\n",
      "Epoch 31/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1190 - sharpe_ratio: 0.1580 - val_loss: -0.0352 - val_sharpe_ratio: 0.1010\n",
      "Epoch 32/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1053 - sharpe_ratio: 0.1533 - val_loss: -0.0506 - val_sharpe_ratio: 0.0876\n",
      "Epoch 33/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1146 - sharpe_ratio: 0.1539 - val_loss: 0.0320 - val_sharpe_ratio: 0.0150\n",
      "Epoch 34/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1113 - sharpe_ratio: 0.1531 - val_loss: 0.0282 - val_sharpe_ratio: 0.0194\n",
      "Epoch 35/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1137 - sharpe_ratio: 0.1495 - val_loss: 0.0558 - val_sharpe_ratio: -0.0158\n",
      "Epoch 36/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1123 - sharpe_ratio: 0.1511 - val_loss: -0.0685 - val_sharpe_ratio: 0.1185\n",
      "Epoch 37/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1118 - sharpe_ratio: 0.1534 - val_loss: -0.0359 - val_sharpe_ratio: 0.1155\n",
      "Epoch 38/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1121 - sharpe_ratio: 0.1535 - val_loss: 0.0081 - val_sharpe_ratio: 0.0476\n",
      "Epoch 39/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1167 - sharpe_ratio: 0.1564 - val_loss: 0.0012 - val_sharpe_ratio: 0.0193\n",
      "Epoch 40/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1144 - sharpe_ratio: 0.1570 - val_loss: -0.0639 - val_sharpe_ratio: 0.1098\n",
      "Epoch 41/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1180 - sharpe_ratio: 0.1573 - val_loss: -0.0428 - val_sharpe_ratio: 0.0798\n",
      "Epoch 42/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1109 - sharpe_ratio: 0.1517 - val_loss: 0.0057 - val_sharpe_ratio: 0.0488\n",
      "Epoch 43/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1074 - sharpe_ratio: 0.1558 - val_loss: -0.0086 - val_sharpe_ratio: 0.0692\n",
      "Epoch 44/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1157 - sharpe_ratio: 0.1538 - val_loss: -0.0369 - val_sharpe_ratio: 0.0736\n",
      "Epoch 45/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1133 - sharpe_ratio: 0.1512 - val_loss: -0.0941 - val_sharpe_ratio: 0.1416\n",
      "Epoch 46/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1172 - sharpe_ratio: 0.1574 - val_loss: -0.0957 - val_sharpe_ratio: 0.1413\n",
      "Epoch 47/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1187 - sharpe_ratio: 0.1607 - val_loss: 0.0058 - val_sharpe_ratio: 0.0341\n",
      "Epoch 48/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1134 - sharpe_ratio: 0.1549 - val_loss: -0.0415 - val_sharpe_ratio: 0.0804\n",
      "Epoch 49/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1081 - sharpe_ratio: 0.1532 - val_loss: -0.0732 - val_sharpe_ratio: 0.1280\n",
      "Epoch 50/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1055 - sharpe_ratio: 0.1539 - val_loss: 0.0325 - val_sharpe_ratio: 0.0295\n",
      "Epoch 51/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1070 - sharpe_ratio: 0.1530 - val_loss: 0.0301 - val_sharpe_ratio: 0.0276\n",
      "Epoch 52/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1110 - sharpe_ratio: 0.1483 - val_loss: 0.0119 - val_sharpe_ratio: 0.0468\n",
      "Epoch 53/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1194 - sharpe_ratio: 0.1606 - val_loss: 0.0087 - val_sharpe_ratio: 0.0372\n",
      "Epoch 54/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1135 - sharpe_ratio: 0.1557 - val_loss: -0.0294 - val_sharpe_ratio: 0.0712\n",
      "Epoch 55/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1084 - sharpe_ratio: 0.1457 - val_loss: 0.0036 - val_sharpe_ratio: 0.0513\n",
      "Epoch 56/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1107 - sharpe_ratio: 0.1594 - val_loss: -0.1008 - val_sharpe_ratio: 0.1416\n",
      "Epoch 57/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1124 - sharpe_ratio: 0.1536 - val_loss: 0.0591 - val_sharpe_ratio: -0.0226\n",
      "Epoch 58/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1014 - sharpe_ratio: 0.1531 - val_loss: 0.0085 - val_sharpe_ratio: 0.0275\n",
      "Epoch 59/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1093 - sharpe_ratio: 0.1566 - val_loss: -0.0134 - val_sharpe_ratio: 0.0733\n",
      "Epoch 60/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.0975 - sharpe_ratio: 0.1467 - val_loss: -0.0260 - val_sharpe_ratio: 0.0737\n",
      "Epoch 61/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1071 - sharpe_ratio: 0.1500 - val_loss: 0.0428 - val_sharpe_ratio: 0.0043\n",
      "Epoch 62/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1118 - sharpe_ratio: 0.1569 - val_loss: 0.0114 - val_sharpe_ratio: 0.0372\n",
      "Epoch 63/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1104 - sharpe_ratio: 0.1506 - val_loss: 0.0340 - val_sharpe_ratio: 0.0110\n",
      "Epoch 64/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1034 - sharpe_ratio: 0.1568 - val_loss: 0.0270 - val_sharpe_ratio: 0.0525\n",
      "Epoch 65/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1038 - sharpe_ratio: 0.1539 - val_loss: 0.0330 - val_sharpe_ratio: -0.0354\n",
      "Epoch 66/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1028 - sharpe_ratio: 0.1503 - val_loss: 0.0417 - val_sharpe_ratio: -0.0045\n",
      "Epoch 67/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1090 - sharpe_ratio: 0.1510 - val_loss: 0.0208 - val_sharpe_ratio: 0.0372\n",
      "Epoch 68/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1062 - sharpe_ratio: 0.1533 - val_loss: -0.0345 - val_sharpe_ratio: 0.0815\n",
      "Epoch 69/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1004 - sharpe_ratio: 0.1534 - val_loss: -0.0450 - val_sharpe_ratio: 0.1012\n",
      "Epoch 70/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1078 - sharpe_ratio: 0.1519 - val_loss: -0.0415 - val_sharpe_ratio: 0.0966\n",
      "Epoch 71/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1126 - sharpe_ratio: 0.1548 - val_loss: -0.0408 - val_sharpe_ratio: 0.1157\n",
      "Epoch 72/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1158 - sharpe_ratio: 0.1585 - val_loss: -0.0726 - val_sharpe_ratio: 0.1275\n",
      "Epoch 73/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1058 - sharpe_ratio: 0.1513 - val_loss: -0.0324 - val_sharpe_ratio: 0.0873\n",
      "Epoch 74/300\n",
      "95/95 [==============================] - 3s 31ms/step - loss: -0.1111 - sharpe_ratio: 0.1568 - val_loss: -0.0106 - val_sharpe_ratio: 0.0626\n",
      "Epoch 75/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1080 - sharpe_ratio: 0.1548 - val_loss: -0.0356 - val_sharpe_ratio: 0.0832\n",
      "Epoch 76/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1109 - sharpe_ratio: 0.1487 - val_loss: 0.0179 - val_sharpe_ratio: -0.0199\n",
      "Epoch 77/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1083 - sharpe_ratio: 0.1540 - val_loss: -0.0375 - val_sharpe_ratio: 0.1006\n",
      "Epoch 78/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1044 - sharpe_ratio: 0.1518 - val_loss: -4.4594e-04 - val_sharpe_ratio: 0.0621\n",
      "Epoch 79/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1189 - sharpe_ratio: 0.1602 - val_loss: 0.0535 - val_sharpe_ratio: 0.0200\n",
      "Epoch 80/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1100 - sharpe_ratio: 0.1548 - val_loss: -0.0195 - val_sharpe_ratio: 0.0770\n",
      "Epoch 81/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1140 - sharpe_ratio: 0.1523 - val_loss: -0.0166 - val_sharpe_ratio: 0.0781\n",
      "Epoch 82/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1122 - sharpe_ratio: 0.1571 - val_loss: -0.0258 - val_sharpe_ratio: 0.0929\n",
      "Epoch 83/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1026 - sharpe_ratio: 0.1542 - val_loss: 0.0705 - val_sharpe_ratio: 0.0150\n",
      "Epoch 84/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1065 - sharpe_ratio: 0.1548 - val_loss: 0.0196 - val_sharpe_ratio: 0.0295\n",
      "Epoch 85/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1149 - sharpe_ratio: 0.1513 - val_loss: 0.0168 - val_sharpe_ratio: 0.0599\n",
      "Epoch 86/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1045 - sharpe_ratio: 0.1507 - val_loss: 0.0307 - val_sharpe_ratio: 0.0301\n",
      "Epoch 87/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1091 - sharpe_ratio: 0.1563 - val_loss: -0.0121 - val_sharpe_ratio: 0.0558\n",
      "Epoch 88/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1106 - sharpe_ratio: 0.1523 - val_loss: -0.0032 - val_sharpe_ratio: 0.0360\n",
      "Epoch 89/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1062 - sharpe_ratio: 0.1463 - val_loss: 0.0196 - val_sharpe_ratio: 0.0566\n",
      "Epoch 90/300\n",
      "95/95 [==============================] - 3s 32ms/step - loss: -0.1136 - sharpe_ratio: 0.1573 - val_loss: -0.0226 - val_sharpe_ratio: 0.0655\n",
      "Epoch 91/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1184 - sharpe_ratio: 0.1506 - val_loss: -0.0386 - val_sharpe_ratio: 0.0901\n",
      "Epoch 92/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1032 - sharpe_ratio: 0.1563 - val_loss: -0.0531 - val_sharpe_ratio: 0.1185\n",
      "Epoch 93/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1169 - sharpe_ratio: 0.1614 - val_loss: 0.0149 - val_sharpe_ratio: 0.0491\n",
      "Epoch 94/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1175 - sharpe_ratio: 0.1587 - val_loss: -0.0471 - val_sharpe_ratio: 0.0900\n",
      "Epoch 95/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1117 - sharpe_ratio: 0.1619 - val_loss: 0.0315 - val_sharpe_ratio: 0.0033\n",
      "Epoch 96/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.0915 - sharpe_ratio: 0.1497 - val_loss: -0.0264 - val_sharpe_ratio: 0.1053\n",
      "Epoch 97/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1097 - sharpe_ratio: 0.1517 - val_loss: -0.0458 - val_sharpe_ratio: 0.1002\n",
      "Epoch 98/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1120 - sharpe_ratio: 0.1546 - val_loss: 7.7716e-04 - val_sharpe_ratio: 0.0577\n",
      "Epoch 99/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1141 - sharpe_ratio: 0.1582 - val_loss: -0.0139 - val_sharpe_ratio: 0.0599\n",
      "Epoch 100/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1031 - sharpe_ratio: 0.1520 - val_loss: -0.0214 - val_sharpe_ratio: 0.0498\n",
      "Epoch 101/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1053 - sharpe_ratio: 0.1516 - val_loss: -0.0543 - val_sharpe_ratio: 0.1067\n",
      "Epoch 102/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1074 - sharpe_ratio: 0.1537 - val_loss: 0.0188 - val_sharpe_ratio: 0.0452\n",
      "Epoch 103/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1042 - sharpe_ratio: 0.1519 - val_loss: 0.0057 - val_sharpe_ratio: 0.0596\n",
      "Epoch 104/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1073 - sharpe_ratio: 0.1568 - val_loss: -0.0072 - val_sharpe_ratio: 0.0496\n",
      "Epoch 105/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1186 - sharpe_ratio: 0.1551 - val_loss: -0.0467 - val_sharpe_ratio: 0.0805\n",
      "Epoch 106/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1098 - sharpe_ratio: 0.1543 - val_loss: -0.0287 - val_sharpe_ratio: 0.1033\n",
      "Epoch 107/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1083 - sharpe_ratio: 0.1568 - val_loss: -0.0357 - val_sharpe_ratio: 0.1163\n",
      "Epoch 108/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1049 - sharpe_ratio: 0.1495 - val_loss: 0.0507 - val_sharpe_ratio: -0.0129\n",
      "Epoch 109/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1040 - sharpe_ratio: 0.1522 - val_loss: -0.0767 - val_sharpe_ratio: 0.1205\n",
      "Epoch 110/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1066 - sharpe_ratio: 0.1507 - val_loss: -0.0228 - val_sharpe_ratio: 0.0655\n",
      "Epoch 111/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1036 - sharpe_ratio: 0.1487 - val_loss: 0.0168 - val_sharpe_ratio: -0.0284\n",
      "Epoch 112/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1102 - sharpe_ratio: 0.1559 - val_loss: -0.0601 - val_sharpe_ratio: 0.1061\n",
      "Epoch 113/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1145 - sharpe_ratio: 0.1559 - val_loss: -0.0493 - val_sharpe_ratio: 0.1123\n",
      "Epoch 114/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1088 - sharpe_ratio: 0.1533 - val_loss: -0.0068 - val_sharpe_ratio: 0.0626\n",
      "Epoch 115/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1072 - sharpe_ratio: 0.1502 - val_loss: -0.0336 - val_sharpe_ratio: 0.0856\n",
      "Epoch 116/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1102 - sharpe_ratio: 0.1565 - val_loss: -0.0252 - val_sharpe_ratio: 0.0410\n",
      "Epoch 117/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1153 - sharpe_ratio: 0.1599 - val_loss: -0.0196 - val_sharpe_ratio: 0.0568\n",
      "Epoch 118/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1206 - sharpe_ratio: 0.1604 - val_loss: -0.0598 - val_sharpe_ratio: 0.0876\n",
      "Epoch 119/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1149 - sharpe_ratio: 0.1534 - val_loss: -0.0191 - val_sharpe_ratio: 0.0599\n",
      "Epoch 120/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1133 - sharpe_ratio: 0.1551 - val_loss: -0.0203 - val_sharpe_ratio: 0.0752\n",
      "Epoch 121/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1046 - sharpe_ratio: 0.1509 - val_loss: -0.0018 - val_sharpe_ratio: 0.0799\n",
      "Epoch 122/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1129 - sharpe_ratio: 0.1575 - val_loss: -0.0499 - val_sharpe_ratio: 0.1185\n",
      "Epoch 123/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1048 - sharpe_ratio: 0.1534 - val_loss: -0.0629 - val_sharpe_ratio: 0.1146\n",
      "Epoch 124/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1022 - sharpe_ratio: 0.1577 - val_loss: -0.0393 - val_sharpe_ratio: 0.0846\n",
      "Epoch 125/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1140 - sharpe_ratio: 0.1555 - val_loss: 0.0044 - val_sharpe_ratio: 0.0406\n",
      "Epoch 126/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1072 - sharpe_ratio: 0.1502 - val_loss: 0.0122 - val_sharpe_ratio: 0.0430\n",
      "Epoch 127/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1055 - sharpe_ratio: 0.1537 - val_loss: 0.0088 - val_sharpe_ratio: 0.0549\n",
      "Epoch 128/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1093 - sharpe_ratio: 0.1552 - val_loss: -0.0107 - val_sharpe_ratio: 0.0674\n",
      "Epoch 129/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1074 - sharpe_ratio: 0.1566 - val_loss: -0.0474 - val_sharpe_ratio: 0.0948\n",
      "Epoch 130/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1177 - sharpe_ratio: 0.1609 - val_loss: -0.0328 - val_sharpe_ratio: 0.0834\n",
      "Epoch 131/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1053 - sharpe_ratio: 0.1527 - val_loss: -0.0696 - val_sharpe_ratio: 0.1354\n",
      "Epoch 132/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 3s 28ms/step - loss: -0.0959 - sharpe_ratio: 0.1581 - val_loss: 0.0140 - val_sharpe_ratio: 0.0384\n",
      "Epoch 133/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1092 - sharpe_ratio: 0.1524 - val_loss: -0.0368 - val_sharpe_ratio: 0.0876\n",
      "Epoch 134/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1043 - sharpe_ratio: 0.1557 - val_loss: -0.0326 - val_sharpe_ratio: 0.0936\n",
      "Epoch 135/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1047 - sharpe_ratio: 0.1535 - val_loss: -0.0270 - val_sharpe_ratio: 0.0824\n",
      "Epoch 136/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1146 - sharpe_ratio: 0.1589 - val_loss: -0.0285 - val_sharpe_ratio: 0.0948\n",
      "Epoch 137/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1142 - sharpe_ratio: 0.1557 - val_loss: -0.0332 - val_sharpe_ratio: 0.0860\n",
      "Epoch 138/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1084 - sharpe_ratio: 0.1538 - val_loss: -0.0117 - val_sharpe_ratio: 0.0635\n",
      "Epoch 139/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1031 - sharpe_ratio: 0.1528 - val_loss: 0.0081 - val_sharpe_ratio: 0.1061\n",
      "Epoch 140/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1053 - sharpe_ratio: 0.1544 - val_loss: -9.0922e-04 - val_sharpe_ratio: 0.0523\n",
      "Epoch 141/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.0938 - sharpe_ratio: 0.1506 - val_loss: -0.0225 - val_sharpe_ratio: 0.0815\n",
      "Epoch 142/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1023 - sharpe_ratio: 0.1506 - val_loss: -0.0571 - val_sharpe_ratio: 0.1010\n",
      "Epoch 143/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1173 - sharpe_ratio: 0.1559 - val_loss: -0.0522 - val_sharpe_ratio: 0.1034\n",
      "Epoch 144/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1136 - sharpe_ratio: 0.1541 - val_loss: -0.0138 - val_sharpe_ratio: 0.0845\n",
      "Epoch 145/300\n",
      "95/95 [==============================] - 3s 31ms/step - loss: -0.1128 - sharpe_ratio: 0.1564 - val_loss: -0.0326 - val_sharpe_ratio: 0.0715\n",
      "Epoch 146/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1091 - sharpe_ratio: 0.1524 - val_loss: -0.0487 - val_sharpe_ratio: 0.1147\n",
      "Epoch 147/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1119 - sharpe_ratio: 0.1531 - val_loss: -0.0384 - val_sharpe_ratio: 0.0845\n",
      "Epoch 148/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1089 - sharpe_ratio: 0.1511 - val_loss: -0.0457 - val_sharpe_ratio: 0.0974\n",
      "Epoch 149/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1141 - sharpe_ratio: 0.1550 - val_loss: 0.0011 - val_sharpe_ratio: 0.0459\n",
      "Epoch 150/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1031 - sharpe_ratio: 0.1484 - val_loss: 0.0017 - val_sharpe_ratio: 0.0511\n",
      "Epoch 151/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1018 - sharpe_ratio: 0.1519 - val_loss: -0.0012 - val_sharpe_ratio: 0.0561\n",
      "Epoch 152/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1117 - sharpe_ratio: 0.1507 - val_loss: 0.0028 - val_sharpe_ratio: 0.0363\n",
      "Epoch 153/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1195 - sharpe_ratio: 0.1575 - val_loss: -0.0332 - val_sharpe_ratio: 0.0727\n",
      "Epoch 154/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1130 - sharpe_ratio: 0.1514 - val_loss: -0.0453 - val_sharpe_ratio: 0.0871\n",
      "Epoch 155/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1161 - sharpe_ratio: 0.1597 - val_loss: -0.0687 - val_sharpe_ratio: 0.1196\n",
      "Epoch 156/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1147 - sharpe_ratio: 0.1521 - val_loss: -0.0098 - val_sharpe_ratio: 0.0653\n",
      "Epoch 157/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1145 - sharpe_ratio: 0.1522 - val_loss: -0.0054 - val_sharpe_ratio: 0.0433\n",
      "Epoch 158/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.0928 - sharpe_ratio: 0.1460 - val_loss: 0.0608 - val_sharpe_ratio: 0.0162\n",
      "Epoch 159/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.0992 - sharpe_ratio: 0.1484 - val_loss: 0.0030 - val_sharpe_ratio: 0.0734\n",
      "Epoch 160/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.0942 - sharpe_ratio: 0.1534 - val_loss: -1.9915e-05 - val_sharpe_ratio: 0.0372\n",
      "Epoch 161/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1126 - sharpe_ratio: 0.1530 - val_loss: -0.0215 - val_sharpe_ratio: 0.0776\n",
      "Epoch 162/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1144 - sharpe_ratio: 0.1539 - val_loss: -0.0430 - val_sharpe_ratio: 0.0845\n",
      "Epoch 163/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1196 - sharpe_ratio: 0.1560 - val_loss: 2.6280e-04 - val_sharpe_ratio: 0.0496\n",
      "Epoch 164/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1179 - sharpe_ratio: 0.1559 - val_loss: -0.0406 - val_sharpe_ratio: 0.0888\n",
      "Epoch 165/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1106 - sharpe_ratio: 0.1497 - val_loss: -0.0896 - val_sharpe_ratio: 0.1416\n",
      "Epoch 166/300\n",
      "95/95 [==============================] - 3s 32ms/step - loss: -0.1021 - sharpe_ratio: 0.1543 - val_loss: -0.0146 - val_sharpe_ratio: 0.0622\n",
      "Epoch 167/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1173 - sharpe_ratio: 0.1522 - val_loss: 0.0265 - val_sharpe_ratio: 0.0190\n",
      "Epoch 168/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1126 - sharpe_ratio: 0.1488 - val_loss: -0.0628 - val_sharpe_ratio: 0.0948\n",
      "Epoch 169/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1146 - sharpe_ratio: 0.1532 - val_loss: 0.0390 - val_sharpe_ratio: -0.0430\n",
      "Epoch 170/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1178 - sharpe_ratio: 0.1542 - val_loss: -0.0210 - val_sharpe_ratio: 0.0610\n",
      "Epoch 171/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1052 - sharpe_ratio: 0.1464 - val_loss: 0.0334 - val_sharpe_ratio: 0.0239\n",
      "Epoch 172/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1145 - sharpe_ratio: 0.1502 - val_loss: 0.0156 - val_sharpe_ratio: 0.0372\n",
      "Epoch 173/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1122 - sharpe_ratio: 0.1459 - val_loss: -0.0212 - val_sharpe_ratio: 0.0886\n",
      "Epoch 174/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1159 - sharpe_ratio: 0.1497 - val_loss: -0.0025 - val_sharpe_ratio: 0.0607\n",
      "Epoch 175/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1150 - sharpe_ratio: 0.1480 - val_loss: -0.0017 - val_sharpe_ratio: 0.0527\n",
      "Epoch 176/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1116 - sharpe_ratio: 0.1512 - val_loss: -0.0560 - val_sharpe_ratio: 0.1033\n",
      "Epoch 177/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1217 - sharpe_ratio: 0.1570 - val_loss: -0.0656 - val_sharpe_ratio: 0.0876\n",
      "Epoch 178/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1190 - sharpe_ratio: 0.1534 - val_loss: 0.0078 - val_sharpe_ratio: 0.0408\n",
      "Epoch 179/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1177 - sharpe_ratio: 0.1531 - val_loss: -0.0185 - val_sharpe_ratio: 0.0641\n",
      "Epoch 180/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1093 - sharpe_ratio: 0.1472 - val_loss: -0.0738 - val_sharpe_ratio: 0.1041\n",
      "Epoch 181/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1202 - sharpe_ratio: 0.1537 - val_loss: -0.0798 - val_sharpe_ratio: 0.1416\n",
      "Epoch 182/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1151 - sharpe_ratio: 0.1592 - val_loss: -0.0310 - val_sharpe_ratio: 0.0814\n",
      "Epoch 183/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1090 - sharpe_ratio: 0.1536 - val_loss: -0.0154 - val_sharpe_ratio: 0.0760\n",
      "Epoch 184/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1071 - sharpe_ratio: 0.1536 - val_loss: -0.0067 - val_sharpe_ratio: 0.0622\n",
      "Epoch 185/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1131 - sharpe_ratio: 0.1556 - val_loss: -0.0220 - val_sharpe_ratio: 0.0816\n",
      "Epoch 186/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1151 - sharpe_ratio: 0.1517 - val_loss: -0.0378 - val_sharpe_ratio: 0.0645\n",
      "Epoch 187/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1150 - sharpe_ratio: 0.1481 - val_loss: -0.0262 - val_sharpe_ratio: 0.0693\n",
      "Epoch 188/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1188 - sharpe_ratio: 0.1546 - val_loss: -0.0607 - val_sharpe_ratio: 0.1111\n",
      "Epoch 189/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1315 - sharpe_ratio: 0.1559 - val_loss: 0.0389 - val_sharpe_ratio: -0.0022\n",
      "Epoch 190/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1188 - sharpe_ratio: 0.1489 - val_loss: 0.0425 - val_sharpe_ratio: 0.0150\n",
      "Epoch 191/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1131 - sharpe_ratio: 0.1479 - val_loss: -0.0430 - val_sharpe_ratio: 0.0781\n",
      "Epoch 192/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1148 - sharpe_ratio: 0.1464 - val_loss: 0.0444 - val_sharpe_ratio: -0.0320\n",
      "Epoch 193/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1181 - sharpe_ratio: 0.1533 - val_loss: -0.0094 - val_sharpe_ratio: 0.0516\n",
      "Epoch 194/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1138 - sharpe_ratio: 0.1537 - val_loss: -0.0192 - val_sharpe_ratio: 0.0795\n",
      "Epoch 195/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.0990 - sharpe_ratio: 0.1547 - val_loss: 0.0215 - val_sharpe_ratio: 0.0351\n",
      "Epoch 196/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1077 - sharpe_ratio: 0.1536 - val_loss: -0.0227 - val_sharpe_ratio: 0.0833\n",
      "Epoch 197/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1146 - sharpe_ratio: 0.1572 - val_loss: -0.0664 - val_sharpe_ratio: 0.1133\n",
      "Epoch 198/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1105 - sharpe_ratio: 0.1485 - val_loss: -0.0213 - val_sharpe_ratio: 0.0664\n",
      "Epoch 199/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1169 - sharpe_ratio: 0.1512 - val_loss: -0.0067 - val_sharpe_ratio: 0.0467\n",
      "Epoch 200/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1167 - sharpe_ratio: 0.1559 - val_loss: -0.0924 - val_sharpe_ratio: 0.1278\n",
      "Epoch 201/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1096 - sharpe_ratio: 0.1521 - val_loss: 0.0246 - val_sharpe_ratio: 0.0139\n",
      "Epoch 202/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1106 - sharpe_ratio: 0.1486 - val_loss: 5.5884e-04 - val_sharpe_ratio: 0.0447\n",
      "Epoch 203/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1081 - sharpe_ratio: 0.1544 - val_loss: 0.0183 - val_sharpe_ratio: 0.0771\n",
      "Epoch 204/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1139 - sharpe_ratio: 0.1593 - val_loss: -0.0133 - val_sharpe_ratio: 0.0652\n",
      "Epoch 205/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1256 - sharpe_ratio: 0.1555 - val_loss: -0.0507 - val_sharpe_ratio: 0.1023\n",
      "Epoch 206/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1088 - sharpe_ratio: 0.1565 - val_loss: 0.0329 - val_sharpe_ratio: 0.0150\n",
      "Epoch 207/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1110 - sharpe_ratio: 0.1555 - val_loss: 0.0057 - val_sharpe_ratio: 0.0492\n",
      "Epoch 208/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1156 - sharpe_ratio: 0.1533 - val_loss: -0.0594 - val_sharpe_ratio: 0.0974\n",
      "Epoch 209/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1136 - sharpe_ratio: 0.1549 - val_loss: -0.0267 - val_sharpe_ratio: 0.0841\n",
      "Epoch 210/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1183 - sharpe_ratio: 0.1559 - val_loss: -0.0719 - val_sharpe_ratio: 0.1216\n",
      "Epoch 211/300\n",
      "95/95 [==============================] - 3s 31ms/step - loss: -0.1126 - sharpe_ratio: 0.1507 - val_loss: -0.0265 - val_sharpe_ratio: 0.0715\n",
      "Epoch 212/300\n",
      "95/95 [==============================] - 3s 31ms/step - loss: -0.1141 - sharpe_ratio: 0.1556 - val_loss: -0.0197 - val_sharpe_ratio: 0.0466\n",
      "Epoch 213/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1081 - sharpe_ratio: 0.1545 - val_loss: 0.0143 - val_sharpe_ratio: 0.0269\n",
      "Epoch 214/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1180 - sharpe_ratio: 0.1567 - val_loss: -0.0578 - val_sharpe_ratio: 0.1295\n",
      "Epoch 215/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1180 - sharpe_ratio: 0.1569 - val_loss: 0.0163 - val_sharpe_ratio: 0.0491\n",
      "Epoch 216/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1131 - sharpe_ratio: 0.1521 - val_loss: -0.0341 - val_sharpe_ratio: 0.0781\n",
      "Epoch 217/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1127 - sharpe_ratio: 0.1550 - val_loss: -0.0115 - val_sharpe_ratio: 0.0734\n",
      "Epoch 218/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1168 - sharpe_ratio: 0.1562 - val_loss: 0.0086 - val_sharpe_ratio: 0.0397\n",
      "Epoch 219/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1127 - sharpe_ratio: 0.1556 - val_loss: -0.0125 - val_sharpe_ratio: 0.0565\n",
      "Epoch 220/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1124 - sharpe_ratio: 0.1474 - val_loss: -0.0283 - val_sharpe_ratio: 0.0895\n",
      "Epoch 221/300\n",
      "95/95 [==============================] - 3s 32ms/step - loss: -0.1104 - sharpe_ratio: 0.1571 - val_loss: 0.0144 - val_sharpe_ratio: 0.0599\n",
      "Epoch 222/300\n",
      "95/95 [==============================] - 3s 32ms/step - loss: -0.0935 - sharpe_ratio: 0.1531 - val_loss: -0.0084 - val_sharpe_ratio: 0.0750\n",
      "Epoch 223/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1104 - sharpe_ratio: 0.1531 - val_loss: 0.0322 - val_sharpe_ratio: -0.0129\n",
      "Epoch 224/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1098 - sharpe_ratio: 0.1531 - val_loss: 0.0027 - val_sharpe_ratio: 0.0408\n",
      "Epoch 225/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1154 - sharpe_ratio: 0.1565 - val_loss: -0.0139 - val_sharpe_ratio: 0.0560\n",
      "Epoch 226/300\n",
      "95/95 [==============================] - 3s 31ms/step - loss: -0.1227 - sharpe_ratio: 0.1565 - val_loss: -0.0016 - val_sharpe_ratio: 0.0578\n",
      "Epoch 227/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1204 - sharpe_ratio: 0.1537 - val_loss: 0.0117 - val_sharpe_ratio: 0.0437\n",
      "Epoch 228/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1122 - sharpe_ratio: 0.1539 - val_loss: -0.0188 - val_sharpe_ratio: 0.0520\n",
      "Epoch 229/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1054 - sharpe_ratio: 0.1488 - val_loss: -0.0269 - val_sharpe_ratio: 0.0619\n",
      "Epoch 230/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1157 - sharpe_ratio: 0.1607 - val_loss: -0.0179 - val_sharpe_ratio: 0.0584\n",
      "Epoch 231/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1155 - sharpe_ratio: 0.1576 - val_loss: 0.0099 - val_sharpe_ratio: 0.0057\n",
      "Epoch 232/300\n",
      "95/95 [==============================] - 3s 35ms/step - loss: -0.1213 - sharpe_ratio: 0.1562 - val_loss: -0.0289 - val_sharpe_ratio: 0.0876\n",
      "Epoch 233/300\n",
      "95/95 [==============================] - 3s 31ms/step - loss: -0.1014 - sharpe_ratio: 0.1499 - val_loss: -0.0120 - val_sharpe_ratio: 0.0676\n",
      "Epoch 234/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1125 - sharpe_ratio: 0.1548 - val_loss: -0.0241 - val_sharpe_ratio: 0.0749\n",
      "Epoch 235/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1240 - sharpe_ratio: 0.1596 - val_loss: -0.0237 - val_sharpe_ratio: 0.0609\n",
      "Epoch 236/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1117 - sharpe_ratio: 0.1517 - val_loss: -0.0030 - val_sharpe_ratio: 0.0377\n",
      "Epoch 237/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1169 - sharpe_ratio: 0.1500 - val_loss: -0.0361 - val_sharpe_ratio: 0.0683\n",
      "Epoch 238/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1243 - sharpe_ratio: 0.1590 - val_loss: -0.0236 - val_sharpe_ratio: 0.0701\n",
      "Epoch 239/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1196 - sharpe_ratio: 0.1540 - val_loss: -0.0078 - val_sharpe_ratio: 0.0496\n",
      "Epoch 240/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1129 - sharpe_ratio: 0.1528 - val_loss: -0.0095 - val_sharpe_ratio: 0.0680\n",
      "Epoch 241/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1152 - sharpe_ratio: 0.1544 - val_loss: -0.0632 - val_sharpe_ratio: 0.1041\n",
      "Epoch 242/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1189 - sharpe_ratio: 0.1549 - val_loss: -0.0224 - val_sharpe_ratio: 0.1006\n",
      "Epoch 243/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1103 - sharpe_ratio: 0.1530 - val_loss: -0.0184 - val_sharpe_ratio: 0.0562\n",
      "Epoch 244/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1181 - sharpe_ratio: 0.1549 - val_loss: 0.0060 - val_sharpe_ratio: 0.0432\n",
      "Epoch 245/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1129 - sharpe_ratio: 0.1541 - val_loss: 0.0405 - val_sharpe_ratio: 0.0115\n",
      "Epoch 246/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1043 - sharpe_ratio: 0.1449 - val_loss: -0.0231 - val_sharpe_ratio: 0.0832\n",
      "Epoch 247/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1168 - sharpe_ratio: 0.1589 - val_loss: -0.0228 - val_sharpe_ratio: 0.0886\n",
      "Epoch 248/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1061 - sharpe_ratio: 0.1546 - val_loss: -0.0349 - val_sharpe_ratio: 0.0816\n",
      "Epoch 249/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1050 - sharpe_ratio: 0.1605 - val_loss: 0.0072 - val_sharpe_ratio: 0.0561\n",
      "Epoch 250/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1112 - sharpe_ratio: 0.1524 - val_loss: -0.0373 - val_sharpe_ratio: 0.1125\n",
      "Epoch 251/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.0938 - sharpe_ratio: 0.1511 - val_loss: -0.0434 - val_sharpe_ratio: 0.1081\n",
      "Epoch 252/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1072 - sharpe_ratio: 0.1583 - val_loss: 0.0054 - val_sharpe_ratio: 0.0405\n",
      "Epoch 253/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1009 - sharpe_ratio: 0.1527 - val_loss: -0.0176 - val_sharpe_ratio: 0.0735\n",
      "Epoch 254/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1095 - sharpe_ratio: 0.1579 - val_loss: -0.0533 - val_sharpe_ratio: 0.1114\n",
      "Epoch 255/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1096 - sharpe_ratio: 0.1564 - val_loss: -0.0085 - val_sharpe_ratio: 0.0628\n",
      "Epoch 256/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1077 - sharpe_ratio: 0.1584 - val_loss: -0.0106 - val_sharpe_ratio: 0.0612\n",
      "Epoch 257/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1126 - sharpe_ratio: 0.1597 - val_loss: -0.0343 - val_sharpe_ratio: 0.1041\n",
      "Epoch 258/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1140 - sharpe_ratio: 0.1588 - val_loss: -0.0301 - val_sharpe_ratio: 0.0874\n",
      "Epoch 259/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1233 - sharpe_ratio: 0.1619 - val_loss: -0.0075 - val_sharpe_ratio: 0.0958\n",
      "Epoch 260/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1137 - sharpe_ratio: 0.1585 - val_loss: -0.0400 - val_sharpe_ratio: 0.0988\n",
      "Epoch 261/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1157 - sharpe_ratio: 0.1600 - val_loss: 0.0137 - val_sharpe_ratio: 0.0221\n",
      "Epoch 262/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1064 - sharpe_ratio: 0.1568 - val_loss: -0.0094 - val_sharpe_ratio: 0.0526\n",
      "Epoch 263/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1181 - sharpe_ratio: 0.1622 - val_loss: -0.0032 - val_sharpe_ratio: 0.0746\n",
      "Epoch 264/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1046 - sharpe_ratio: 0.1582 - val_loss: -0.0458 - val_sharpe_ratio: 0.1218\n",
      "Epoch 265/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1149 - sharpe_ratio: 0.1592 - val_loss: -0.0132 - val_sharpe_ratio: 0.0905\n",
      "Epoch 266/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1163 - sharpe_ratio: 0.1653 - val_loss: 0.0440 - val_sharpe_ratio: 0.0521\n",
      "Epoch 267/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1117 - sharpe_ratio: 0.1621 - val_loss: -0.0373 - val_sharpe_ratio: 0.0887\n",
      "Epoch 268/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1192 - sharpe_ratio: 0.1592 - val_loss: -0.0595 - val_sharpe_ratio: 0.0833\n",
      "Epoch 269/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.0975 - sharpe_ratio: 0.1553 - val_loss: -0.0610 - val_sharpe_ratio: 0.1200\n",
      "Epoch 270/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1011 - sharpe_ratio: 0.1548 - val_loss: 0.0094 - val_sharpe_ratio: 0.0625\n",
      "Epoch 271/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1105 - sharpe_ratio: 0.1625 - val_loss: -0.0021 - val_sharpe_ratio: 0.0320\n",
      "Epoch 272/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1128 - sharpe_ratio: 0.1620 - val_loss: -0.0290 - val_sharpe_ratio: 0.0929\n",
      "Epoch 273/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1054 - sharpe_ratio: 0.1554 - val_loss: 0.0066 - val_sharpe_ratio: 0.0320\n",
      "Epoch 274/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1094 - sharpe_ratio: 0.1617 - val_loss: -0.0302 - val_sharpe_ratio: 0.0838\n",
      "Epoch 275/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1176 - sharpe_ratio: 0.1628 - val_loss: -0.0098 - val_sharpe_ratio: 0.0735\n",
      "Epoch 276/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1110 - sharpe_ratio: 0.1598 - val_loss: -0.0333 - val_sharpe_ratio: 0.0765\n",
      "Epoch 277/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1081 - sharpe_ratio: 0.1553 - val_loss: -0.0218 - val_sharpe_ratio: 0.0720\n",
      "Epoch 278/300\n",
      "95/95 [==============================] - 3s 31ms/step - loss: -0.1091 - sharpe_ratio: 0.1615 - val_loss: -0.0010 - val_sharpe_ratio: 0.0602\n",
      "Epoch 279/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1101 - sharpe_ratio: 0.1628 - val_loss: -0.0171 - val_sharpe_ratio: 0.0602\n",
      "Epoch 280/300\n",
      "95/95 [==============================] - 3s 31ms/step - loss: -0.1176 - sharpe_ratio: 0.1631 - val_loss: -0.0580 - val_sharpe_ratio: 0.1025\n",
      "Epoch 281/300\n",
      "95/95 [==============================] - 3s 31ms/step - loss: -0.1203 - sharpe_ratio: 0.1613 - val_loss: -0.0581 - val_sharpe_ratio: 0.1174\n",
      "Epoch 282/300\n",
      "95/95 [==============================] - 3s 37ms/step - loss: -0.1155 - sharpe_ratio: 0.1583 - val_loss: 0.0219 - val_sharpe_ratio: 0.0242\n",
      "Epoch 283/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1114 - sharpe_ratio: 0.1587 - val_loss: 0.0323 - val_sharpe_ratio: 0.0242\n",
      "Epoch 284/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1139 - sharpe_ratio: 0.1670 - val_loss: -0.0456 - val_sharpe_ratio: 0.1120\n",
      "Epoch 285/300\n",
      "95/95 [==============================] - 3s 32ms/step - loss: -0.1132 - sharpe_ratio: 0.1596 - val_loss: 0.0100 - val_sharpe_ratio: 0.0420\n",
      "Epoch 286/300\n",
      "95/95 [==============================] - 3s 31ms/step - loss: -0.1051 - sharpe_ratio: 0.1546 - val_loss: 0.0251 - val_sharpe_ratio: 0.0320\n",
      "Epoch 287/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.0969 - sharpe_ratio: 0.1528 - val_loss: -0.0391 - val_sharpe_ratio: 0.0994\n",
      "Epoch 288/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1166 - sharpe_ratio: 0.1580 - val_loss: -0.0097 - val_sharpe_ratio: 0.0570\n",
      "Epoch 289/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1143 - sharpe_ratio: 0.1602 - val_loss: -0.0153 - val_sharpe_ratio: 0.1021\n",
      "Epoch 290/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1146 - sharpe_ratio: 0.1597 - val_loss: 0.0033 - val_sharpe_ratio: 0.0504\n",
      "Epoch 291/300\n",
      "95/95 [==============================] - 3s 31ms/step - loss: -0.1209 - sharpe_ratio: 0.1638 - val_loss: -0.0472 - val_sharpe_ratio: 0.0879\n",
      "Epoch 292/300\n",
      "95/95 [==============================] - 3s 30ms/step - loss: -0.1177 - sharpe_ratio: 0.1632 - val_loss: -0.0208 - val_sharpe_ratio: 0.0586\n",
      "Epoch 293/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1166 - sharpe_ratio: 0.1593 - val_loss: -0.0212 - val_sharpe_ratio: 0.0817\n",
      "Epoch 294/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1273 - sharpe_ratio: 0.1639 - val_loss: -0.0319 - val_sharpe_ratio: 0.0828\n",
      "Epoch 295/300\n",
      "95/95 [==============================] - 3s 27ms/step - loss: -0.1188 - sharpe_ratio: 0.1610 - val_loss: -0.0452 - val_sharpe_ratio: 0.0817\n",
      "Epoch 296/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1240 - sharpe_ratio: 0.1650 - val_loss: -0.0248 - val_sharpe_ratio: 0.0579\n",
      "Epoch 297/300\n",
      "95/95 [==============================] - 3s 28ms/step - loss: -0.1145 - sharpe_ratio: 0.1612 - val_loss: 0.0124 - val_sharpe_ratio: 0.0353\n",
      "Epoch 298/300\n",
      "95/95 [==============================] - 3s 29ms/step - loss: -0.1170 - sharpe_ratio: 0.1634 - val_loss: -0.0341 - val_sharpe_ratio: 0.0921\n",
      "Epoch 299/300\n",
      "95/95 [==============================] - 3s 31ms/step - loss: -0.1206 - sharpe_ratio: 0.1624 - val_loss: -0.0647 - val_sharpe_ratio: 0.1146\n",
      "Epoch 300/300\n",
      "95/95 [==============================] - 3s 36ms/step - loss: -0.1240 - sharpe_ratio: 0.1595 - val_loss: -0.0294 - val_sharpe_ratio: 0.0897\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "There are total 11 samples to predict\n",
      "Sample 0 : [ ASIANPAINT.NS HDFC.NS HDFCBANK.NS INFY.NS MARUTI.NS RELIANCE.NS TCS.NS ]\n",
      "Sample 1 : [ ASIANPAINT.NS HDFC.NS HDFCBANK.NS INFY.NS MARUTI.NS RELIANCE.NS TCS.NS ]\n",
      "Sample 2 : [ ASIANPAINT.NS HDFC.NS HDFCBANK.NS INFY.NS MARUTI.NS RELIANCE.NS TCS.NS ]\n",
      "Sample 3 : [ ASIANPAINT.NS HDFC.NS HDFCBANK.NS INFY.NS MARUTI.NS RELIANCE.NS TCS.NS ]\n",
      "Sample 4 : [ ASIANPAINT.NS HDFC.NS HDFCBANK.NS INFY.NS MARUTI.NS RELIANCE.NS TCS.NS ]\n",
      "Sample 5 : [ HDFC.NS HDFCBANK.NS INFY.NS MARUTI.NS RELIANCE.NS TCS.NS ]\n",
      "Sample 6 : [ ASIANPAINT.NS HDFC.NS HDFCBANK.NS INFY.NS MARUTI.NS RELIANCE.NS TCS.NS ]\n",
      "Sample 7 : [ ASIANPAINT.NS HDFC.NS HDFCBANK.NS INFY.NS MARUTI.NS RELIANCE.NS TCS.NS ]\n",
      "Sample 8 : [ ASIANPAINT.NS HDFC.NS HDFCBANK.NS INFY.NS MARUTI.NS RELIANCE.NS TCS.NS ]\n",
      "Sample 9 : [ ASIANPAINT.NS HDFC.NS HDFCBANK.NS INFY.NS MARUTI.NS RELIANCE.NS TCS.NS ]\n",
      "Sample 10 : [ ASIANPAINT.NS HDFC.NS HDFCBANK.NS INFY.NS MARUTI.NS RELIANCE.NS TCS.NS ]\n",
      "Sharpe ratio of this portfolio: [1.230677850867467, 0.5581981389938003, -0.6652388093534575, -1.8712040372441312, -0.267865094462823, 0.5421436071132107, 1.1216339419877788, 1.3149016842404102, 1.3695318143563286, 1.1132331519572043, -0.14534610870596762]\n",
      "write file log at C:/Users/yv67/Documents/12FundsHK_ToShare/deeplearningdata/logs/GRU\\log_1733.txt\n",
      "Epoch 1/300\n",
      "109/109 [==============================] - 4s 35ms/step - loss: -0.1071 - sharpe_ratio: 0.1507 - val_loss: -0.1101 - val_sharpe_ratio: 0.1678\n",
      "Epoch 2/300\n",
      "109/109 [==============================] - 3s 31ms/step - loss: -0.1079 - sharpe_ratio: 0.1554 - val_loss: -0.0736 - val_sharpe_ratio: 0.1461\n",
      "Epoch 3/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.1077 - sharpe_ratio: 0.1547 - val_loss: -0.1070 - val_sharpe_ratio: 0.1345\n",
      "Epoch 4/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1028 - sharpe_ratio: 0.1498 - val_loss: -0.0742 - val_sharpe_ratio: 0.1424\n",
      "Epoch 5/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1022 - sharpe_ratio: 0.1485 - val_loss: -0.0800 - val_sharpe_ratio: 0.1083\n",
      "Epoch 6/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.0986 - sharpe_ratio: 0.1503 - val_loss: -0.1408 - val_sharpe_ratio: 0.1903\n",
      "Epoch 7/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.1099 - sharpe_ratio: 0.1545 - val_loss: -0.1078 - val_sharpe_ratio: 0.1570\n",
      "Epoch 8/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.0964 - sharpe_ratio: 0.1499 - val_loss: -0.0874 - val_sharpe_ratio: 0.0989\n",
      "Epoch 9/300\n",
      "109/109 [==============================] - 4s 33ms/step - loss: -0.1029 - sharpe_ratio: 0.1510 - val_loss: -0.0848 - val_sharpe_ratio: 0.1558\n",
      "Epoch 10/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.1113 - sharpe_ratio: 0.1506 - val_loss: -0.1201 - val_sharpe_ratio: 0.1737\n",
      "Epoch 11/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1016 - sharpe_ratio: 0.1505 - val_loss: -0.1266 - val_sharpe_ratio: 0.1736\n",
      "Epoch 12/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.1063 - sharpe_ratio: 0.1523 - val_loss: -0.1387 - val_sharpe_ratio: 0.1825\n",
      "Epoch 13/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1174 - sharpe_ratio: 0.1545 - val_loss: -0.1224 - val_sharpe_ratio: 0.1546\n",
      "Epoch 14/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1122 - sharpe_ratio: 0.1555 - val_loss: -0.0850 - val_sharpe_ratio: 0.1361\n",
      "Epoch 15/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.0970 - sharpe_ratio: 0.1494 - val_loss: -0.0632 - val_sharpe_ratio: 0.1161\n",
      "Epoch 16/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1059 - sharpe_ratio: 0.1512 - val_loss: -0.0610 - val_sharpe_ratio: 0.1147\n",
      "Epoch 17/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.1054 - sharpe_ratio: 0.1439 - val_loss: -0.1049 - val_sharpe_ratio: 0.1364\n",
      "Epoch 18/300\n",
      "109/109 [==============================] - 3s 31ms/step - loss: -0.1045 - sharpe_ratio: 0.1517 - val_loss: -0.0987 - val_sharpe_ratio: 0.1581\n",
      "Epoch 19/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.1058 - sharpe_ratio: 0.1564 - val_loss: -0.1124 - val_sharpe_ratio: 0.1754\n",
      "Epoch 20/300\n",
      "109/109 [==============================] - 3s 31ms/step - loss: -0.0980 - sharpe_ratio: 0.1474 - val_loss: -0.0765 - val_sharpe_ratio: 0.1150\n",
      "Epoch 21/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.0927 - sharpe_ratio: 0.1494 - val_loss: -0.1098 - val_sharpe_ratio: 0.1558\n",
      "Epoch 22/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1094 - sharpe_ratio: 0.1529 - val_loss: -0.0547 - val_sharpe_ratio: 0.0965\n",
      "Epoch 23/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1017 - sharpe_ratio: 0.1484 - val_loss: -0.1131 - val_sharpe_ratio: 0.1558\n",
      "Epoch 24/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1015 - sharpe_ratio: 0.1524 - val_loss: -0.1175 - val_sharpe_ratio: 0.1790\n",
      "Epoch 25/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.0924 - sharpe_ratio: 0.1459 - val_loss: -0.0883 - val_sharpe_ratio: 0.1413\n",
      "Epoch 26/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1044 - sharpe_ratio: 0.1520 - val_loss: -0.0209 - val_sharpe_ratio: 0.0416\n",
      "Epoch 27/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1102 - sharpe_ratio: 0.1520 - val_loss: -0.0302 - val_sharpe_ratio: 0.0893\n",
      "Epoch 28/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1012 - sharpe_ratio: 0.1495 - val_loss: -0.1046 - val_sharpe_ratio: 0.1498\n",
      "Epoch 29/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1074 - sharpe_ratio: 0.1524 - val_loss: -0.0833 - val_sharpe_ratio: 0.1165\n",
      "Epoch 30/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1144 - sharpe_ratio: 0.1593 - val_loss: -0.1229 - val_sharpe_ratio: 0.1650\n",
      "Epoch 31/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1047 - sharpe_ratio: 0.1555 - val_loss: -0.1285 - val_sharpe_ratio: 0.1751\n",
      "Epoch 32/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.0922 - sharpe_ratio: 0.1489 - val_loss: -0.0924 - val_sharpe_ratio: 0.1626\n",
      "Epoch 33/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.0961 - sharpe_ratio: 0.1508 - val_loss: -0.0894 - val_sharpe_ratio: 0.1593\n",
      "Epoch 34/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1111 - sharpe_ratio: 0.1535 - val_loss: -0.1279 - val_sharpe_ratio: 0.1690\n",
      "Epoch 35/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1143 - sharpe_ratio: 0.1508 - val_loss: -0.1461 - val_sharpe_ratio: 0.1909\n",
      "Epoch 36/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1191 - sharpe_ratio: 0.1555 - val_loss: -0.1012 - val_sharpe_ratio: 0.1563\n",
      "Epoch 37/300\n",
      "109/109 [==============================] - 4s 33ms/step - loss: -0.1047 - sharpe_ratio: 0.1505 - val_loss: -0.1184 - val_sharpe_ratio: 0.1767\n",
      "Epoch 38/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1015 - sharpe_ratio: 0.1513 - val_loss: -0.0850 - val_sharpe_ratio: 0.1375\n",
      "Epoch 39/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1084 - sharpe_ratio: 0.1501 - val_loss: -0.0700 - val_sharpe_ratio: 0.1258\n",
      "Epoch 40/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1052 - sharpe_ratio: 0.1522 - val_loss: -0.1157 - val_sharpe_ratio: 0.1792\n",
      "Epoch 41/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1042 - sharpe_ratio: 0.1523 - val_loss: -0.0833 - val_sharpe_ratio: 0.1147\n",
      "Epoch 42/300\n",
      "109/109 [==============================] - 3s 31ms/step - loss: -0.1025 - sharpe_ratio: 0.1529 - val_loss: -0.1337 - val_sharpe_ratio: 0.1737\n",
      "Epoch 43/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1156 - sharpe_ratio: 0.1576 - val_loss: -0.1224 - val_sharpe_ratio: 0.1737\n",
      "Epoch 44/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.1049 - sharpe_ratio: 0.1512 - val_loss: -0.0966 - val_sharpe_ratio: 0.1692\n",
      "Epoch 45/300\n",
      "109/109 [==============================] - 3s 32ms/step - loss: -0.0973 - sharpe_ratio: 0.1500 - val_loss: -0.0906 - val_sharpe_ratio: 0.1495\n",
      "Epoch 46/300\n",
      "109/109 [==============================] - 3s 31ms/step - loss: -0.0958 - sharpe_ratio: 0.1510 - val_loss: -0.0842 - val_sharpe_ratio: 0.1387\n",
      "Epoch 47/300\n",
      "109/109 [==============================] - 4s 32ms/step - loss: -0.0916 - sharpe_ratio: 0.1508 - val_loss: -0.0619 - val_sharpe_ratio: 0.1092\n",
      "Epoch 48/300\n",
      "109/109 [==============================] - 4s 33ms/step - loss: -0.1136 - sharpe_ratio: 0.1554 - val_loss: -0.1392 - val_sharpe_ratio: 0.1903\n",
      "Epoch 49/300\n",
      "109/109 [==============================] - 3s 32ms/step - loss: -0.1097 - sharpe_ratio: 0.1529 - val_loss: -0.0871 - val_sharpe_ratio: 0.1668\n",
      "Epoch 50/300\n",
      "109/109 [==============================] - 3s 31ms/step - loss: -0.1055 - sharpe_ratio: 0.1518 - val_loss: -0.0329 - val_sharpe_ratio: 0.0798\n",
      "Epoch 51/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.0999 - sharpe_ratio: 0.1514 - val_loss: -0.1268 - val_sharpe_ratio: 0.1753\n",
      "Epoch 52/300\n",
      "109/109 [==============================] - 3s 32ms/step - loss: -0.1009 - sharpe_ratio: 0.1510 - val_loss: -0.1316 - val_sharpe_ratio: 0.1844\n",
      "Epoch 53/300\n",
      "109/109 [==============================] - 3s 31ms/step - loss: -0.1025 - sharpe_ratio: 0.1501 - val_loss: -0.0894 - val_sharpe_ratio: 0.1448\n",
      "Epoch 54/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1187 - sharpe_ratio: 0.1563 - val_loss: -0.0870 - val_sharpe_ratio: 0.1433\n",
      "Epoch 55/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1161 - sharpe_ratio: 0.1562 - val_loss: -0.1026 - val_sharpe_ratio: 0.1647\n",
      "Epoch 56/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.1139 - sharpe_ratio: 0.1545 - val_loss: -0.0781 - val_sharpe_ratio: 0.1371\n",
      "Epoch 57/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.0951 - sharpe_ratio: 0.1495 - val_loss: -0.1097 - val_sharpe_ratio: 0.1652\n",
      "Epoch 58/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.1017 - sharpe_ratio: 0.1547 - val_loss: -0.1149 - val_sharpe_ratio: 0.1668\n",
      "Epoch 59/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1064 - sharpe_ratio: 0.1525 - val_loss: -0.1066 - val_sharpe_ratio: 0.1532\n",
      "Epoch 60/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1098 - sharpe_ratio: 0.1503 - val_loss: -0.0876 - val_sharpe_ratio: 0.1245\n",
      "Epoch 61/300\n",
      "109/109 [==============================] - 3s 32ms/step - loss: -0.1027 - sharpe_ratio: 0.1473 - val_loss: -0.0933 - val_sharpe_ratio: 0.1653\n",
      "Epoch 62/300\n",
      "109/109 [==============================] - 3s 31ms/step - loss: -0.1072 - sharpe_ratio: 0.1515 - val_loss: -0.1291 - val_sharpe_ratio: 0.1697\n",
      "Epoch 63/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.1107 - sharpe_ratio: 0.1531 - val_loss: -0.1369 - val_sharpe_ratio: 0.1860\n",
      "Epoch 64/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.1079 - sharpe_ratio: 0.1506 - val_loss: -0.0960 - val_sharpe_ratio: 0.1558\n",
      "Epoch 65/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1049 - sharpe_ratio: 0.1542 - val_loss: -0.0736 - val_sharpe_ratio: 0.1382\n",
      "Epoch 66/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.1060 - sharpe_ratio: 0.1504 - val_loss: -0.0940 - val_sharpe_ratio: 0.1258\n",
      "Epoch 67/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.1083 - sharpe_ratio: 0.1535 - val_loss: -0.1231 - val_sharpe_ratio: 0.1737\n",
      "Epoch 68/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1030 - sharpe_ratio: 0.1509 - val_loss: -0.1358 - val_sharpe_ratio: 0.1668\n",
      "Epoch 69/300\n",
      "109/109 [==============================] - 3s 31ms/step - loss: -0.0886 - sharpe_ratio: 0.1484 - val_loss: -0.1165 - val_sharpe_ratio: 0.1702\n",
      "Epoch 70/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.0972 - sharpe_ratio: 0.1434 - val_loss: -0.1091 - val_sharpe_ratio: 0.1881\n",
      "Epoch 71/300\n",
      "109/109 [==============================] - 3s 31ms/step - loss: -0.1080 - sharpe_ratio: 0.1541 - val_loss: -0.1253 - val_sharpe_ratio: 0.1746\n",
      "Epoch 72/300\n",
      "109/109 [==============================] - 3s 32ms/step - loss: -0.0968 - sharpe_ratio: 0.1500 - val_loss: -0.0911 - val_sharpe_ratio: 0.1395\n",
      "Epoch 73/300\n",
      "109/109 [==============================] - 3s 31ms/step - loss: -0.0957 - sharpe_ratio: 0.1492 - val_loss: -0.1139 - val_sharpe_ratio: 0.1597\n",
      "Epoch 74/300\n",
      "109/109 [==============================] - 3s 31ms/step - loss: -0.1102 - sharpe_ratio: 0.1515 - val_loss: -0.1021 - val_sharpe_ratio: 0.1765\n",
      "Epoch 75/300\n",
      "109/109 [==============================] - 4s 33ms/step - loss: -0.1140 - sharpe_ratio: 0.1547 - val_loss: -0.1339 - val_sharpe_ratio: 0.1895\n",
      "Epoch 76/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1043 - sharpe_ratio: 0.1500 - val_loss: -0.0634 - val_sharpe_ratio: 0.1150\n",
      "Epoch 77/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.1045 - sharpe_ratio: 0.1511 - val_loss: -0.1161 - val_sharpe_ratio: 0.1738\n",
      "Epoch 78/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1115 - sharpe_ratio: 0.1580 - val_loss: -0.1203 - val_sharpe_ratio: 0.1642\n",
      "Epoch 79/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1027 - sharpe_ratio: 0.1544 - val_loss: -0.0941 - val_sharpe_ratio: 0.1668\n",
      "Epoch 80/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1147 - sharpe_ratio: 0.1515 - val_loss: -0.1387 - val_sharpe_ratio: 0.1780\n",
      "Epoch 81/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1042 - sharpe_ratio: 0.1498 - val_loss: -0.0673 - val_sharpe_ratio: 0.1131\n",
      "Epoch 82/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.0995 - sharpe_ratio: 0.1498 - val_loss: -0.1043 - val_sharpe_ratio: 0.1723\n",
      "Epoch 83/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1024 - sharpe_ratio: 0.1531 - val_loss: -0.0281 - val_sharpe_ratio: 0.0724\n",
      "Epoch 84/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.0976 - sharpe_ratio: 0.1488 - val_loss: -0.0801 - val_sharpe_ratio: 0.1263\n",
      "Epoch 85/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1087 - sharpe_ratio: 0.1542 - val_loss: -0.0424 - val_sharpe_ratio: 0.0781\n",
      "Epoch 86/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.0997 - sharpe_ratio: 0.1551 - val_loss: -0.0858 - val_sharpe_ratio: 0.1607\n",
      "Epoch 87/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1071 - sharpe_ratio: 0.1580 - val_loss: -0.1101 - val_sharpe_ratio: 0.1737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/300\n",
      "109/109 [==============================] - 3s 31ms/step - loss: -0.1011 - sharpe_ratio: 0.1485 - val_loss: -0.1028 - val_sharpe_ratio: 0.1691\n",
      "Epoch 89/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.0979 - sharpe_ratio: 0.1518 - val_loss: -0.1213 - val_sharpe_ratio: 0.1794\n",
      "Epoch 90/300\n",
      "109/109 [==============================] - 3s 31ms/step - loss: -0.1011 - sharpe_ratio: 0.1536 - val_loss: -0.1311 - val_sharpe_ratio: 0.1903\n",
      "Epoch 91/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.0994 - sharpe_ratio: 0.1561 - val_loss: -0.0719 - val_sharpe_ratio: 0.1376\n",
      "Epoch 92/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.0954 - sharpe_ratio: 0.1516 - val_loss: -0.0785 - val_sharpe_ratio: 0.1316\n",
      "Epoch 93/300\n",
      "109/109 [==============================] - 3s 30ms/step - loss: -0.1064 - sharpe_ratio: 0.1497 - val_loss: -0.0633 - val_sharpe_ratio: 0.1128\n",
      "Epoch 94/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1049 - sharpe_ratio: 0.1551 - val_loss: -0.1361 - val_sharpe_ratio: 0.1903\n",
      "Epoch 95/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1075 - sharpe_ratio: 0.1565 - val_loss: -0.0676 - val_sharpe_ratio: 0.1128\n",
      "Epoch 96/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1121 - sharpe_ratio: 0.1592 - val_loss: -0.1038 - val_sharpe_ratio: 0.1466\n",
      "Epoch 97/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1036 - sharpe_ratio: 0.1584 - val_loss: -0.1018 - val_sharpe_ratio: 0.1650\n",
      "Epoch 98/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1224 - sharpe_ratio: 0.1526 - val_loss: -0.0441 - val_sharpe_ratio: 0.0600\n",
      "Epoch 99/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1127 - sharpe_ratio: 0.1559 - val_loss: -0.1038 - val_sharpe_ratio: 0.1295\n",
      "Epoch 100/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.0978 - sharpe_ratio: 0.1508 - val_loss: -0.0699 - val_sharpe_ratio: 0.1481\n",
      "Epoch 101/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.0860 - sharpe_ratio: 0.1477 - val_loss: -0.1358 - val_sharpe_ratio: 0.1921\n",
      "Epoch 102/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1097 - sharpe_ratio: 0.1567 - val_loss: -0.1210 - val_sharpe_ratio: 0.1687\n",
      "Epoch 103/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1047 - sharpe_ratio: 0.1515 - val_loss: -0.0963 - val_sharpe_ratio: 0.1373\n",
      "Epoch 104/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1028 - sharpe_ratio: 0.1588 - val_loss: -0.0755 - val_sharpe_ratio: 0.1516\n",
      "Epoch 105/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1140 - sharpe_ratio: 0.1547 - val_loss: -0.0583 - val_sharpe_ratio: 0.1263\n",
      "Epoch 106/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1073 - sharpe_ratio: 0.1580 - val_loss: -0.0650 - val_sharpe_ratio: 0.1299\n",
      "Epoch 107/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1055 - sharpe_ratio: 0.1548 - val_loss: -0.0797 - val_sharpe_ratio: 0.1500\n",
      "Epoch 108/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1034 - sharpe_ratio: 0.1633 - val_loss: -0.0805 - val_sharpe_ratio: 0.1403\n",
      "Epoch 109/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1011 - sharpe_ratio: 0.1523 - val_loss: -0.0692 - val_sharpe_ratio: 0.1180\n",
      "Epoch 110/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1072 - sharpe_ratio: 0.1528 - val_loss: -0.0651 - val_sharpe_ratio: 0.1231\n",
      "Epoch 111/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1113 - sharpe_ratio: 0.1568 - val_loss: -0.0819 - val_sharpe_ratio: 0.1401\n",
      "Epoch 112/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1069 - sharpe_ratio: 0.1506 - val_loss: -0.0631 - val_sharpe_ratio: 0.1128\n",
      "Epoch 113/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1130 - sharpe_ratio: 0.1594 - val_loss: -0.0172 - val_sharpe_ratio: 0.0716\n",
      "Epoch 114/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.0981 - sharpe_ratio: 0.1576 - val_loss: -0.0755 - val_sharpe_ratio: 0.1523\n",
      "Epoch 115/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1047 - sharpe_ratio: 0.1537 - val_loss: -0.0750 - val_sharpe_ratio: 0.1496\n",
      "Epoch 116/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1061 - sharpe_ratio: 0.1562 - val_loss: -0.1042 - val_sharpe_ratio: 0.1831\n",
      "Epoch 117/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1074 - sharpe_ratio: 0.1531 - val_loss: -0.0972 - val_sharpe_ratio: 0.1737\n",
      "Epoch 118/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1153 - sharpe_ratio: 0.1590 - val_loss: -0.0697 - val_sharpe_ratio: 0.1142\n",
      "Epoch 119/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1177 - sharpe_ratio: 0.1546 - val_loss: -0.0591 - val_sharpe_ratio: 0.1183\n",
      "Epoch 120/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1062 - sharpe_ratio: 0.1540 - val_loss: -0.0939 - val_sharpe_ratio: 0.1559\n",
      "Epoch 121/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1093 - sharpe_ratio: 0.1555 - val_loss: -0.0815 - val_sharpe_ratio: 0.1312\n",
      "Epoch 122/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1066 - sharpe_ratio: 0.1532 - val_loss: -0.0898 - val_sharpe_ratio: 0.1492\n",
      "Epoch 123/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1080 - sharpe_ratio: 0.1559 - val_loss: -0.1123 - val_sharpe_ratio: 0.1784\n",
      "Epoch 124/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1053 - sharpe_ratio: 0.1562 - val_loss: -0.0987 - val_sharpe_ratio: 0.1598\n",
      "Epoch 125/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.0977 - sharpe_ratio: 0.1542 - val_loss: -0.0765 - val_sharpe_ratio: 0.1400\n",
      "Epoch 126/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.0930 - sharpe_ratio: 0.1505 - val_loss: -0.0562 - val_sharpe_ratio: 0.1246\n",
      "Epoch 127/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.0994 - sharpe_ratio: 0.1538 - val_loss: -0.0682 - val_sharpe_ratio: 0.1152\n",
      "Epoch 128/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1059 - sharpe_ratio: 0.1558 - val_loss: -0.1131 - val_sharpe_ratio: 0.1481\n",
      "Epoch 129/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1082 - sharpe_ratio: 0.1531 - val_loss: -0.0308 - val_sharpe_ratio: 0.1267\n",
      "Epoch 130/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.0864 - sharpe_ratio: 0.1480 - val_loss: -0.1031 - val_sharpe_ratio: 0.1481\n",
      "Epoch 131/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1097 - sharpe_ratio: 0.1575 - val_loss: -0.1491 - val_sharpe_ratio: 0.2029\n",
      "Epoch 132/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1055 - sharpe_ratio: 0.1533 - val_loss: -0.0451 - val_sharpe_ratio: 0.1000\n",
      "Epoch 133/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1101 - sharpe_ratio: 0.1587 - val_loss: -0.0754 - val_sharpe_ratio: 0.1404\n",
      "Epoch 134/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1012 - sharpe_ratio: 0.1538 - val_loss: -0.0852 - val_sharpe_ratio: 0.1386\n",
      "Epoch 135/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.0999 - sharpe_ratio: 0.1522 - val_loss: -0.0994 - val_sharpe_ratio: 0.1516\n",
      "Epoch 136/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1022 - sharpe_ratio: 0.1550 - val_loss: -0.1061 - val_sharpe_ratio: 0.1553\n",
      "Epoch 137/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1065 - sharpe_ratio: 0.1514 - val_loss: -0.0496 - val_sharpe_ratio: 0.1267\n",
      "Epoch 138/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1071 - sharpe_ratio: 0.1551 - val_loss: -0.0532 - val_sharpe_ratio: 0.1299\n",
      "Epoch 139/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1063 - sharpe_ratio: 0.1548 - val_loss: -0.1173 - val_sharpe_ratio: 0.1824\n",
      "Epoch 140/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.0876 - sharpe_ratio: 0.1536 - val_loss: -0.1214 - val_sharpe_ratio: 0.1923\n",
      "Epoch 141/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1101 - sharpe_ratio: 0.1625 - val_loss: -0.0576 - val_sharpe_ratio: 0.1485\n",
      "Epoch 142/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.0995 - sharpe_ratio: 0.1582 - val_loss: -0.0352 - val_sharpe_ratio: 0.1102\n",
      "Epoch 143/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.0939 - sharpe_ratio: 0.1516 - val_loss: -0.0516 - val_sharpe_ratio: 0.0920\n",
      "Epoch 144/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.0958 - sharpe_ratio: 0.1526 - val_loss: -0.0367 - val_sharpe_ratio: 0.1386\n",
      "Epoch 145/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1001 - sharpe_ratio: 0.1587 - val_loss: -0.1105 - val_sharpe_ratio: 0.1528\n",
      "Epoch 146/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.0951 - sharpe_ratio: 0.1558 - val_loss: -0.1242 - val_sharpe_ratio: 0.1915\n",
      "Epoch 147/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.0942 - sharpe_ratio: 0.1561 - val_loss: -0.0327 - val_sharpe_ratio: 0.1361\n",
      "Epoch 148/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.0981 - sharpe_ratio: 0.1595 - val_loss: -0.0185 - val_sharpe_ratio: 0.0852\n",
      "Epoch 149/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.0977 - sharpe_ratio: 0.1565 - val_loss: -0.0481 - val_sharpe_ratio: 0.1035\n",
      "Epoch 150/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.0945 - sharpe_ratio: 0.1510 - val_loss: -0.0490 - val_sharpe_ratio: 0.0753\n",
      "Epoch 151/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1001 - sharpe_ratio: 0.1551 - val_loss: -0.0737 - val_sharpe_ratio: 0.1226\n",
      "Epoch 152/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1094 - sharpe_ratio: 0.1557 - val_loss: -0.0919 - val_sharpe_ratio: 0.1336\n",
      "Epoch 153/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.0989 - sharpe_ratio: 0.1526 - val_loss: -0.0469 - val_sharpe_ratio: 0.1515\n",
      "Epoch 154/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1017 - sharpe_ratio: 0.1591 - val_loss: -0.1172 - val_sharpe_ratio: 0.1531\n",
      "Epoch 155/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1006 - sharpe_ratio: 0.1549 - val_loss: 0.0219 - val_sharpe_ratio: 0.0090\n",
      "Epoch 156/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.0900 - sharpe_ratio: 0.1488 - val_loss: -0.1441 - val_sharpe_ratio: 0.2179\n",
      "Epoch 157/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.0918 - sharpe_ratio: 0.1502 - val_loss: -0.1135 - val_sharpe_ratio: 0.1865\n",
      "Epoch 158/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.0934 - sharpe_ratio: 0.1575 - val_loss: -0.0763 - val_sharpe_ratio: 0.1188\n",
      "Epoch 159/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.0898 - sharpe_ratio: 0.1553 - val_loss: -0.0980 - val_sharpe_ratio: 0.2147\n",
      "Epoch 160/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.0871 - sharpe_ratio: 0.1540 - val_loss: -0.0476 - val_sharpe_ratio: 0.1162\n",
      "Epoch 161/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1059 - sharpe_ratio: 0.1578 - val_loss: -0.0275 - val_sharpe_ratio: 0.0691\n",
      "Epoch 162/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1007 - sharpe_ratio: 0.1623 - val_loss: -0.0337 - val_sharpe_ratio: 0.1082\n",
      "Epoch 163/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1079 - sharpe_ratio: 0.1563 - val_loss: -0.0567 - val_sharpe_ratio: 0.1068\n",
      "Epoch 164/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1030 - sharpe_ratio: 0.1529 - val_loss: -0.0087 - val_sharpe_ratio: 0.0582\n",
      "Epoch 165/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1091 - sharpe_ratio: 0.1553 - val_loss: -0.0312 - val_sharpe_ratio: 0.0602\n",
      "Epoch 166/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1138 - sharpe_ratio: 0.1531 - val_loss: -0.0795 - val_sharpe_ratio: 0.1496\n",
      "Epoch 167/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1072 - sharpe_ratio: 0.1537 - val_loss: -0.0776 - val_sharpe_ratio: 0.1281\n",
      "Epoch 168/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1041 - sharpe_ratio: 0.1548 - val_loss: -0.1021 - val_sharpe_ratio: 0.1559\n",
      "Epoch 169/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1025 - sharpe_ratio: 0.1525 - val_loss: -0.1023 - val_sharpe_ratio: 0.1561\n",
      "Epoch 170/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.0968 - sharpe_ratio: 0.1468 - val_loss: -0.0167 - val_sharpe_ratio: 0.0511\n",
      "Epoch 171/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1094 - sharpe_ratio: 0.1548 - val_loss: -0.0539 - val_sharpe_ratio: 0.0869\n",
      "Epoch 172/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.0808 - sharpe_ratio: 0.1449 - val_loss: -0.0684 - val_sharpe_ratio: 0.1341\n",
      "Epoch 173/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1008 - sharpe_ratio: 0.1531 - val_loss: -0.0849 - val_sharpe_ratio: 0.1729\n",
      "Epoch 174/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1036 - sharpe_ratio: 0.1538 - val_loss: -0.0340 - val_sharpe_ratio: 0.1105\n",
      "Epoch 175/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1080 - sharpe_ratio: 0.1476 - val_loss: -0.0227 - val_sharpe_ratio: 0.0317\n",
      "Epoch 176/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1116 - sharpe_ratio: 0.1443 - val_loss: -0.0554 - val_sharpe_ratio: 0.1141\n",
      "Epoch 177/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.0987 - sharpe_ratio: 0.1407 - val_loss: -0.0607 - val_sharpe_ratio: 0.0883\n",
      "Epoch 178/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1058 - sharpe_ratio: 0.1460 - val_loss: -0.1071 - val_sharpe_ratio: 0.1611\n",
      "Epoch 179/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1147 - sharpe_ratio: 0.1513 - val_loss: -0.0998 - val_sharpe_ratio: 0.1724\n",
      "Epoch 180/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1152 - sharpe_ratio: 0.1529 - val_loss: -0.0898 - val_sharpe_ratio: 0.1355\n",
      "Epoch 181/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1123 - sharpe_ratio: 0.1494 - val_loss: -0.1230 - val_sharpe_ratio: 0.1553\n",
      "Epoch 182/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1010 - sharpe_ratio: 0.1369 - val_loss: -0.0549 - val_sharpe_ratio: 0.1078\n",
      "Epoch 183/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1069 - sharpe_ratio: 0.1427 - val_loss: -0.0472 - val_sharpe_ratio: 0.1206\n",
      "Epoch 184/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1048 - sharpe_ratio: 0.1469 - val_loss: -0.0297 - val_sharpe_ratio: 0.0948\n",
      "Epoch 185/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1200 - sharpe_ratio: 0.1410 - val_loss: 0.0278 - val_sharpe_ratio: 0.0090\n",
      "Epoch 186/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1115 - sharpe_ratio: 0.1434 - val_loss: -0.0534 - val_sharpe_ratio: 0.1264\n",
      "Epoch 187/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1132 - sharpe_ratio: 0.1226 - val_loss: -0.0980 - val_sharpe_ratio: 0.1368\n",
      "Epoch 188/300\n",
      "109/109 [==============================] - 3s 26ms/step - loss: -0.1117 - sharpe_ratio: 0.1206 - val_loss: -0.0650 - val_sharpe_ratio: 0.1584\n",
      "Epoch 189/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1064 - sharpe_ratio: 0.1270 - val_loss: -0.0591 - val_sharpe_ratio: 0.1529\n",
      "Epoch 190/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.0924 - sharpe_ratio: 0.1345 - val_loss: -0.1059 - val_sharpe_ratio: 0.1812\n",
      "Epoch 191/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1137 - sharpe_ratio: 0.1371 - val_loss: -0.0250 - val_sharpe_ratio: 0.0670\n",
      "Epoch 192/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 3s 27ms/step - loss: -0.0895 - sharpe_ratio: 0.1438 - val_loss: -0.0078 - val_sharpe_ratio: 0.0875\n",
      "Epoch 193/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.0975 - sharpe_ratio: 0.1387 - val_loss: -0.0159 - val_sharpe_ratio: 0.0418\n",
      "Epoch 194/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1034 - sharpe_ratio: 0.1480 - val_loss: -0.0205 - val_sharpe_ratio: 0.0650\n",
      "Epoch 195/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1037 - sharpe_ratio: 0.1285 - val_loss: -0.0624 - val_sharpe_ratio: 0.0785\n",
      "Epoch 196/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1053 - sharpe_ratio: 0.1202 - val_loss: -0.0421 - val_sharpe_ratio: 0.0554\n",
      "Epoch 197/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.0931 - sharpe_ratio: 0.1115 - val_loss: -0.0904 - val_sharpe_ratio: 0.1136\n",
      "Epoch 198/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1014 - sharpe_ratio: 0.1173 - val_loss: -0.0224 - val_sharpe_ratio: 0.0322\n",
      "Epoch 199/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1112 - sharpe_ratio: 0.1048 - val_loss: -0.0536 - val_sharpe_ratio: 0.1128\n",
      "Epoch 200/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1074 - sharpe_ratio: 0.0979 - val_loss: -0.0267 - val_sharpe_ratio: -0.0096\n",
      "Epoch 201/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1147 - sharpe_ratio: 0.1156 - val_loss: -0.0476 - val_sharpe_ratio: 0.0345\n",
      "Epoch 202/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1221 - sharpe_ratio: 0.1039 - val_loss: -0.0506 - val_sharpe_ratio: 0.0293\n",
      "Epoch 203/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1051 - sharpe_ratio: 0.0905 - val_loss: -0.0716 - val_sharpe_ratio: 0.1387\n",
      "Epoch 204/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1132 - sharpe_ratio: 0.0682 - val_loss: -0.1142 - val_sharpe_ratio: 0.1670\n",
      "Epoch 205/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1147 - sharpe_ratio: 0.0672 - val_loss: 0.0076 - val_sharpe_ratio: 0.0112\n",
      "Epoch 206/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.0970 - sharpe_ratio: 0.0729 - val_loss: -0.0092 - val_sharpe_ratio: 0.0326\n",
      "Epoch 207/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1034 - sharpe_ratio: 0.0554 - val_loss: -0.0759 - val_sharpe_ratio: -0.0296\n",
      "Epoch 208/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1136 - sharpe_ratio: 0.0584 - val_loss: -0.0429 - val_sharpe_ratio: 0.0644\n",
      "Epoch 209/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1106 - sharpe_ratio: 0.0328 - val_loss: -0.0552 - val_sharpe_ratio: 0.0150\n",
      "Epoch 210/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1087 - sharpe_ratio: 0.0332 - val_loss: -0.0925 - val_sharpe_ratio: 0.0503\n",
      "Epoch 211/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1086 - sharpe_ratio: 0.0363 - val_loss: -0.0791 - val_sharpe_ratio: 0.0997\n",
      "Epoch 212/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1128 - sharpe_ratio: 0.0221 - val_loss: -0.0573 - val_sharpe_ratio: 0.0416\n",
      "Epoch 213/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1195 - sharpe_ratio: 0.0150 - val_loss: -0.1377 - val_sharpe_ratio: 0.1659\n",
      "Epoch 214/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1093 - sharpe_ratio: 0.0094 - val_loss: -0.1319 - val_sharpe_ratio: 0.1659\n",
      "Epoch 215/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1143 - sharpe_ratio: 0.0084 - val_loss: -0.0101 - val_sharpe_ratio: 0.0493\n",
      "Epoch 216/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1124 - sharpe_ratio: 0.0121 - val_loss: -0.0570 - val_sharpe_ratio: 0.1347\n",
      "Epoch 217/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1262 - sharpe_ratio: 0.0084 - val_loss: -0.0405 - val_sharpe_ratio: -0.0127\n",
      "Epoch 218/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1253 - sharpe_ratio: 0.0024 - val_loss: -0.0926 - val_sharpe_ratio: 0.0885\n",
      "Epoch 219/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1211 - sharpe_ratio: 0.0038 - val_loss: 0.0147 - val_sharpe_ratio: 0.0336\n",
      "Epoch 220/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1158 - sharpe_ratio: -2.3236e-04 - val_loss: -0.0577 - val_sharpe_ratio: -0.0345\n",
      "Epoch 221/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1260 - sharpe_ratio: 8.8322e-04 - val_loss: -0.0085 - val_sharpe_ratio: -0.0254\n",
      "Epoch 222/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1169 - sharpe_ratio: 9.9396e-04 - val_loss: -0.0334 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 223/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1157 - sharpe_ratio: 0.0011 - val_loss: -0.0088 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 224/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1149 - sharpe_ratio: 5.6829e-04 - val_loss: -0.0887 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 225/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1203 - sharpe_ratio: -2.7290e-04 - val_loss: 0.0282 - val_sharpe_ratio: 0.0158\n",
      "Epoch 226/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1147 - sharpe_ratio: 6.7173e-04 - val_loss: 0.0015 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 227/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1125 - sharpe_ratio: 1.3645e-04 - val_loss: -0.1381 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 228/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1245 - sharpe_ratio: 6.6200e-04 - val_loss: -0.0723 - val_sharpe_ratio: 0.1019\n",
      "Epoch 229/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1238 - sharpe_ratio: 3.0707e-04 - val_loss: 0.0260 - val_sharpe_ratio: -0.0254\n",
      "Epoch 230/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1195 - sharpe_ratio: 0.0017 - val_loss: -0.0339 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 231/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1197 - sharpe_ratio: 4.1668e-04 - val_loss: -0.0445 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 232/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1192 - sharpe_ratio: 1.2214e-04 - val_loss: -0.0749 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 233/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1180 - sharpe_ratio: 2.0166e-04 - val_loss: -0.0273 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 234/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1189 - sharpe_ratio: 0.0013 - val_loss: -0.0949 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 235/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1133 - sharpe_ratio: -2.2081e-04 - val_loss: -0.1531 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 236/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1231 - sharpe_ratio: 2.3709e-04 - val_loss: -0.0429 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 237/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1163 - sharpe_ratio: 4.0076e-04 - val_loss: -0.0070 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 238/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1194 - sharpe_ratio: -4.8638e-04 - val_loss: -0.1240 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 239/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1152 - sharpe_ratio: 0.0010 - val_loss: -0.0063 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 240/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1193 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0426 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 241/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1226 - sharpe_ratio: 3.5395e-04 - val_loss: 0.0056 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 242/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1168 - sharpe_ratio: -2.9782e-04 - val_loss: 0.0394 - val_sharpe_ratio: 0.0204\n",
      "Epoch 243/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1159 - sharpe_ratio: 1.0203e-06 - val_loss: -0.1441 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 244/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1208 - sharpe_ratio: 7.1695e-05 - val_loss: -0.0834 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 245/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1165 - sharpe_ratio: 2.2882e-04 - val_loss: -0.0086 - val_sharpe_ratio: 0.0078\n",
      "Epoch 246/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1120 - sharpe_ratio: 5.5062e-05 - val_loss: -0.0335 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 247/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1190 - sharpe_ratio: 1.3893e-04 - val_loss: -0.0567 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 248/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1180 - sharpe_ratio: 5.2686e-04 - val_loss: -0.1140 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 249/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1224 - sharpe_ratio: 5.4803e-04 - val_loss: -0.0644 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 250/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1131 - sharpe_ratio: 1.9173e-04 - val_loss: -0.0326 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 251/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1150 - sharpe_ratio: 4.1741e-04 - val_loss: -0.0824 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 252/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1162 - sharpe_ratio: 4.1717e-04 - val_loss: -0.0655 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 253/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1193 - sharpe_ratio: 2.3345e-04 - val_loss: -0.0076 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 254/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1171 - sharpe_ratio: 0.0011 - val_loss: -0.0302 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 255/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1173 - sharpe_ratio: 7.0501e-05 - val_loss: -0.1426 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 256/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1189 - sharpe_ratio: -2.1699e-04 - val_loss: -0.0651 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 257/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1196 - sharpe_ratio: 2.5178e-04 - val_loss: -0.1039 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 258/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1221 - sharpe_ratio: 5.3318e-05 - val_loss: 8.5127e-04 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 259/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1105 - sharpe_ratio: 0.0016 - val_loss: -0.0724 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 260/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1263 - sharpe_ratio: 1.8574e-04 - val_loss: -0.0520 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 261/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1236 - sharpe_ratio: 0.0011 - val_loss: 0.0072 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 262/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1134 - sharpe_ratio: 4.4566e-04 - val_loss: -0.1246 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 263/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1241 - sharpe_ratio: 4.0910e-04 - val_loss: -0.1088 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 264/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1155 - sharpe_ratio: -1.0278e-04 - val_loss: -0.0437 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 265/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1130 - sharpe_ratio: -4.7361e-05 - val_loss: -0.0511 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 266/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.0765 - sharpe_ratio: -8.5069e-05 - val_loss: -0.0961 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 267/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1130 - sharpe_ratio: -1.2479e-04 - val_loss: -0.0684 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 268/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1091 - sharpe_ratio: 4.8758e-04 - val_loss: -0.0656 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 269/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1187 - sharpe_ratio: 2.7774e-05 - val_loss: -0.0199 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 270/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1137 - sharpe_ratio: 9.7326e-04 - val_loss: -0.0924 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 271/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1172 - sharpe_ratio: 1.6638e-04 - val_loss: -0.0056 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 272/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1167 - sharpe_ratio: 3.2183e-04 - val_loss: -0.1594 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 273/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1201 - sharpe_ratio: 2.5077e-04 - val_loss: 0.0179 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 274/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1209 - sharpe_ratio: 6.9757e-04 - val_loss: -0.0893 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 275/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1239 - sharpe_ratio: 2.4234e-04 - val_loss: 0.0160 - val_sharpe_ratio: -0.0242\n",
      "Epoch 276/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1246 - sharpe_ratio: 2.9983e-04 - val_loss: -0.0181 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 277/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1065 - sharpe_ratio: 7.4902e-04 - val_loss: -0.0869 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 278/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1215 - sharpe_ratio: 3.8565e-04 - val_loss: -0.1250 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 279/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1166 - sharpe_ratio: -7.4130e-05 - val_loss: -0.0955 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 280/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1180 - sharpe_ratio: 0.0000e+00 - val_loss: -0.1178 - val_sharpe_ratio: 0.1659\n",
      "Epoch 281/300\n",
      "109/109 [==============================] - 3s 29ms/step - loss: -0.1248 - sharpe_ratio: 0.0000e+00 - val_loss: -0.1376 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 282/300\n",
      "109/109 [==============================] - 3s 28ms/step - loss: -0.1116 - sharpe_ratio: 1.1814e-05 - val_loss: -0.0494 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 283/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1078 - sharpe_ratio: 4.4844e-04 - val_loss: -0.1018 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 284/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1189 - sharpe_ratio: 3.8058e-04 - val_loss: -0.0064 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 285/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1238 - sharpe_ratio: 1.6214e-04 - val_loss: 9.8031e-04 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 286/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1243 - sharpe_ratio: -1.0642e-04 - val_loss: -0.0117 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 287/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1088 - sharpe_ratio: 4.6016e-04 - val_loss: -0.0285 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 288/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1015 - sharpe_ratio: -1.4821e-04 - val_loss: -0.0377 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 289/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1179 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0265 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 290/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1202 - sharpe_ratio: 1.4456e-04 - val_loss: -0.1274 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 291/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1264 - sharpe_ratio: 0.0000e+00 - val_loss: -0.1123 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 292/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1172 - sharpe_ratio: 7.7274e-04 - val_loss: -0.0742 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 293/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1237 - sharpe_ratio: 1.4996e-04 - val_loss: -0.0990 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 294/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1215 - sharpe_ratio: -1.7780e-04 - val_loss: -0.0901 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 295/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1193 - sharpe_ratio: -7.2807e-06 - val_loss: -0.0040 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 296/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1219 - sharpe_ratio: 8.4543e-05 - val_loss: 0.0563 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 297/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1138 - sharpe_ratio: 3.2687e-04 - val_loss: 0.0026 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 298/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1242 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0690 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 299/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1186 - sharpe_ratio: 4.0502e-05 - val_loss: -0.0374 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 300/300\n",
      "109/109 [==============================] - 3s 27ms/step - loss: -0.1232 - sharpe_ratio: 1.9200e-04 - val_loss: -0.0064 - val_sharpe_ratio: 0.0000e+00\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "There are total 11 samples to predict\n",
      "Sample 0 : [  ]\n",
      "Sample 1 : [  ]\n",
      "Sample 2 : [  ]\n",
      "Sample 3 : [  ]\n",
      "Sample 4 : [  ]\n",
      "Sample 5 : [  ]\n",
      "Sample 6 : [  ]\n",
      "Sample 7 : [  ]\n",
      "Sample 8 : [  ]\n",
      "Sample 9 : [  ]\n",
      "Sample 10 : [  ]\n",
      "Sharpe ratio of this portfolio: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "write file log at C:/Users/yv67/Documents/12FundsHK_ToShare/deeplearningdata/logs/GRU\\log_1949.txt\n",
      "Epoch 1/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1123 - sharpe_ratio: 3.4492e-04 - val_loss: 0.0336 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 2/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1194 - sharpe_ratio: 0.0012 - val_loss: 0.0056 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 3/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1192 - sharpe_ratio: 0.0034 - val_loss: 0.0203 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 4/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1284 - sharpe_ratio: 5.2529e-04 - val_loss: 0.0677 - val_sharpe_ratio: -0.0099\n",
      "Epoch 5/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1282 - sharpe_ratio: 0.0011 - val_loss: -0.0053 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 6/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1260 - sharpe_ratio: 0.0022 - val_loss: 0.0470 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 7/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1256 - sharpe_ratio: 8.5636e-04 - val_loss: 0.0235 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 8/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1290 - sharpe_ratio: 0.0019 - val_loss: 0.0344 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 9/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1232 - sharpe_ratio: 6.9631e-04 - val_loss: 0.0326 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 10/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1256 - sharpe_ratio: -5.0663e-05 - val_loss: 0.0451 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 11/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1271 - sharpe_ratio: 0.0027 - val_loss: 0.0473 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 12/300\n",
      "122/122 [==============================] - 3s 29ms/step - loss: -0.1171 - sharpe_ratio: 0.0017 - val_loss: 0.0587 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 13/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1094 - sharpe_ratio: 0.0017 - val_loss: 0.0488 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 14/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1149 - sharpe_ratio: 0.0014 - val_loss: 0.0658 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 15/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1286 - sharpe_ratio: 0.0011 - val_loss: 0.0243 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 16/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1251 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0681 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 17/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1333 - sharpe_ratio: 0.0020 - val_loss: 0.0364 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 18/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1182 - sharpe_ratio: 0.0026 - val_loss: 0.0728 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 19/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1293 - sharpe_ratio: 0.0023 - val_loss: 0.0428 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 20/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1235 - sharpe_ratio: 0.0021 - val_loss: 0.0382 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 21/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1275 - sharpe_ratio: 0.0012 - val_loss: 0.0558 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 22/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1093 - sharpe_ratio: 4.0908e-04 - val_loss: 0.0427 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 23/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1163 - sharpe_ratio: 0.0013 - val_loss: 0.0614 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 24/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1201 - sharpe_ratio: 0.0011 - val_loss: 0.0474 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 25/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1214 - sharpe_ratio: 0.0014 - val_loss: -0.0169 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 26/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1203 - sharpe_ratio: 0.0022 - val_loss: 0.0344 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 27/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1263 - sharpe_ratio: 0.0012 - val_loss: 0.0231 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 28/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1252 - sharpe_ratio: 0.0024 - val_loss: 0.0127 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 29/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1307 - sharpe_ratio: 7.9051e-04 - val_loss: 0.0283 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 30/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1255 - sharpe_ratio: 0.0026 - val_loss: 0.0275 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 31/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1308 - sharpe_ratio: 9.0919e-04 - val_loss: -1.7732e-04 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 32/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1107 - sharpe_ratio: 0.0021 - val_loss: 0.0613 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 33/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1135 - sharpe_ratio: 0.0027 - val_loss: 0.0481 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 34/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1255 - sharpe_ratio: 5.9362e-04 - val_loss: 0.0308 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 35/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1246 - sharpe_ratio: 0.0019 - val_loss: 0.0190 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 36/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1315 - sharpe_ratio: 4.1644e-04 - val_loss: 0.0697 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 37/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1117 - sharpe_ratio: 0.0030 - val_loss: 0.0505 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 38/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1285 - sharpe_ratio: 0.0011 - val_loss: 0.0492 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 39/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1293 - sharpe_ratio: 0.0023 - val_loss: 0.0495 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 40/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1183 - sharpe_ratio: 0.0022 - val_loss: 0.0744 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 41/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1045 - sharpe_ratio: 0.0016 - val_loss: -0.0155 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 42/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1301 - sharpe_ratio: 0.0019 - val_loss: 0.0105 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 43/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1298 - sharpe_ratio: 0.0021 - val_loss: -0.0014 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 44/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1185 - sharpe_ratio: 4.1767e-04 - val_loss: 0.0650 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 45/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1143 - sharpe_ratio: 0.0012 - val_loss: 0.0303 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 46/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1337 - sharpe_ratio: 0.0027 - val_loss: 0.0519 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 47/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1158 - sharpe_ratio: 0.0023 - val_loss: 0.0183 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 48/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1280 - sharpe_ratio: 8.6101e-04 - val_loss: -0.0040 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 49/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1177 - sharpe_ratio: 0.0023 - val_loss: 0.0591 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 50/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1280 - sharpe_ratio: 0.0014 - val_loss: 0.0197 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 51/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1144 - sharpe_ratio: 4.2017e-04 - val_loss: 0.0367 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 52/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1352 - sharpe_ratio: 0.0013 - val_loss: 0.0403 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 53/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1288 - sharpe_ratio: 0.0017 - val_loss: 0.0205 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 54/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1235 - sharpe_ratio: 6.7119e-04 - val_loss: 0.0576 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 55/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1152 - sharpe_ratio: 0.0015 - val_loss: 0.0457 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 56/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1245 - sharpe_ratio: 1.4484e-04 - val_loss: 0.0663 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 57/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1140 - sharpe_ratio: 0.0018 - val_loss: -0.0039 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 58/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.0533 - sharpe_ratio: 0.0107 - val_loss: 0.0924 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 59/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1150 - sharpe_ratio: 0.0011 - val_loss: 0.0797 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 60/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1054 - sharpe_ratio: 2.9117e-05 - val_loss: 0.0314 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 61/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1132 - sharpe_ratio: 7.8158e-04 - val_loss: 0.0314 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 62/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1148 - sharpe_ratio: 0.0011 - val_loss: 0.0468 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 63/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1217 - sharpe_ratio: 0.0016 - val_loss: 0.0116 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 64/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1212 - sharpe_ratio: 0.0015 - val_loss: 0.0377 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 65/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1231 - sharpe_ratio: 8.6539e-04 - val_loss: 0.0371 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 66/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1001 - sharpe_ratio: 2.7236e-04 - val_loss: 0.0397 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 67/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1085 - sharpe_ratio: 5.4981e-04 - val_loss: 0.0610 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 68/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1241 - sharpe_ratio: 0.0011 - val_loss: 0.0108 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 69/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1150 - sharpe_ratio: 1.8232e-04 - val_loss: 0.0352 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 70/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1235 - sharpe_ratio: 6.6269e-04 - val_loss: 0.0403 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 71/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1108 - sharpe_ratio: 0.0024 - val_loss: 0.0312 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 72/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1222 - sharpe_ratio: 3.0664e-04 - val_loss: 0.0801 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 73/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1147 - sharpe_ratio: 9.8275e-05 - val_loss: 0.0787 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 74/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1186 - sharpe_ratio: 0.0025 - val_loss: 0.0767 - val_sharpe_ratio: -0.0011\n",
      "Epoch 75/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1255 - sharpe_ratio: 0.0036 - val_loss: 0.0555 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 76/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1115 - sharpe_ratio: 0.0035 - val_loss: 0.0948 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 77/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1185 - sharpe_ratio: 6.0257e-04 - val_loss: 0.0841 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 78/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1260 - sharpe_ratio: 0.0010 - val_loss: 0.0394 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 79/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1178 - sharpe_ratio: 5.9005e-04 - val_loss: -0.0029 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 80/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1222 - sharpe_ratio: 6.7611e-04 - val_loss: 0.0052 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 81/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1184 - sharpe_ratio: 0.0015 - val_loss: 0.0528 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 82/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1180 - sharpe_ratio: 0.0010 - val_loss: 0.0392 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 83/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1141 - sharpe_ratio: 6.1218e-04 - val_loss: 0.0287 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 84/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1138 - sharpe_ratio: 0.0019 - val_loss: 0.0262 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 85/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1157 - sharpe_ratio: 0.0017 - val_loss: 0.0768 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 86/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1123 - sharpe_ratio: 0.0013 - val_loss: 0.0195 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 87/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1213 - sharpe_ratio: 8.3944e-04 - val_loss: 0.0717 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 88/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1194 - sharpe_ratio: 2.0031e-04 - val_loss: 0.0309 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 89/300\n",
      "122/122 [==============================] - 4s 32ms/step - loss: -0.1053 - sharpe_ratio: 0.0011 - val_loss: 0.0433 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 90/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1044 - sharpe_ratio: 9.0176e-04 - val_loss: 0.0561 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 91/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1099 - sharpe_ratio: 0.0015 - val_loss: 0.0595 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 92/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1111 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0407 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 93/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1171 - sharpe_ratio: 0.0025 - val_loss: 0.0759 - val_sharpe_ratio: 0.0042\n",
      "Epoch 94/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1191 - sharpe_ratio: 0.0017 - val_loss: 0.0550 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 95/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1175 - sharpe_ratio: 1.5783e-04 - val_loss: 0.0381 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 96/300\n",
      "122/122 [==============================] - 3s 29ms/step - loss: -0.1223 - sharpe_ratio: 0.0020 - val_loss: 0.0563 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 97/300\n",
      "122/122 [==============================] - 3s 29ms/step - loss: -0.1239 - sharpe_ratio: 9.6608e-04 - val_loss: 0.0103 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 98/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1243 - sharpe_ratio: 0.0017 - val_loss: 0.0582 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 99/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1164 - sharpe_ratio: 0.0011 - val_loss: -6.8373e-04 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 100/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1237 - sharpe_ratio: 6.6928e-04 - val_loss: 0.0594 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 101/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1217 - sharpe_ratio: 0.0017 - val_loss: 0.0165 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 102/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1272 - sharpe_ratio: -3.0966e-05 - val_loss: 0.0656 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 103/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1278 - sharpe_ratio: 0.0011 - val_loss: 0.0449 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 104/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1173 - sharpe_ratio: 9.0757e-04 - val_loss: 0.0278 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 105/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1221 - sharpe_ratio: 7.3770e-04 - val_loss: 0.0179 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 106/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1221 - sharpe_ratio: 8.3484e-04 - val_loss: -0.0074 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 107/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1253 - sharpe_ratio: 2.5991e-04 - val_loss: -0.0219 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 108/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1225 - sharpe_ratio: 0.0012 - val_loss: 0.0467 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 109/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1220 - sharpe_ratio: 5.0551e-04 - val_loss: 0.0324 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 110/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1220 - sharpe_ratio: 0.0013 - val_loss: 0.0073 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 111/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1247 - sharpe_ratio: 3.1947e-04 - val_loss: 0.0568 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 112/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1223 - sharpe_ratio: 1.0594e-04 - val_loss: 0.0096 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 113/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1262 - sharpe_ratio: 0.0015 - val_loss: 0.0385 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 114/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1364 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0491 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 115/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1280 - sharpe_ratio: 0.0014 - val_loss: 0.0476 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 116/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1197 - sharpe_ratio: 0.0016 - val_loss: 0.0394 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 117/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1348 - sharpe_ratio: 5.2166e-04 - val_loss: 0.0193 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 118/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1135 - sharpe_ratio: 8.1274e-04 - val_loss: 0.0022 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 119/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1191 - sharpe_ratio: 3.7899e-04 - val_loss: 0.0762 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 120/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1108 - sharpe_ratio: 1.8568e-04 - val_loss: 0.0126 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 121/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1199 - sharpe_ratio: 0.0014 - val_loss: 0.0129 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 122/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1107 - sharpe_ratio: 0.0016 - val_loss: -0.0116 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 123/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1256 - sharpe_ratio: 1.5737e-04 - val_loss: 0.0249 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 124/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1316 - sharpe_ratio: 0.0019 - val_loss: 0.0695 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 125/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1243 - sharpe_ratio: 0.0012 - val_loss: 0.0187 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 126/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1233 - sharpe_ratio: 0.0014 - val_loss: 0.0415 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 127/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1121 - sharpe_ratio: 0.0014 - val_loss: 0.0064 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 128/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1151 - sharpe_ratio: 4.8341e-05 - val_loss: 0.0478 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 129/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1186 - sharpe_ratio: 0.0012 - val_loss: 0.0331 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 130/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1275 - sharpe_ratio: 0.0013 - val_loss: 0.0701 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 131/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1238 - sharpe_ratio: 9.9272e-04 - val_loss: 0.0128 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 132/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1346 - sharpe_ratio: 0.0022 - val_loss: -0.0163 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 133/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1246 - sharpe_ratio: 0.0012 - val_loss: 0.0307 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 134/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1216 - sharpe_ratio: 0.0019 - val_loss: 0.0759 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 135/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1204 - sharpe_ratio: 0.0025 - val_loss: 0.0136 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 136/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1239 - sharpe_ratio: 6.5266e-04 - val_loss: -0.0206 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 137/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1287 - sharpe_ratio: 7.4810e-04 - val_loss: 0.0129 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 138/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1332 - sharpe_ratio: 0.0020 - val_loss: 0.0562 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 139/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1234 - sharpe_ratio: 0.0012 - val_loss: 0.0355 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 140/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1276 - sharpe_ratio: 0.0024 - val_loss: 0.0446 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 141/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1237 - sharpe_ratio: 3.3159e-04 - val_loss: 0.0016 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 142/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1227 - sharpe_ratio: 3.9142e-04 - val_loss: 0.0079 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 143/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1294 - sharpe_ratio: 7.6458e-04 - val_loss: 0.0449 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 144/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1197 - sharpe_ratio: 0.0026 - val_loss: 0.1347 - val_sharpe_ratio: -0.0032\n",
      "Epoch 145/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1104 - sharpe_ratio: 0.0012 - val_loss: 0.0518 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 146/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1300 - sharpe_ratio: 7.1134e-04 - val_loss: 0.0537 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 147/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1212 - sharpe_ratio: 2.6861e-04 - val_loss: 0.0534 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 148/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1280 - sharpe_ratio: 7.0128e-04 - val_loss: 0.0388 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 149/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1318 - sharpe_ratio: 1.5204e-04 - val_loss: 0.0366 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 150/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1212 - sharpe_ratio: 0.0020 - val_loss: 0.0339 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 151/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1321 - sharpe_ratio: 0.0017 - val_loss: -0.0065 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 152/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1206 - sharpe_ratio: 3.1702e-04 - val_loss: 0.0618 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 153/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1037 - sharpe_ratio: 0.0013 - val_loss: 0.0458 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 154/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1084 - sharpe_ratio: -1.3798e-04 - val_loss: 0.0262 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 155/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1252 - sharpe_ratio: 2.8598e-04 - val_loss: 0.0886 - val_sharpe_ratio: -0.0462\n",
      "Epoch 156/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1233 - sharpe_ratio: 4.0300e-05 - val_loss: 0.0088 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 157/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1182 - sharpe_ratio: 0.0012 - val_loss: 0.0338 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 158/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1198 - sharpe_ratio: 9.6059e-06 - val_loss: 0.0628 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 159/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1221 - sharpe_ratio: 4.8732e-04 - val_loss: 0.0733 - val_sharpe_ratio: -0.0080\n",
      "Epoch 160/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1135 - sharpe_ratio: 3.7024e-04 - val_loss: 0.0582 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 161/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1289 - sharpe_ratio: 5.3898e-04 - val_loss: 0.0830 - val_sharpe_ratio: -0.0378\n",
      "Epoch 162/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1238 - sharpe_ratio: 0.0014 - val_loss: 0.0236 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 163/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1285 - sharpe_ratio: 8.2835e-04 - val_loss: 0.0469 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 164/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1331 - sharpe_ratio: 0.0011 - val_loss: 0.0354 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 165/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1164 - sharpe_ratio: 4.0589e-04 - val_loss: 0.0398 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 166/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1224 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0032 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 167/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1184 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0073 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 168/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1156 - sharpe_ratio: 0.0012 - val_loss: 0.0467 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 169/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1320 - sharpe_ratio: 3.1074e-04 - val_loss: 0.0386 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 170/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1240 - sharpe_ratio: 0.0033 - val_loss: 0.0443 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 171/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1239 - sharpe_ratio: 2.4586e-05 - val_loss: 0.0569 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 172/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1213 - sharpe_ratio: 0.0022 - val_loss: 0.0012 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 173/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1315 - sharpe_ratio: 8.2256e-04 - val_loss: 0.0374 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 174/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1343 - sharpe_ratio: 0.0010 - val_loss: 0.0551 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 175/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1342 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0063 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 176/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1122 - sharpe_ratio: 7.5547e-04 - val_loss: 0.0444 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 177/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1131 - sharpe_ratio: 0.0015 - val_loss: 0.0510 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 178/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1139 - sharpe_ratio: 2.3911e-04 - val_loss: 0.0479 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 179/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1218 - sharpe_ratio: 0.0016 - val_loss: 0.0694 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 180/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1118 - sharpe_ratio: 8.4654e-04 - val_loss: 0.0018 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 181/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1196 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0252 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 182/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1129 - sharpe_ratio: 9.2098e-04 - val_loss: 0.0345 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 183/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1255 - sharpe_ratio: 0.0013 - val_loss: 0.0176 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 184/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1256 - sharpe_ratio: 0.0016 - val_loss: -0.0120 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 185/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1118 - sharpe_ratio: 0.0016 - val_loss: -0.0055 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 186/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1331 - sharpe_ratio: 9.8238e-05 - val_loss: 0.0040 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 187/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1207 - sharpe_ratio: 0.0016 - val_loss: 0.0567 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 188/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1206 - sharpe_ratio: 5.4246e-04 - val_loss: 0.0405 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 189/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1248 - sharpe_ratio: 9.3378e-04 - val_loss: -4.2134e-04 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 190/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1284 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0281 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 191/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1200 - sharpe_ratio: 2.0356e-04 - val_loss: 0.0825 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 192/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1154 - sharpe_ratio: 0.0015 - val_loss: -0.0056 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 193/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1182 - sharpe_ratio: -6.4245e-05 - val_loss: 0.0129 - val_sharpe_ratio: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1290 - sharpe_ratio: 0.0011 - val_loss: 0.0165 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 195/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1212 - sharpe_ratio: 5.3856e-06 - val_loss: 0.0078 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 196/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1129 - sharpe_ratio: 0.0012 - val_loss: 0.0452 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 197/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1146 - sharpe_ratio: 0.0011 - val_loss: 0.0303 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 198/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1306 - sharpe_ratio: 8.2209e-04 - val_loss: 0.0239 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 199/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1309 - sharpe_ratio: 0.0011 - val_loss: 0.0264 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 200/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1231 - sharpe_ratio: 1.4552e-04 - val_loss: 0.0588 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 201/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1234 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0438 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 202/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1337 - sharpe_ratio: 0.0015 - val_loss: 0.0430 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 203/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1274 - sharpe_ratio: 0.0011 - val_loss: 0.0143 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 204/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1224 - sharpe_ratio: 0.0015 - val_loss: 0.0474 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 205/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1282 - sharpe_ratio: 4.9574e-04 - val_loss: 0.0092 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 206/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1284 - sharpe_ratio: 2.3142e-04 - val_loss: -0.0071 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 207/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1216 - sharpe_ratio: 2.9117e-05 - val_loss: 0.0741 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 208/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1286 - sharpe_ratio: 1.6120e-04 - val_loss: 0.0045 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 209/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1176 - sharpe_ratio: 0.0026 - val_loss: 0.0362 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 210/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1237 - sharpe_ratio: 5.7221e-04 - val_loss: 0.0235 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 211/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1300 - sharpe_ratio: 9.2696e-04 - val_loss: 0.0409 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 212/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1264 - sharpe_ratio: 6.5181e-04 - val_loss: 0.0494 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 213/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1163 - sharpe_ratio: 1.7116e-04 - val_loss: 0.1004 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 214/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1105 - sharpe_ratio: 0.0031 - val_loss: 0.0329 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 215/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1282 - sharpe_ratio: 1.7443e-04 - val_loss: 0.0227 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 216/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1216 - sharpe_ratio: 0.0021 - val_loss: -2.3717e-04 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 217/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1255 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0558 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 218/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1229 - sharpe_ratio: 7.4995e-04 - val_loss: 0.0528 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 219/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1278 - sharpe_ratio: 7.6461e-04 - val_loss: 0.0659 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 220/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1145 - sharpe_ratio: 7.1706e-04 - val_loss: 0.0300 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 221/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1312 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0293 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 222/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1259 - sharpe_ratio: 2.7757e-04 - val_loss: 0.0892 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 223/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1213 - sharpe_ratio: 0.0017 - val_loss: 0.0448 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 224/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1222 - sharpe_ratio: 4.5183e-04 - val_loss: 0.0061 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 225/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1204 - sharpe_ratio: 3.9457e-04 - val_loss: 0.0839 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 226/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1279 - sharpe_ratio: 1.4500e-04 - val_loss: 0.0248 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 227/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1254 - sharpe_ratio: 4.6530e-04 - val_loss: 0.0656 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 228/300\n",
      "122/122 [==============================] - 4s 30ms/step - loss: -0.1149 - sharpe_ratio: 6.6822e-05 - val_loss: 0.0502 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 229/300\n",
      "122/122 [==============================] - 4s 31ms/step - loss: -0.1206 - sharpe_ratio: 6.4576e-04 - val_loss: 0.0464 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 230/300\n",
      "122/122 [==============================] - 4s 30ms/step - loss: -0.1225 - sharpe_ratio: 4.4375e-04 - val_loss: 0.0076 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 231/300\n",
      "122/122 [==============================] - 4s 31ms/step - loss: -0.1277 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0347 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 232/300\n",
      "122/122 [==============================] - 4s 32ms/step - loss: -0.1311 - sharpe_ratio: 0.0012 - val_loss: 0.0168 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 233/300\n",
      "122/122 [==============================] - 4s 30ms/step - loss: -0.1382 - sharpe_ratio: 1.9595e-04 - val_loss: 0.0382 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 234/300\n",
      "122/122 [==============================] - 4s 29ms/step - loss: -0.1182 - sharpe_ratio: 0.0019 - val_loss: 0.0280 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 235/300\n",
      "122/122 [==============================] - 4s 30ms/step - loss: -0.1297 - sharpe_ratio: 0.0012 - val_loss: 0.0224 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 236/300\n",
      "122/122 [==============================] - 4s 32ms/step - loss: -0.1191 - sharpe_ratio: 5.0086e-04 - val_loss: 0.0677 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 237/300\n",
      "122/122 [==============================] - 4s 30ms/step - loss: -0.1216 - sharpe_ratio: 0.0014 - val_loss: 0.0574 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 238/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1214 - sharpe_ratio: 0.0017 - val_loss: 0.0220 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 239/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1136 - sharpe_ratio: 0.0016 - val_loss: 0.0698 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 240/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1214 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0195 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 241/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1295 - sharpe_ratio: 1.2664e-04 - val_loss: 0.0241 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 242/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1285 - sharpe_ratio: 0.0015 - val_loss: 0.0617 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 243/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1155 - sharpe_ratio: 8.8310e-04 - val_loss: 0.0149 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 244/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1224 - sharpe_ratio: 4.7860e-04 - val_loss: 0.0300 - val_sharpe_ratio: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1155 - sharpe_ratio: 1.8090e-04 - val_loss: 0.0574 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 246/300\n",
      "122/122 [==============================] - 4s 30ms/step - loss: -0.1114 - sharpe_ratio: 0.0023 - val_loss: 0.0611 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 247/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1195 - sharpe_ratio: 5.4529e-04 - val_loss: -0.0034 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 248/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1313 - sharpe_ratio: 0.0012 - val_loss: 0.0352 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 249/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1265 - sharpe_ratio: -1.5480e-04 - val_loss: 0.0244 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 250/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1225 - sharpe_ratio: 5.1876e-04 - val_loss: 0.0612 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 251/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1289 - sharpe_ratio: 7.4398e-04 - val_loss: 0.0608 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 252/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1307 - sharpe_ratio: 0.0022 - val_loss: -5.0849e-04 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 253/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1250 - sharpe_ratio: 1.0069e-04 - val_loss: 0.0240 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 254/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1252 - sharpe_ratio: 2.1613e-04 - val_loss: 0.0321 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 255/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1304 - sharpe_ratio: 2.8177e-04 - val_loss: 0.0593 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 256/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1315 - sharpe_ratio: 5.2921e-04 - val_loss: 0.0356 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 257/300\n",
      "122/122 [==============================] - 4s 29ms/step - loss: -0.1081 - sharpe_ratio: 0.0016 - val_loss: 0.0042 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 258/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1195 - sharpe_ratio: 7.5956e-05 - val_loss: -0.0011 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 259/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1332 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0447 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 260/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1269 - sharpe_ratio: 7.8494e-04 - val_loss: 0.0576 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 261/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1240 - sharpe_ratio: 4.5335e-04 - val_loss: 0.0694 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 262/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1167 - sharpe_ratio: 0.0020 - val_loss: 0.0640 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 263/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1158 - sharpe_ratio: 0.0011 - val_loss: 0.0337 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 264/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1201 - sharpe_ratio: 0.0015 - val_loss: 0.0639 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 265/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1301 - sharpe_ratio: 0.0015 - val_loss: 0.0199 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 266/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1272 - sharpe_ratio: 0.0015 - val_loss: 0.0595 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 267/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1271 - sharpe_ratio: 0.0025 - val_loss: 0.0025 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 268/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1187 - sharpe_ratio: 0.0015 - val_loss: 0.0489 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 269/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1248 - sharpe_ratio: 5.7674e-04 - val_loss: -0.0081 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 270/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1209 - sharpe_ratio: 3.4368e-04 - val_loss: 0.0417 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 271/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1212 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0397 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 272/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1077 - sharpe_ratio: 0.0012 - val_loss: 0.0763 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 273/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1104 - sharpe_ratio: 7.4640e-04 - val_loss: 0.0661 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 274/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1258 - sharpe_ratio: 5.2250e-04 - val_loss: 0.0581 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 275/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1214 - sharpe_ratio: 7.8486e-04 - val_loss: 0.0396 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 276/300\n",
      "122/122 [==============================] - 3s 26ms/step - loss: -0.1224 - sharpe_ratio: 4.0063e-04 - val_loss: 0.0375 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 277/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1267 - sharpe_ratio: 4.2697e-04 - val_loss: 0.0289 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 278/300\n",
      "122/122 [==============================] - 4s 34ms/step - loss: -0.1180 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0034 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 279/300\n",
      "122/122 [==============================] - 4s 31ms/step - loss: -0.1174 - sharpe_ratio: 0.0017 - val_loss: 0.0484 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 280/300\n",
      "122/122 [==============================] - 4s 30ms/step - loss: -0.1226 - sharpe_ratio: 0.0011 - val_loss: 0.1003 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 281/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1235 - sharpe_ratio: 0.0019 - val_loss: 0.0632 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 282/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1194 - sharpe_ratio: 6.3522e-04 - val_loss: 0.0917 - val_sharpe_ratio: -0.0080\n",
      "Epoch 283/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1109 - sharpe_ratio: 4.7641e-04 - val_loss: 0.0504 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 284/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1225 - sharpe_ratio: 9.9947e-04 - val_loss: 0.0336 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 285/300\n",
      "122/122 [==============================] - 3s 27ms/step - loss: -0.1091 - sharpe_ratio: 1.7427e-04 - val_loss: 0.0462 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 286/300\n",
      "122/122 [==============================] - 3s 29ms/step - loss: -0.1316 - sharpe_ratio: 3.1648e-04 - val_loss: 0.0244 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 287/300\n",
      "122/122 [==============================] - 3s 29ms/step - loss: -0.1266 - sharpe_ratio: 0.0011 - val_loss: 0.0725 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 288/300\n",
      "122/122 [==============================] - 4s 29ms/step - loss: -0.1204 - sharpe_ratio: 2.1087e-04 - val_loss: 0.0454 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 289/300\n",
      "122/122 [==============================] - 4s 30ms/step - loss: -0.1199 - sharpe_ratio: 5.6352e-04 - val_loss: 0.0448 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 290/300\n",
      "122/122 [==============================] - 4s 29ms/step - loss: -0.1214 - sharpe_ratio: 5.9092e-04 - val_loss: 0.0319 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 291/300\n",
      "122/122 [==============================] - 4s 31ms/step - loss: -0.1330 - sharpe_ratio: 9.0093e-05 - val_loss: 0.0124 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 292/300\n",
      "122/122 [==============================] - 3s 29ms/step - loss: -0.1193 - sharpe_ratio: 0.0010 - val_loss: 0.0317 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 293/300\n",
      "122/122 [==============================] - 4s 30ms/step - loss: -0.1191 - sharpe_ratio: 8.3474e-04 - val_loss: 0.0339 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 294/300\n",
      "122/122 [==============================] - 4s 30ms/step - loss: -0.1130 - sharpe_ratio: 0.0010 - val_loss: 0.0036 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 295/300\n",
      "122/122 [==============================] - 4s 30ms/step - loss: -0.1194 - sharpe_ratio: 9.2981e-04 - val_loss: 0.0508 - val_sharpe_ratio: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/300\n",
      "122/122 [==============================] - 4s 30ms/step - loss: -0.1145 - sharpe_ratio: 7.1459e-04 - val_loss: 0.0594 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 297/300\n",
      "122/122 [==============================] - 4s 30ms/step - loss: -0.1145 - sharpe_ratio: 7.5704e-04 - val_loss: 0.0553 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 298/300\n",
      "122/122 [==============================] - 4s 29ms/step - loss: -0.1267 - sharpe_ratio: 3.7568e-04 - val_loss: 0.0302 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 299/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1147 - sharpe_ratio: 0.0014 - val_loss: 0.0941 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 300/300\n",
      "122/122 [==============================] - 3s 28ms/step - loss: -0.1273 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0270 - val_sharpe_ratio: 0.0000e+00\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "There are total 11 samples to predict\n",
      "Sample 0 : [  ]\n",
      "Sample 1 : [  ]\n",
      "Sample 2 : [  ]\n",
      "Sample 3 : [  ]\n",
      "Sample 4 : [  ]\n",
      "Sample 5 : [  ]\n",
      "Sample 6 : [  ]\n",
      "Sample 7 : [  ]\n",
      "Sample 8 : [  ]\n",
      "Sample 9 : [  ]\n",
      "Sample 10 : [  ]\n",
      "Sharpe ratio of this portfolio: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "write file log at C:/Users/yv67/Documents/12FundsHK_ToShare/deeplearningdata/logs/GRU\\log_2165.txt\n",
      "Epoch 1/300\n",
      "136/136 [==============================] - 4s 27ms/step - loss: -0.1022 - sharpe_ratio: 1.8902e-04 - val_loss: -1.5200e-04 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 2/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1063 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0015 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 3/300\n",
      "136/136 [==============================] - 5s 35ms/step - loss: -0.1042 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0409 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 4/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1115 - sharpe_ratio: 3.9389e-04 - val_loss: 0.0268 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 5/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1116 - sharpe_ratio: 1.6604e-04 - val_loss: -0.0474 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 6/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1059 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0697 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 7/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.0999 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0569 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 8/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1111 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0556 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 9/300\n",
      "136/136 [==============================] - 5s 35ms/step - loss: -0.0984 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0705 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 10/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1222 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0171 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 11/300\n",
      "136/136 [==============================] - 5s 33ms/step - loss: -0.1020 - sharpe_ratio: -4.0599e-05 - val_loss: -0.0849 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 12/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1160 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0021 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 13/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.0918 - sharpe_ratio: -1.2861e-04 - val_loss: -0.0272 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 14/300\n",
      "136/136 [==============================] - 4s 32ms/step - loss: -0.1065 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0195 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 15/300\n",
      "136/136 [==============================] - 5s 34ms/step - loss: -0.1023 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0311 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 16/300\n",
      "136/136 [==============================] - 5s 40ms/step - loss: -0.1047 - sharpe_ratio: 2.4243e-04 - val_loss: -0.0112 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 17/300\n",
      "136/136 [==============================] - 5s 35ms/step - loss: -0.1006 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0253 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 18/300\n",
      "136/136 [==============================] - 5s 34ms/step - loss: -0.1120 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0358 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 19/300\n",
      "136/136 [==============================] - 5s 35ms/step - loss: -0.1136 - sharpe_ratio: 1.1105e-04 - val_loss: 3.3101e-04 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 20/300\n",
      "136/136 [==============================] - 5s 35ms/step - loss: -0.0982 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0022 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 21/300\n",
      "136/136 [==============================] - 5s 35ms/step - loss: -0.1137 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0219 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 22/300\n",
      "136/136 [==============================] - 5s 33ms/step - loss: -0.1176 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0379 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 23/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.0984 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0889 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 24/300\n",
      "136/136 [==============================] - 4s 32ms/step - loss: -0.0966 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0650 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 25/300\n",
      "136/136 [==============================] - 5s 34ms/step - loss: -0.1117 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0428 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 26/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1181 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0139 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 27/300\n",
      "136/136 [==============================] - 4s 32ms/step - loss: -0.0924 - sharpe_ratio: 2.9145e-05 - val_loss: 0.0167 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 28/300\n",
      "136/136 [==============================] - 4s 32ms/step - loss: -0.1087 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0738 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 29/300\n",
      "136/136 [==============================] - 5s 35ms/step - loss: -0.1045 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0720 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 30/300\n",
      "136/136 [==============================] - 5s 37ms/step - loss: -0.1171 - sharpe_ratio: -3.0827e-05 - val_loss: -0.0200 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 31/300\n",
      "136/136 [==============================] - 4s 33ms/step - loss: -0.1162 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0309 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 32/300\n",
      "136/136 [==============================] - 5s 34ms/step - loss: -0.1155 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0586 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 33/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1051 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0389 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 34/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1113 - sharpe_ratio: -3.3386e-04 - val_loss: -0.0323 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 35/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1139 - sharpe_ratio: -1.2530e-04 - val_loss: -0.0590 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 36/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1083 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0125 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 37/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1150 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0073 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 38/300\n",
      "136/136 [==============================] - 4s 32ms/step - loss: -0.1047 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0376 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 39/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1046 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0292 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 40/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1016 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0342 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 41/300\n",
      "136/136 [==============================] - 5s 38ms/step - loss: -0.1134 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0453 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 42/300\n",
      "136/136 [==============================] - 4s 33ms/step - loss: -0.1203 - sharpe_ratio: 0.0000e+00 - val_loss: -8.8847e-04 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 43/300\n",
      "136/136 [==============================] - 5s 40ms/step - loss: -0.0969 - sharpe_ratio: -1.1193e-04 - val_loss: 0.0387 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 44/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1036 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0283 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 45/300\n",
      "136/136 [==============================] - 4s 32ms/step - loss: -0.1139 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0310 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 46/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1070 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0481 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 47/300\n",
      "136/136 [==============================] - 5s 34ms/step - loss: -0.1015 - sharpe_ratio: 6.7468e-05 - val_loss: 0.0020 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 48/300\n",
      "136/136 [==============================] - 4s 32ms/step - loss: -0.1024 - sharpe_ratio: -4.5533e-05 - val_loss: -0.0449 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 49/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1089 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0062 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 50/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1088 - sharpe_ratio: 3.2835e-05 - val_loss: -0.0454 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 51/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1116 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0442 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 52/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1083 - sharpe_ratio: 2.2088e-04 - val_loss: -0.0320 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 53/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1152 - sharpe_ratio: 0.0000e+00 - val_loss: -7.1286e-04 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 54/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1001 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0173 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 55/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1091 - sharpe_ratio: 7.5530e-06 - val_loss: -0.0379 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 56/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1082 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0448 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 57/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1186 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0581 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 58/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1116 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0294 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 59/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1117 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0309 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 60/300\n",
      "136/136 [==============================] - 4s 27ms/step - loss: -0.1130 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0489 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 61/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1121 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0480 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 62/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1042 - sharpe_ratio: 5.1857e-05 - val_loss: 0.0483 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 63/300\n",
      "136/136 [==============================] - 4s 27ms/step - loss: -0.1083 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0259 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 64/300\n",
      "136/136 [==============================] - 4s 27ms/step - loss: -0.1144 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0084 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 65/300\n",
      "136/136 [==============================] - 4s 27ms/step - loss: -0.1094 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0052 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 66/300\n",
      "136/136 [==============================] - 4s 27ms/step - loss: -0.1045 - sharpe_ratio: 1.9735e-04 - val_loss: -0.0092 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 67/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1039 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0058 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 68/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1100 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0670 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 69/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1067 - sharpe_ratio: -5.0551e-05 - val_loss: 0.0486 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 70/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.0991 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0274 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 71/300\n",
      "136/136 [==============================] - 4s 33ms/step - loss: -0.1062 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0128 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 72/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1087 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0070 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 73/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1106 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0189 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 74/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1073 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0016 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 75/300\n",
      "136/136 [==============================] - 4s 32ms/step - loss: -0.1024 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0344 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 76/300\n",
      "136/136 [==============================] - 5s 34ms/step - loss: -0.0970 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0141 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 77/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1057 - sharpe_ratio: 4.9606e-05 - val_loss: -0.0478 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 78/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1171 - sharpe_ratio: -1.1824e-05 - val_loss: -0.0076 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 79/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1141 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0386 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 80/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1131 - sharpe_ratio: 8.0784e-05 - val_loss: -0.0037 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 81/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1095 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0561 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 82/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1123 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0489 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 83/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1155 - sharpe_ratio: -1.0780e-04 - val_loss: -0.0241 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 84/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1005 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0554 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 85/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1024 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0585 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 86/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.0925 - sharpe_ratio: -7.7171e-05 - val_loss: 0.0051 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 87/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1106 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0212 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 88/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1054 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0119 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 89/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1005 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0229 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 90/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.0995 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0642 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 91/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1074 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0123 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 92/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1082 - sharpe_ratio: 2.5008e-04 - val_loss: -0.0259 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 93/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1092 - sharpe_ratio: -4.0064e-06 - val_loss: -0.0268 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 94/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1160 - sharpe_ratio: 1.1528e-04 - val_loss: -0.0030 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 95/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1044 - sharpe_ratio: -1.3335e-04 - val_loss: -0.0115 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 96/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1067 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0184 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 97/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1105 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0220 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 98/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1080 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0557 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 99/300\n",
      "136/136 [==============================] - 5s 33ms/step - loss: -0.1070 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0779 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 100/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1077 - sharpe_ratio: -2.0249e-04 - val_loss: -0.0657 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 101/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.0993 - sharpe_ratio: -7.6645e-05 - val_loss: 0.0163 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 102/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.0998 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0589 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 103/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1172 - sharpe_ratio: 3.6890e-06 - val_loss: -0.0316 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 104/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1136 - sharpe_ratio: -3.6951e-05 - val_loss: -0.0219 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 105/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.0976 - sharpe_ratio: 2.7027e-05 - val_loss: -0.0402 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 106/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1059 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0388 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 107/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1141 - sharpe_ratio: -7.9309e-05 - val_loss: -0.0130 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 108/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1161 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0144 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 109/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1048 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0236 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 110/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1081 - sharpe_ratio: -2.2759e-04 - val_loss: -0.0697 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 111/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1009 - sharpe_ratio: 4.2991e-05 - val_loss: 0.0124 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 112/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1121 - sharpe_ratio: 3.5480e-05 - val_loss: -0.0221 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 113/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1040 - sharpe_ratio: -3.8419e-04 - val_loss: -0.0266 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 114/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1117 - sharpe_ratio: 1.7617e-05 - val_loss: 0.0141 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 115/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1101 - sharpe_ratio: 5.5734e-05 - val_loss: -0.0068 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 116/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1146 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0297 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 117/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1043 - sharpe_ratio: -5.0351e-05 - val_loss: -0.0122 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 118/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1094 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0370 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 119/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1132 - sharpe_ratio: -1.6404e-05 - val_loss: -0.0462 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 120/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1130 - sharpe_ratio: -7.2945e-05 - val_loss: -0.0492 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 121/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1177 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0021 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 122/300\n",
      "136/136 [==============================] - 4s 27ms/step - loss: -0.1090 - sharpe_ratio: -1.8913e-05 - val_loss: -0.0161 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 123/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1151 - sharpe_ratio: -2.2779e-05 - val_loss: -0.0643 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 124/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1159 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0274 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 125/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1023 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0328 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 126/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1078 - sharpe_ratio: 1.5331e-05 - val_loss: -0.0496 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 127/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1176 - sharpe_ratio: 0.0000e+00 - val_loss: -6.9216e-04 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 128/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1035 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0546 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 129/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1071 - sharpe_ratio: -1.6943e-04 - val_loss: 0.0398 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 130/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1112 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0242 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 131/300\n",
      "136/136 [==============================] - 4s 32ms/step - loss: -0.1148 - sharpe_ratio: -1.1859e-04 - val_loss: -0.0261 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 132/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1153 - sharpe_ratio: 1.0100e-04 - val_loss: 0.0282 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 133/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1071 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0292 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 134/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1083 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0156 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 135/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1044 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0480 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 136/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1077 - sharpe_ratio: -4.4276e-05 - val_loss: -0.0343 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 137/300\n",
      "136/136 [==============================] - 4s 33ms/step - loss: -0.1086 - sharpe_ratio: -8.6724e-05 - val_loss: -0.0152 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 138/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1142 - sharpe_ratio: -7.7291e-05 - val_loss: -0.0079 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 139/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1045 - sharpe_ratio: -6.3425e-05 - val_loss: 0.0090 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 140/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1089 - sharpe_ratio: -8.7151e-06 - val_loss: -0.0060 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 141/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1184 - sharpe_ratio: 8.5204e-05 - val_loss: -0.0287 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 142/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1156 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0030 - val_sharpe_ratio: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1106 - sharpe_ratio: -1.9394e-05 - val_loss: -0.0200 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 144/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1022 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0598 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 145/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1085 - sharpe_ratio: 4.3197e-05 - val_loss: 0.0129 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 146/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1028 - sharpe_ratio: 6.1790e-05 - val_loss: 0.0100 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 147/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1107 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0186 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 148/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1082 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0561 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 149/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1159 - sharpe_ratio: -1.2113e-04 - val_loss: -0.0350 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 150/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1103 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0236 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 151/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1122 - sharpe_ratio: -4.3810e-05 - val_loss: -0.0425 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 152/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1116 - sharpe_ratio: -7.2377e-05 - val_loss: -0.0454 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 153/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1137 - sharpe_ratio: 1.0536e-04 - val_loss: -0.0011 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 154/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1088 - sharpe_ratio: -8.4425e-05 - val_loss: 0.0055 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 155/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1138 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0161 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 156/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1067 - sharpe_ratio: -7.1771e-05 - val_loss: 0.0149 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 157/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1016 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0103 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 158/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1184 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0422 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 159/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1079 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0771 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 160/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1125 - sharpe_ratio: -7.7291e-05 - val_loss: -0.0593 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 161/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1098 - sharpe_ratio: 8.4801e-05 - val_loss: 0.0112 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 162/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1107 - sharpe_ratio: -1.0046e-05 - val_loss: -0.0568 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 163/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1204 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0021 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 164/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1138 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0239 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 165/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1151 - sharpe_ratio: -5.1902e-05 - val_loss: 0.0029 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 166/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1055 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0134 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 167/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1108 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0126 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 168/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1017 - sharpe_ratio: 1.0265e-04 - val_loss: -0.0090 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 169/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1027 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0384 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 170/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1139 - sharpe_ratio: 1.1486e-05 - val_loss: -0.0430 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 171/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1180 - sharpe_ratio: 1.4763e-05 - val_loss: -0.0276 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 172/300\n",
      "136/136 [==============================] - 5s 33ms/step - loss: -0.1137 - sharpe_ratio: 1.1767e-04 - val_loss: -0.0258 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 173/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1149 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0031 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 174/300\n",
      "136/136 [==============================] - 4s 33ms/step - loss: -0.1014 - sharpe_ratio: 2.9365e-05 - val_loss: 0.0120 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 175/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1101 - sharpe_ratio: -3.0945e-05 - val_loss: 0.0089 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 176/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1115 - sharpe_ratio: 2.9622e-04 - val_loss: -0.0441 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 177/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1067 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0430 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 178/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1089 - sharpe_ratio: 0.0000e+00 - val_loss: 3.1975e-04 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 179/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1029 - sharpe_ratio: 7.5869e-06 - val_loss: -0.0359 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 180/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1084 - sharpe_ratio: 5.9979e-05 - val_loss: -0.0533 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 181/300\n",
      "136/136 [==============================] - 5s 36ms/step - loss: -0.1139 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0350 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 182/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1151 - sharpe_ratio: 8.9350e-05 - val_loss: -0.0191 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 183/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1186 - sharpe_ratio: 1.1035e-04 - val_loss: 0.0115 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 184/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1006 - sharpe_ratio: 1.8651e-04 - val_loss: -0.0200 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 185/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1097 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0246 - val_sharpe_ratio: 0.0524\n",
      "Epoch 186/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1078 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0088 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 187/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1056 - sharpe_ratio: -6.0837e-05 - val_loss: -0.1044 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 188/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1135 - sharpe_ratio: -1.6398e-04 - val_loss: -0.0029 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 189/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1139 - sharpe_ratio: -3.7328e-05 - val_loss: -0.0396 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 190/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1108 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0231 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 191/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1104 - sharpe_ratio: 1.8796e-04 - val_loss: -0.0214 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 192/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1124 - sharpe_ratio: -1.1586e-04 - val_loss: -0.0165 - val_sharpe_ratio: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1047 - sharpe_ratio: -2.5678e-04 - val_loss: -0.0414 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 194/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1028 - sharpe_ratio: -1.1051e-05 - val_loss: -0.0365 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 195/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1174 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0145 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 196/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1129 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0340 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 197/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1157 - sharpe_ratio: 4.9655e-05 - val_loss: -0.0143 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 198/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1099 - sharpe_ratio: -3.9916e-05 - val_loss: -0.0462 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 199/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1166 - sharpe_ratio: 4.6786e-05 - val_loss: -0.0553 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 200/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1169 - sharpe_ratio: -1.1191e-04 - val_loss: -0.0263 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 201/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1052 - sharpe_ratio: -7.7291e-05 - val_loss: -0.0192 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 202/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1112 - sharpe_ratio: 3.1758e-05 - val_loss: -0.0266 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 203/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1115 - sharpe_ratio: -1.6481e-05 - val_loss: 0.0043 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 204/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1100 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0228 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 205/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1045 - sharpe_ratio: -3.0602e-04 - val_loss: -0.0127 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 206/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1111 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0040 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 207/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1148 - sharpe_ratio: -1.6089e-04 - val_loss: 0.0084 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 208/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1131 - sharpe_ratio: -2.4722e-04 - val_loss: -0.0092 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 209/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1141 - sharpe_ratio: -9.2714e-05 - val_loss: -0.0489 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 210/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1094 - sharpe_ratio: -3.9806e-04 - val_loss: 0.0104 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 211/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1073 - sharpe_ratio: -2.2599e-05 - val_loss: 0.0317 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 212/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.0970 - sharpe_ratio: -1.2130e-04 - val_loss: -0.0497 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 213/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1090 - sharpe_ratio: -4.7895e-05 - val_loss: -0.0107 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 214/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1213 - sharpe_ratio: -2.6403e-05 - val_loss: -0.0247 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 215/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1118 - sharpe_ratio: -1.5087e-04 - val_loss: 0.0432 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 216/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1127 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0399 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 217/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1212 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0933 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 218/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1087 - sharpe_ratio: -2.9409e-04 - val_loss: -0.0106 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 219/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1063 - sharpe_ratio: 2.4111e-04 - val_loss: -0.0512 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 220/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1165 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0398 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 221/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1067 - sharpe_ratio: -8.1623e-05 - val_loss: -0.0523 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 222/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1071 - sharpe_ratio: -2.1986e-04 - val_loss: -0.0387 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 223/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1100 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0387 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 224/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1177 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0223 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 225/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1103 - sharpe_ratio: -3.7456e-05 - val_loss: -0.0389 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 226/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1180 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0268 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 227/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1104 - sharpe_ratio: -4.0268e-05 - val_loss: -0.0177 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 228/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1086 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0292 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 229/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1133 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0355 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 230/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1134 - sharpe_ratio: -5.8406e-05 - val_loss: 0.0533 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 231/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1102 - sharpe_ratio: -2.8865e-05 - val_loss: -0.0139 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 232/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1120 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0093 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 233/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1072 - sharpe_ratio: -3.9661e-05 - val_loss: -0.0101 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 234/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1211 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0222 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 235/300\n",
      "136/136 [==============================] - 4s 27ms/step - loss: -0.1204 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0126 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 236/300\n",
      "136/136 [==============================] - 4s 27ms/step - loss: -0.1138 - sharpe_ratio: -7.1634e-05 - val_loss: -0.0161 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 237/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1098 - sharpe_ratio: -2.4726e-04 - val_loss: 3.4780e-04 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 238/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1025 - sharpe_ratio: -7.7479e-05 - val_loss: 0.0045 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 239/300\n",
      "136/136 [==============================] - 4s 27ms/step - loss: -0.1060 - sharpe_ratio: 6.7452e-05 - val_loss: -0.0269 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 240/300\n",
      "136/136 [==============================] - 4s 27ms/step - loss: -0.1024 - sharpe_ratio: 7.4262e-05 - val_loss: 0.0066 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 241/300\n",
      "136/136 [==============================] - 4s 27ms/step - loss: -0.1013 - sharpe_ratio: -8.0208e-05 - val_loss: -0.0419 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 242/300\n",
      "136/136 [==============================] - 4s 27ms/step - loss: -0.1152 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0074 - val_sharpe_ratio: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 243/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1089 - sharpe_ratio: 2.4054e-04 - val_loss: 0.0057 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 244/300\n",
      "136/136 [==============================] - 4s 27ms/step - loss: -0.0921 - sharpe_ratio: 3.9574e-05 - val_loss: -0.0235 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 245/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1100 - sharpe_ratio: -1.1807e-04 - val_loss: 0.0602 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 246/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1063 - sharpe_ratio: 2.0710e-04 - val_loss: -0.0175 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 247/300\n",
      "136/136 [==============================] - 4s 27ms/step - loss: -0.1121 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0262 - val_sharpe_ratio: 0.0099\n",
      "Epoch 248/300\n",
      "136/136 [==============================] - 4s 27ms/step - loss: -0.1191 - sharpe_ratio: 1.1683e-04 - val_loss: -0.0598 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 249/300\n",
      "136/136 [==============================] - 5s 36ms/step - loss: -0.1111 - sharpe_ratio: -3.5004e-04 - val_loss: 0.0161 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 250/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1127 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0028 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 251/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1151 - sharpe_ratio: -2.4550e-04 - val_loss: 0.0099 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 252/300\n",
      "136/136 [==============================] - 5s 34ms/step - loss: -0.1094 - sharpe_ratio: -3.1685e-05 - val_loss: -0.0116 - val_sharpe_ratio: 0.0099\n",
      "Epoch 253/300\n",
      "136/136 [==============================] - 5s 35ms/step - loss: -0.1111 - sharpe_ratio: -8.2431e-05 - val_loss: -0.0024 - val_sharpe_ratio: 0.0133\n",
      "Epoch 254/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1043 - sharpe_ratio: -1.9382e-04 - val_loss: -0.0379 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 255/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1078 - sharpe_ratio: -2.6917e-05 - val_loss: 0.0542 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 256/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1020 - sharpe_ratio: -8.5213e-05 - val_loss: 0.0256 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 257/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1133 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0452 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 258/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1138 - sharpe_ratio: 1.3520e-04 - val_loss: -0.0360 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 259/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1200 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0274 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 260/300\n",
      "136/136 [==============================] - 4s 33ms/step - loss: -0.1159 - sharpe_ratio: -7.6327e-05 - val_loss: -0.0424 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 261/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1169 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0043 - val_sharpe_ratio: -0.0104\n",
      "Epoch 262/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1190 - sharpe_ratio: -2.1037e-04 - val_loss: -0.0704 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 263/300\n",
      "136/136 [==============================] - 4s 28ms/step - loss: -0.1071 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0380 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 264/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1210 - sharpe_ratio: -3.4887e-05 - val_loss: -0.0508 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 265/300\n",
      "136/136 [==============================] - 5s 37ms/step - loss: -0.1189 - sharpe_ratio: -2.8865e-05 - val_loss: -0.0585 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 266/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1139 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0070 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 267/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1106 - sharpe_ratio: 1.8944e-04 - val_loss: -0.0135 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 268/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1115 - sharpe_ratio: -1.1605e-04 - val_loss: -0.0221 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 269/300\n",
      "136/136 [==============================] - 5s 38ms/step - loss: -0.1066 - sharpe_ratio: -9.7246e-05 - val_loss: -0.0150 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 270/300\n",
      "136/136 [==============================] - 7s 52ms/step - loss: -0.1120 - sharpe_ratio: 6.2781e-05 - val_loss: -0.0178 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 271/300\n",
      "136/136 [==============================] - 6s 42ms/step - loss: -0.1062 - sharpe_ratio: 2.9540e-04 - val_loss: -0.0259 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 272/300\n",
      "136/136 [==============================] - 5s 40ms/step - loss: -0.1086 - sharpe_ratio: -9.5285e-05 - val_loss: -0.0456 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 273/300\n",
      "136/136 [==============================] - 6s 45ms/step - loss: -0.1179 - sharpe_ratio: -1.2363e-05 - val_loss: -0.0521 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 274/300\n",
      "136/136 [==============================] - 6s 46ms/step - loss: -0.1180 - sharpe_ratio: -1.7800e-04 - val_loss: 0.0090 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 275/300\n",
      "136/136 [==============================] - 6s 41ms/step - loss: -0.1133 - sharpe_ratio: 2.2748e-04 - val_loss: -0.0342 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 276/300\n",
      "136/136 [==============================] - 5s 36ms/step - loss: -0.1137 - sharpe_ratio: -1.3715e-06 - val_loss: -0.0354 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 277/300\n",
      "136/136 [==============================] - 8s 57ms/step - loss: -0.1062 - sharpe_ratio: -1.2048e-04 - val_loss: -0.0176 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 278/300\n",
      "136/136 [==============================] - 4s 33ms/step - loss: -0.1035 - sharpe_ratio: -6.5776e-05 - val_loss: -0.0948 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 279/300\n",
      "136/136 [==============================] - 5s 40ms/step - loss: -0.1082 - sharpe_ratio: -4.5993e-04 - val_loss: -0.0061 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 280/300\n",
      "136/136 [==============================] - 5s 38ms/step - loss: -0.1180 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0734 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 281/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1071 - sharpe_ratio: 1.7666e-04 - val_loss: -0.0053 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 282/300\n",
      "136/136 [==============================] - 4s 32ms/step - loss: -0.1125 - sharpe_ratio: 1.5648e-06 - val_loss: -0.0627 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 283/300\n",
      "136/136 [==============================] - 5s 33ms/step - loss: -0.1031 - sharpe_ratio: -9.6221e-06 - val_loss: -0.0128 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 284/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1041 - sharpe_ratio: -6.9668e-05 - val_loss: -0.0235 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 285/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1151 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0212 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 286/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1034 - sharpe_ratio: 9.1835e-05 - val_loss: 0.0091 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 287/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1086 - sharpe_ratio: 1.2694e-04 - val_loss: -0.0110 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 288/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1168 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0417 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 289/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1135 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0469 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 290/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1221 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0081 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 291/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1141 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0452 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 292/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1102 - sharpe_ratio: -9.8152e-05 - val_loss: -0.0429 - val_sharpe_ratio: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1187 - sharpe_ratio: -2.7444e-05 - val_loss: -0.0437 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 294/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1188 - sharpe_ratio: -1.3409e-05 - val_loss: -0.0267 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 295/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1163 - sharpe_ratio: -1.0808e-04 - val_loss: -0.0493 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 296/300\n",
      "136/136 [==============================] - 4s 31ms/step - loss: -0.1012 - sharpe_ratio: 0.0000e+00 - val_loss: -0.0063 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 297/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1174 - sharpe_ratio: -3.6955e-04 - val_loss: -0.0151 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 298/300\n",
      "136/136 [==============================] - 4s 30ms/step - loss: -0.1168 - sharpe_ratio: -5.3704e-05 - val_loss: -0.0070 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 299/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1097 - sharpe_ratio: 0.0000e+00 - val_loss: 0.0020 - val_sharpe_ratio: 0.0000e+00\n",
      "Epoch 300/300\n",
      "136/136 [==============================] - 4s 29ms/step - loss: -0.1097 - sharpe_ratio: 4.6652e-04 - val_loss: 0.0020 - val_sharpe_ratio: 0.0000e+00\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "There are total 11 samples to predict\n",
      "Sample 0 : [  ]\n",
      "Sample 1 : [  ]\n",
      "Sample 2 : [  ]\n",
      "Sample 3 : [  ]\n",
      "Sample 4 : [  ]\n",
      "Sample 5 : [  ]\n",
      "Sample 6 : [  ]\n",
      "Sample 7 : [  ]\n",
      "Sample 8 : [  ]\n",
      "Sample 9 : [  ]\n",
      "Sample 10 : [  ]\n",
      "Sharpe ratio of this portfolio: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "write file log at C:/Users/yv67/Documents/12FundsHK_ToShare/deeplearningdata/logs/GRU\\log_2381.txt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x216 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class PortfolioOptimization:\n",
    "    def __init__(self,model_name,model,X,y,tickers,timesteps_input=64,timesteps_output=19):\n",
    "        self.model_name = model_name\n",
    "        self.model = model\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.tickers = tickers\n",
    "        self.timesteps_input = timesteps_input\n",
    "        self.timesteps_output = timesteps_output\n",
    "       \n",
    "      \n",
    "    \n",
    "    @classmethod \n",
    "    def rolling_array(self,a, stepsize=1, window=60):\n",
    "        n = a.shape[0]\n",
    "        return np.stack((a[i:i + window:stepsize] for i in range(0,n - window + 1)),axis=0) \n",
    "\n",
    "    \n",
    "    \n",
    "    @classmethod   \n",
    "    def load_data(self,path,window_x,window_y):\n",
    "        print(path)\n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "        df.head(4)\n",
    "        df['date'] = df.date.apply(pd.Timestamp)\n",
    "\n",
    "        df['dow'] = df.date.apply(lambda x: x.dayofweek)\n",
    "        ## just select working days\n",
    "        df = df[(df.dow<=4)&(df.dow>=0)]\n",
    "        df = df.drop(['dow'],axis=1)\n",
    "        df = df.drop(['volume'],axis=1)\n",
    "        df = df.pivot_table(index='date', columns='ticker')\n",
    "\n",
    "        ## select tickers not nan in final day\n",
    "        columns = df.close.columns[~df.close.iloc[-1].isna()]\n",
    "        df = df.iloc[:, df.columns.get_level_values(1).isin(columns)]\n",
    "\n",
    "\n",
    "        #df.volume = df.volume.interpolate(method='linear',limit_area='inside',limit_direction='both', axis=0)\n",
    "        df.close = df.close.interpolate(method='linear',limit_area='inside',limit_direction='both', axis=0)\n",
    "\n",
    "\n",
    "\n",
    "        close = df.close\n",
    "        daily_return = ((close.shift(-1) - close)/close).shift(1)\n",
    "\n",
    "        daily_return = daily_return.interpolate(method='linear',limit_area=\"inside\",limit_direction='both', axis=0)\n",
    "        # daily_return = daily_return.fillna(daily_return.min(axis=0),axis=0)\n",
    "        # daily_return = daily_return.fillna(daily_return.min(axis=0),inplace=True)\n",
    "\n",
    "        # daily_return.fillna(daily_return.min(axis=0), inplace=True)\n",
    "\n",
    "        tickers = df.close.columns\n",
    "\n",
    "        X = df.values.reshape(df.shape[0],1,-1)\n",
    "        y = daily_return.values\n",
    "\n",
    "        ## fill X\n",
    "        ##fill nan by 0.0\n",
    "        X[np.isnan(X)] = 0.0\n",
    "\n",
    "        ## fill y\n",
    "        y[np.isnan(y)] = -1e2\n",
    "        # y[np.isnan(y)] = 0\n",
    "\n",
    "        # X1 = rolling_array(X[window_x:],stepsize=1,window=window_y)\n",
    "\n",
    "        X = self.rolling_array(X[:-window_y],stepsize=1,window=window_x)\n",
    "        y = self.rolling_array(y[window_x:],stepsize=1,window=window_y)\n",
    "        X = np.moveaxis(X,-1,1)\n",
    "        # X1 = np.moveaxis(X1,-1,1)\n",
    "        y = np.swapaxes(y,1,2)\n",
    "\n",
    "        return X,y,tickers\n",
    "    \n",
    "    @classmethod \n",
    "    def load_config_file(self,path):\n",
    "        with open(path,'r') as file:\n",
    "            f = json.load(file)\n",
    "        return f\n",
    "    \n",
    "    @classmethod   \n",
    "    def from_existing_config(self,csvpath_data,model_name,model_config_path,timesteps_input=64,timesteps_output=19):\n",
    "       \n",
    "        X,y,tickers = self.load_data( csvpath_data,  timesteps_input,  timesteps_output)\n",
    "       \n",
    "          \n",
    "        if model_name == \"LSTN\":    \n",
    "            \n",
    "            hyper_params = self.load_config_file(model_config_path[model_name])\n",
    "            hyper_params['input_shape'] = (X.shape[1],X.shape[2],X.shape[3])\n",
    "            model = self.build_lstm_model(hyper_params)\n",
    "            \n",
    "        elif model_name == \"GRU\":\n",
    "            hyper_params = self.load_config_file(model_config_path[model_name])\n",
    "            hyper_params['input_shape'] = (X.shape[1],X.shape[2],X.shape[3])\n",
    "            model = self.build_gru_model(hyper_params)\n",
    "            \n",
    "        elif model_name == \"AA_GRU\":\n",
    "            hyper_params = self.load_config_file(model_config_path[model_name])\n",
    "            hyper_params['input_shape'] = (X.shape[1],X.shape[2],X.shape[3])\n",
    "            print(hyper_params)\n",
    "            model = self.build_add_att_gru_model(hyper_params)\n",
    "        \n",
    "        return self(model_name,model,X,y,tickers,timesteps_input,timesteps_output)\n",
    "    \n",
    "   # @classmethod\n",
    "    def write_log(self,history,path_dir,name_file):\n",
    "        his = history.history\n",
    "        if os.path.exists(path_dir)==False:\n",
    "            os.makedirs(path_dir)\n",
    "        with open(os.path.join(path_dir,name_file), 'w') as outfile:\n",
    "            json.dump(his, outfile,cls=MyEncoder, indent=2)\n",
    "        print(\"write file log at %s\"%(os.path.join(path_dir,name_file)))\n",
    "\n",
    "   # @classmethod    \n",
    "    def train_model(self,n_fold,batch_size,epochs):\n",
    "        tscv = TimeSeriesSplit(n_splits=n_fold)\n",
    "        \n",
    "        for train_index, test_index in tscv.split(self.X):\n",
    "\n",
    "            X_tr, X_val = self.X[train_index], self.X[test_index[range(self.timesteps_output-1,len(test_index),self.timesteps_output)]]\n",
    "            y_tr, y_val = self.y[train_index], self.y[test_index[range(self.timesteps_output-1,len(test_index),self.timesteps_output)]]\n",
    "\n",
    "           \n",
    "            his = self.model.fit(X_tr, y_tr, batch_size=batch_size, epochs= epochs,validation_data=(X_val,y_val))\n",
    "            \n",
    "           \n",
    "            mask_tickers = self.predict_portfolio(X_val)\n",
    "            print('Sharpe ratio of this portfolio: %s' % str([self.calc_sharpe_ratio(mask_tickers[i],y_val[i]) for i in range(len(y_val))]))\n",
    "\n",
    "            self.write_log(his,'C:/Users/yv67/Documents/12FundsHK_ToShare/deeplearningdata/logs/%s' % self.model_name,\"log_%d.txt\"%(test_index[-1]))\n",
    "        self.visualize_log('C:/Users/yv67/Documents/12FundsHK_ToShare/deeplearningdata/logs/',self.model_name)\n",
    "        \n",
    "    #@classmethod\n",
    "    def predict_portfolio(self,X):\n",
    "       # print(self.model)\n",
    "        results = self.model.predict(X)\n",
    "        mask_tickers = results>0.5\n",
    "        print(\"There are total %d samples to predict\" % len(results))\n",
    "        for i in range(len(mask_tickers)):\n",
    "            print('Sample %d : [ %s ]' % (i, ' '.join([self.tickers[j] for j in range(len(self.tickers)) if mask_tickers[i][j]==1])))\n",
    "\n",
    "        return mask_tickers\n",
    "    \n",
    "    #@classmethod\n",
    "    def calc_sharpe_ratio(self,weight,y):\n",
    "        \"\"\"Here y is the daily return have the shape (tickers,days)\n",
    "        weight have the shape (tickers,)\"\"\"\n",
    "        epsilon = 1e-6\n",
    "        weights = np.round(weight)\n",
    "        sum_w = np.clip(weights.sum(),epsilon,y.shape[0])\n",
    "        norm_weight = weights/sum_w\n",
    "        port_return = norm_weight.dot(y).squeeze()\n",
    "        mean = np.mean(port_return)\n",
    "        std = np.maximum(np.std(port_return),epsilon)\n",
    "        return np.sqrt(self.timesteps_output) * mean/std\n",
    "\n",
    "    @classmethod\n",
    "    def visualize_log(self,path_folder,model_name):\n",
    "        \n",
    "        n_cols = 6\n",
    "        n_rows = 1\n",
    "        fig,axes = plt.subplots(ncols = n_cols,figsize=(20,3))\n",
    "        path_files = [os.path.join(path_folder,model_name,file) for file in os.listdir(os.path.join(path_folder,model_name)) if os.path.isfile(os.path.join(path_folder,model_name,file))]\n",
    "        for i,path in enumerate(path_files[-6:]):\n",
    "\n",
    "            with open(path) as f:\n",
    "                history = json.loads(f.read())\n",
    "\n",
    "            axes[i].plot(history['sharpe_ratio'][:])\n",
    "            axes[i].plot(history['val_sharpe_ratio'][:])\n",
    "            axes[i].set_ylabel('Sharpe_ratio')\n",
    "            axes[i].set_xlabel('Epoch')\n",
    "            axes[i].legend(['Train', 'Test'], loc='upper left')\n",
    "        new_path = os.path.join('/'.join(path_folder.split('/')[:-1]),'plot',model_name)\n",
    "        if os.path.exists(new_path)==False:\n",
    "            os.makedirs(new_path)\n",
    "        plt.savefig(os.path.join(new_path,'1.png'))\n",
    "    \n",
    "    @classmethod  \n",
    "    def sharpe_ratio_loss(self,y_true, y_pred):\n",
    "        epsilon = 1e-6\n",
    "        max_bound = 1 - epsilon\n",
    "        n_tickers = K.cast(K.shape(y_true)[1],K.floatx())\n",
    "        constraint_value = 3e-3\n",
    "        y_pred_reshape = K.expand_dims(y_pred, axis=-1)\n",
    "        z = y_true * y_pred_reshape\n",
    "        z = K.sum(z, axis=1)\n",
    "\n",
    "        sum_w = K.clip(K.sum(y_pred_reshape, axis=1), epsilon, n_tickers* max_bound)\n",
    "        ## constraint for number of tickers\n",
    "    #     num_constraint = C * (K.sum(y_pred) - 50)*(K.sum(y_pred)-10)\n",
    "        rate = z/sum_w\n",
    "        sharpeRatio = K.mean(rate, axis = 1)/K.maximum(K.std(rate, axis=1),epsilon)\n",
    "        constraint =  K.sum((1.6 - y_pred) * y_pred,axis=1)\n",
    "        return K.mean(constraint_value* constraint - sharpeRatio)\n",
    "\n",
    "\n",
    "    @classmethod  \n",
    "    def sharpe_ratio(self,y_true, y_pred):\n",
    "        epsilon = 1e-6\n",
    "        n_tickers = K.cast(K.shape(y_true)[1],K.floatx())\n",
    "        y_pred_reshape = K.expand_dims(y_pred, axis=-1)\n",
    "        y_pred_reshape= K.cast(K.greater(K.clip(y_pred_reshape, 0, 1), 0.5), K.floatx())\n",
    "\n",
    "        z = y_true * y_pred_reshape\n",
    "        z = K.sum(z, axis=1)\n",
    "        sum_w = K.clip(K.sum(y_pred_reshape, axis=1), epsilon, n_tickers)\n",
    "        rate = z/sum_w\n",
    "        sharpeRatio = K.mean(rate, axis = 1)/K.maximum(K.std(rate, axis=1),epsilon)\n",
    "\n",
    "        return K.mean(sharpeRatio)\n",
    "\n",
    "    \n",
    "\n",
    "    @classmethod  \n",
    "    def build_lstm_model(self,params):\n",
    "        units = params['units']\n",
    "        activation = params['activation']\n",
    "        reg1 = params['l2']\n",
    "        reg2 = params['l2_1']\n",
    "        lr = params['l2_2']\n",
    "        input_shape = params['input_shape']\n",
    "        ts = input_shape[1]\n",
    "        tickers = input_shape[0]\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        reshape_inp = Lambda(lambda x: K.permute_dimensions(x,pattern=(0,2,1,3))) (input)\n",
    "        reshape_inp = Reshape((ts,-1)) (reshape_inp)\n",
    "\n",
    "        batch_norm = BatchNormalization()(reshape_inp)\n",
    "        recurrent_layer = LSTM(units = units,\n",
    "                        activation = activation,\n",
    "                      kernel_regularizer=regularizers.l2(reg1)) (batch_norm)\n",
    "\n",
    "        batch_norm_2 = BatchNormalization()(recurrent_layer)\n",
    "\n",
    "\n",
    "        out = Dense(tickers, kernel_regularizer =regularizers.l2(reg2)) (batch_norm_2)\n",
    "\n",
    "        out = Activation('sigmoid')(out)\n",
    "\n",
    "        model = Model([input], [out])\n",
    "        optimizer = Adam(lr = lr)\n",
    "        model.compile(loss=self.sharpe_ratio_loss, optimizer=optimizer, metrics = [self.sharpe_ratio])\n",
    "        return model\n",
    "\n",
    "    @classmethod \n",
    "    def build_gru_model(self, params):\n",
    "        units = params['units']\n",
    "        activation = params['activation']\n",
    "        reg1 = params['l2']\n",
    "        reg2 = params['l2_1']\n",
    "        lr = params['l2_2']\n",
    "\n",
    "        input_shape = params['input_shape']\n",
    "        ts = input_shape[1]\n",
    "        tickers = input_shape[0]\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        reshape_inp = Lambda(lambda x: K.permute_dimensions(x,pattern=(0,2,1,3))) (input)\n",
    "        reshape_inp = Reshape((ts,-1)) (reshape_inp)\n",
    "\n",
    "        batch_norm = BatchNormalization()(reshape_inp)\n",
    "        recurrent_layer = GRU(units = units,\n",
    "                            activation = activation,\n",
    "                          kernel_regularizer=regularizers.l2(reg1)) (batch_norm)\n",
    "\n",
    "        batch_norm_2 = BatchNormalization()(recurrent_layer)\n",
    "        out = Dense(tickers, kernel_regularizer =regularizers.l2(reg2)) (batch_norm_2)\n",
    "        out = Activation('sigmoid')(out)\n",
    "\n",
    "        model = Model([input], [out])\n",
    "        optimizer = Adam(lr = lr)\n",
    "        model.compile(loss=self.sharpe_ratio_loss, optimizer=optimizer, metrics = [self.sharpe_ratio])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    \n",
    "    @classmethod \n",
    "    def build_add_att_gru_model(self, params):\n",
    "        units = params['units']\n",
    "        activation = params['activation']\n",
    "        reg1 = params['l2']\n",
    "        reg2 = params['l2_1']\n",
    "        lr = params['l2_2']\n",
    "        input_shape = params['input_shape']\n",
    "        ts = input_shape[1]\n",
    "        tickers = input_shape[0]\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        reshape_inp = Lambda(lambda x: K.permute_dimensions(x,pattern=(0,2,1,3))) (input)\n",
    "        reshape_inp = Reshape((ts,-1)) (reshape_inp)\n",
    "\n",
    "        batch_norm = BatchNormalization()(reshape_inp)\n",
    "\n",
    "\n",
    "        recurrent_layer = GRU(units = units,\n",
    "                        activation = activation,\n",
    "                      kernel_regularizer=regularizers.l2(reg1)) (batch_norm)\n",
    "\n",
    "        batch_norm_2 = BatchNormalization()(recurrent_layer)\n",
    "\n",
    "        ##ATTENTION LAYER\n",
    "        contxt_layer = AdditiveAttentionLayer(name='Att',latent_dim=32,kernel_regularizer=regularizers.l2(0.01))([batch_norm,batch_norm_2])\n",
    "\n",
    "        merge = Concatenate()([batch_norm_2,contxt_layer])\n",
    "\n",
    "        out = Dense(units, kernel_regularizer =regularizers.l2(reg2),activation='tanh') (merge)\n",
    "        batch_norm_3 = BatchNormalization()(out)\n",
    "\n",
    "\n",
    "        out = Dense(tickers, kernel_regularizer =regularizers.l2(reg2)) (batch_norm_3)\n",
    "\n",
    "        out = Activation('sigmoid')(out)\n",
    "\n",
    "        model = Model([input], [out])\n",
    "        optimizer = Adam(lr = lr)\n",
    "        model.compile(loss=self.sharpe_ratio_loss, optimizer=optimizer, metrics = [self.sharpe_ratio])\n",
    "        return \n",
    "\n",
    "\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    model_config_path = {\n",
    "                        'ResNet':\"C:/Users/yv67/Documents/12FundsHK_ToShare/deeplearningdata/resnet_hyper_params.json\",\n",
    "                        'GRU': \"C:/Users/yv67/Documents/12FundsHK_ToShare/deeplearningdata/gru_hyper_params.json\",\n",
    "                        'LSTM':r\"C:\\Users\\yv67\\Documents\\12FundsHK_ToShare\\deeplearningdata\\lstm_hyper_params.json\",\n",
    "                        'AA_GRU':\"C:/Users/yv67/Documents/12FundsHK_ToShare/deeplearningdata/gru_hyper_params.json\",\n",
    "                        'AA_LSTM':\"C:/Users/yv67/Documents/12FundsHK_ToShare/deeplearningdata/lstm_hyper_params.json\",\n",
    "                        'SA_GRU':\"C:/Users/yv67/Documents/12FundsHK_ToShare/deeplearningdata/gru_hyper_params.json\",\n",
    "                        'SA_LSTM':\"C:/Users/yv67/Documents/12FundsHK_ToShare/deeplearningdata/lstm_hyper_params.json\"}\n",
    "   \n",
    "    \n",
    "    ## \"LSTM\":\n",
    "    #model = \"AA_GRU\"\n",
    "    model = \"GRU\"\n",
    "    timesteps_input = 64\n",
    "    timesteps_output = 19\n",
    "    data_path = r\"C:\\Users\\yv67\\Documents\\12FundsHK_ToShare\\deeplearningdata\\stocks - Copy (2).csv\"\n",
    "    otimizationModel = PortfolioOptimization.from_existing_config(data_path,model,model_config_path,timesteps_input,timesteps_output)\n",
    "    otimizationModel.train_model(n_fold=10,batch_size=16,epochs=300)\n",
    "    #print(delafo.X)\n",
    "    #    delafo.save_model()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc7a834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9660644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
